{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextGenerationPipeline, AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class JointSeqClassifier(transformers.DistilBertForSequenceClassification):\n",
    "    '''\n",
    "    A class that inherits from DistilBertForSequenceClassification, but extends the model to \n",
    "    have multiple classifiers at the end to perform joint classification over multple tasks.\n",
    "    '''\n",
    "    def __init__(self, config, num_tasks=1):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self. num_tasks = num_tasks\n",
    "\n",
    "        self.distilbert = transformers.DistilBertModel(config)\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        # List of classifiers\n",
    "        self.classifier = nn.ModuleList([nn.Linear(config.dim, config.num_labels) \\\n",
    "                           for i in range(num_tasks)])\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        task_ids, \n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \n",
    "        task_ids (list of ints):\n",
    "            Labels indexing which classification task the labels correspond to.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
    "        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n",
    "        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        \n",
    "        logits_list = []\n",
    "        loss = 0\n",
    "        for i in range(self.num_tasks):\n",
    "            logits = self.classifier[i](pooled_output)  # (bs, num_labels)\n",
    "            logits_list.append(logits)\n",
    "            if labels != None:\n",
    "                for i in task_ids:\n",
    "                    if self.num_labels == 1:\n",
    "                        loss_fct = nn.MSELoss()\n",
    "                        loss += loss_fct(logits.view(-1), labels.view(-1))\n",
    "                    else:\n",
    "                        loss_fct = nn.CrossEntropyLoss()\n",
    "                        loss += loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits_list,) + distilbert_output[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return transformers.modeling_outputs.SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits_list,\n",
    "            hidden_states=distilbert_output.hidden_states,\n",
    "            attentions=distilbert_output.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing JointSeqClassifier: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing JointSeqClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing JointSeqClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of JointSeqClassifier were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['classifier.0.weight', 'classifier.0.bias', 'classifier.1.weight', 'classifier.1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JointSeqClassifier(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): ModuleList(\n",
       "    (0): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING JOINT MODEL\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "                                          model_max_length=64)\n",
    "\n",
    "model = JointSeqClassifier.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                                            num_tasks=2)\n",
    "\n",
    "# Try only updating final layers\n",
    "params_to_update = [[] for i in range(model.num_tasks)]\n",
    "\n",
    "for i in range(model.num_tasks):\n",
    "    for name, param in model.named_parameters():\n",
    "        if f\"classifier.{i}.\" in name:\n",
    "            params_to_update[i].append(param)\n",
    "\n",
    "optims = [AdamW(params_to_update[i], lr=5e-5) for i in range(model.num_tasks)]\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", model_max_length=64)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# # Try only updating final layers\n",
    "# params_to_update = []\n",
    "\n",
    "# for name,param in model.named_parameters():\n",
    "#     if 'classifier' in name:\n",
    "#         params_to_update.append(param)\n",
    "        \n",
    "# optim = AdamW(params_to_update, lr=5e-5)\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single(input_tensor_batch, target_tensor_batch, \n",
    "                 model, model_optimizer, task_ids):\n",
    "    '''\n",
    "    A single forward and backward pass of the neural net on a single training batch.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        - input_tensor_batch  : list of tensors. \n",
    "                                A batch of encoded sentence inputs and is\n",
    "                                of size (batch_size, max_length).\n",
    "        - target_tensors_batch : list of tensors\n",
    "                                 Each tensor represents a batch of class labels.\n",
    "                                 Each tensor is of size (batch_size, 1).\n",
    "        - model                : PyTorch sequence classifier model.  \n",
    "                                 Assumed to be a JointSeqClassifier or \n",
    "                                 DistilBertForSequenceClassification model\n",
    "        - model_optimizer      : PyTorch Optimizer.\n",
    "                                 The optimizer used by the model for training.\n",
    "        - task_ids             : list of ints.\n",
    "                                 List of the indices for the tasks on which we're training. \n",
    "                                 Although it is a list, currently it only works if the list \n",
    "                                 is a single element (for the JointSeqClassifier model). TODO:\n",
    "                                 fix this. \n",
    "                           \n",
    "    Returns:\n",
    "    \n",
    "        - loss : float.\n",
    "                 The loss of this training run.\n",
    "        \n",
    "    '''\n",
    "    model_optimizer.zero_grad()\n",
    "    output = model(input_ids=input_tensor_batch.to(device),  \n",
    "                   task_ids=task_ids, \n",
    "                   labels = target_tensor_batch.to(device),\n",
    "                   output_attentions=False)\n",
    "    loss = output[0]\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train(input_tensors, target_tensors, input_val_tensors, target_val_tensors,\n",
    "          model, model_optimizer, n_epochs, task_ids):\n",
    "    '''\n",
    "    Train the classfier for a given number of epochs on the whole training set.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        - input_tensors   : list of tensors. \n",
    "                            Each entry in the list is a single batch of encoded \n",
    "                            sentence inputs and is of size (batch_size, max_length).\n",
    "        - target_tensors  : list of tensors\n",
    "                            Each tensor represents a batch of class labels.\n",
    "                            Each tensor is of size (batch_size, 1).\n",
    "        - model           : PyTorch sequence classifier model.  \n",
    "                            Assumed to be a JointSeqClassifier or \n",
    "                            DistilBertForSequenceClassification model\n",
    "        - model_optimizer : PyTorch Optimizer.\n",
    "                            The optimizer used by the model for training.\n",
    "        - n_epochs        : int.\n",
    "                            The number of epochs to train for. \n",
    "                            Each epoch is an entire pass over the data. \n",
    "        - task_ids        : list of ints.\n",
    "                            List of the indices for the tasks on which we're training. \n",
    "                            Although it is a list, currently it only works if the list \n",
    "                            is a single element (for the JointSeqClassifier model). TODO:\n",
    "                            fix this. \n",
    "                           \n",
    "    Returns:\n",
    "    \n",
    "        - loss : float.\n",
    "                 The loss of this training run.\n",
    "    '''\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    # Iterate over given num of epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = 0\n",
    "        # Iterate over batches\n",
    "        for i in tqdm.tqdm(range(len(input_tensors)), desc=\"batches progress\"):\n",
    "            input_tensor = input_tensors[i]\n",
    "            target_tensor = target_tensors[i]\n",
    "            loss += train_single(input_tensor, target_tensor, model, \n",
    "                                 model_optimizer, task_ids)\n",
    "        print(f\"Epoch {epoch} :\") \n",
    "        print(f\"\\tLoss {loss/len(input_tensors):.4f}\")\n",
    "        train_accuracy = get_accuracy(input_tensors, target_tensors, model)\n",
    "        val_accuracy = get_accuracy(input_val_tensors, target_val_tensors, model)\n",
    "        print(f\"\\tTraining Accuracy {train_accuracy:.4f}\")\n",
    "        print(f\"\\tValidation Accuracy {val_accuracy:.4f}\")\n",
    "        losses.append(loss/len(input_tensors))\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return losses, train_accs, val_accs\n",
    "\n",
    "def get_accuracy(input_tensors, target_tensors, model, task_num=0):\n",
    "    '''\n",
    "    Get model accuracy for the corresponding task. \n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        - input_tensors  : list of tensors. \n",
    "                           Each tensor represents a batch of encoded sentence inputs and is\n",
    "                           of size (batch_size, max_length).\n",
    "        - target_tensors : list of tensors\n",
    "                           Each tensor represents a batch of class labels.\n",
    "                           Each tensor is of size (batch_size, 1).\n",
    "        - model          : PyTorch sequence classifier model.  \n",
    "                           Assumed to be a JointSeqClassifier or \n",
    "                           DistilBertForSequenceClassification model\n",
    "        - task_num       : int.\n",
    "                           represents the index of the specific task we are evaluating.\n",
    "                           \n",
    "    Returns:\n",
    "    \n",
    "        - accuracy : float.\n",
    "                     Classification accuracy of the model on this data and task.\n",
    "    '''\n",
    "    accs = []\n",
    "    # Iterate over batches\n",
    "    for i in range(len(input_tensors)):\n",
    "        input_tensor_batch = input_tensors[i]\n",
    "        target_tensor_batch = target_tensors[i]\n",
    "        # Wrangle tensors into needed shapes\n",
    "        #target_tensor = torch.stack(target_tensor_batch).reshape(len(input_tensor_batch)).to(device)\n",
    "        #input_tensor = torch.stack(input_tensor_batch)\n",
    "        #input_tensor = input_tensor.reshape(len(input_tensor_batch), \n",
    "        #                                    input_tensor.shape[2]).to(device)\n",
    "        # Run the model\n",
    "        output = model(input_tensor_batch, output_attentions=False, task_ids=[task_num])\n",
    "        # Get classification prediction for the task of interest\n",
    "        preds = output.logits[task_num].argmax(axis=1)\n",
    "        # Get accuracy of given batch\n",
    "        batch_acc = ((preds == target_tensor_batch).sum() \\\n",
    "                     / target_tensor_batch.shape[0]).item()\n",
    "        # Add accuracy to list of accuracies\n",
    "        accs.append(batch_acc)\n",
    "    # Return the total accuracy, averaged over the batches\n",
    "    return np.mean(accs)\n",
    "\n",
    "def sent_pred(sent, model, tokenizer, device, batch_size):\n",
    "    '''\n",
    "    Runs the model on an input sentence.\n",
    "    \n",
    "    Arguments: \n",
    "    \n",
    "      sent  : str. \n",
    "              The input sentence.\n",
    "      model : the PyTorch sequence classifier model.  \n",
    "              Assumed to be a JointSeqClassifier or \n",
    "              DistilBertForSequenceClassification model\n",
    "    Returns:\n",
    "    \n",
    "      pred  : np array. \n",
    "              The prediction, wich is a normalized array with a value for \\\n",
    "              each class, representing the predicted probability for that class\n",
    "      attns : tuple of tensors\n",
    "              each entry in tuple is the attention matrix for an attention head.\n",
    "    '''\n",
    "    input_tensor = tokenizer.encode(sent, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output = model(input_tensor, output_attentions=True, task_ids=len(model.classifier))\n",
    "    \n",
    "    preds = []\n",
    "    scores = []\n",
    "    # Iterate over tasks and get class predition and scorews for each.\n",
    "    for i in range(model.num_tasks):\n",
    "        pred = output.logits[i].argmax(axis=1)\n",
    "    \n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        score = softmax(output.logits[i].detach())\n",
    "        \n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        scores.append(score)\n",
    "    \n",
    "    attns = output.attentions\n",
    "    \n",
    "    return preds, scores, attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stanford Politeness:\n",
    "train_polite_file = \"../../../cross_style_transfer_internal/data/xslue/StanfordPoliteness/train.tsv\"\n",
    "dev_polite_file = \"../../../cross_style_transfer_internal/data/xslue/StanfordPoliteness/dev.tsv\"\n",
    "train_polite_data = pd.read_csv(train_polite_file, names=['domain', 'id', 'text', 'score'], sep='\\t')\n",
    "val_polite_data = pd.read_csv(dev_polite_file, names=['domain', 'id', 'text', 'score'], sep='\\t')\n",
    "\n",
    "\n",
    "# Short Humor\n",
    "train_humor_file = \"../../../cross_style_transfer_internal/data/xslue/ShortHumor/train.tsv\"\n",
    "dev_humor_file = \"../../../cross_style_transfer_internal/data/xslue/ShortHumor/dev.tsv\"\n",
    "train_humor_data = pd.read_csv(train_humor_file, names=['domain', 'score', 'text'], sep='\\t', error_bad_lines=False)\n",
    "val_humor_data = pd.read_csv(dev_humor_file, names=['domain', 'score', 'text'], sep='\\t', \n",
    "                       quoting=3, error_bad_lines=False)\n",
    "\n",
    "# Dictionary for the classes for each task\n",
    "task_names = [\"Politeness\", \"Humor\"]\n",
    "class_labels_dict = [{0: \"impolite\", 1 : \"polite\"}, \n",
    "                     {0: \"humorous\", 1 : \"not humorous\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_humor(humor_df):\n",
    "    '''\n",
    "    Parse short humor dataframe into the format we need for classification.\n",
    "    \n",
    "    Returns a DataFrame with two columns, one for the input text and one for the class labels.\n",
    "    '''\n",
    "    input_df = pd.DataFrame()\n",
    "    input_df['text'] = humor_df['text']\n",
    "    input_df['label'] = humor_df['score']\n",
    "    return input_df\n",
    "\n",
    "def parse_stanford_politeness(polite_df):\n",
    "    '''\n",
    "    Parse stanford politeness dataframe into the format we need for classification.\n",
    "    \n",
    "    Returns a DataFrame with two columns, one for the input text and one for the class labels.\n",
    "    '''\n",
    "    input_df = pd.DataFrame()\n",
    "    input_df['text'] = polite_df['text']\n",
    "    # Map scores >= 0 (polite) to label 1 and scores < 0 (impolite) to label 0.\n",
    "    input_df['label'] = polite_df['score'].apply(lambda x : int(x >= 0))\n",
    "    return input_df\n",
    "\n",
    "def df_to_training_pairs(df, tokenizer, batch_size):\n",
    "    '''\n",
    "    Convert DataFrames with a 'text' and 'label' column into two lists of tensors, \n",
    "    one with texts encoded by the tokenizer and one with the class labels.\n",
    "    '''\n",
    "    input_tensors = df['text'].apply(lambda x : tokenizer.encode(x, \n",
    "                                                                 padding='max_length', \n",
    "                                                                 truncation=True, \n",
    "                                                                 return_tensors=\"pt\"))\n",
    "    target_tensors = df['label'].apply(lambda x : torch.LongTensor([x]))\n",
    "    return input_tensors.values.reshape(-1, batch_size).tolist(), target_tensors.values.reshape(-1, batch_size).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrames for tasks\n",
    "train_polite_df = parse_stanford_politeness(train_polite_data)\n",
    "val_polite_df = parse_stanford_politeness(val_polite_data)\n",
    "\n",
    "train_humor_df = parse_humor(train_humor_data)\n",
    "val_humor_df = parse_humor(val_humor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "input_polite_tensors, target_polite_tensors = df_to_training_pairs(train_polite_df.head((len(train_polite_df)//batch_size)*batch_size), \n",
    "                                                                   tokenizer, batch_size)\n",
    "input_polite_val_tensors, target_polite_val_tensors = df_to_training_pairs(val_polite_df.head((len(val_polite_df)//batch_size)*batch_size), \n",
    "                                                                  tokenizer, batch_size)\n",
    "\n",
    "input_humor_tensors, target_humor_tensors = df_to_training_pairs(train_humor_df.head((len(train_humor_df)//batch_size)*batch_size), \n",
    "                                                                   tokenizer, batch_size)\n",
    "input_humor_val_tensors, target_humor_val_tensors = df_to_training_pairs(val_humor_df.head((len(val_humor_df)//batch_size)*batch_size), \n",
    "                                                                  tokenizer, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(target_polite_tensors)):\n",
    "    input_polite_tensors[i] = torch.stack(input_polite_tensors[i])\n",
    "    input_polite_tensors[i] = input_polite_tensors[i].reshape(len(input_polite_tensors[i]), \n",
    "                                       input_polite_tensors[i].shape[2])\n",
    "    target_polite_tensors[i] = torch.LongTensor(target_polite_tensors[i])\n",
    "for i in range(len(target_polite_val_tensors)):\n",
    "    input_polite_val_tensors[i] = torch.stack(input_polite_val_tensors[i])\n",
    "    input_polite_val_tensors[i] = input_polite_val_tensors[i].reshape(len(input_polite_val_tensors[i]), \n",
    "                                       input_polite_val_tensors[i].shape[2])\n",
    "    target_polite_val_tensors[i] = torch.LongTensor(target_polite_val_tensors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(target_humor_tensors)):\n",
    "    input_humor_tensors[i] = torch.stack(input_humor_tensors[i])\n",
    "    input_humor_tensors[i] = input_humor_tensors[i].reshape(len(input_humor_tensors[i]), \n",
    "                                       input_humor_tensors[i].shape[2])\n",
    "    target_humor_tensors[i] = torch.LongTensor(target_humor_tensors[i])\n",
    "for i in range(len(target_humor_val_tensors)):\n",
    "    input_humor_val_tensors[i] = torch.stack(input_humor_val_tensors[i])\n",
    "    input_humor_val_tensors[i] = input_humor_val_tensors[i].reshape(len(input_humor_val_tensors[i]), \n",
    "                                       input_humor_val_tensors[i].shape[2])\n",
    "    target_humor_val_tensors[i] = torch.LongTensor(target_humor_val_tensors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_single(input_tensors[0], target_tensor_joint_test, model, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batches progress: 100%|██████████| 308/308 [16:29<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "\tLoss 1.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "batches progress:   0%|          | 0/1181 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Accuracy 0.5494\n",
      "\tValidation Accuracy 0.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batches progress:   7%|▋         | 77/1181 [03:57<55:41,  3.03s/it]  "
     ]
    }
   ],
   "source": [
    "train_epochs = 1\n",
    "\n",
    "train(input_polite_tensors, target_polite_tensors, \n",
    "      input_polite_val_tensors, target_polite_val_tensors, \n",
    "      model, optims[0], train_epochs, task_ids=[0])\n",
    "\n",
    "train(input_humor_tensors, target_humor_tensors, \n",
    "      input_humor_val_tensors, target_humor_val_tensors, \n",
    "      model, optims[1], train_epochs, task_ids=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Could you please help me?\"\n",
    "\n",
    "preds, scores, attns = sent_pred(sent, model, tokenizer, device, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum over attention vectors for each head and handle dimensions and move to cpu\n",
    "viz_attns = np.array([attn.sum(axis=1).cpu().detach().squeeze().numpy() for attn in attns])\n",
    "# Sum over heads\n",
    "viz_attns = viz_attns.sum(axis=0)\n",
    "# Drop cls and sep tokens\n",
    "viz_attns = viz_attns[0, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(sent))[1:-1]\n",
    "scores = [score.cpu().detach().squeeze().numpy() for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Input: ['yo', 'momma', 'is', 'so', 'fat', '!']\n",
      "\n",
      "Task: Politeness\n",
      "Style: polite\n",
      "Class Scores: polite : 86.32%, impolite : 13.68%\n",
      "\n",
      "Task: Humor\n",
      "Style: not humorous\n",
      "Class Scores: not humorous : 82.69%, humorous : 17.31%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create heatmap\n",
    "print(f\"Tokenized Input: {tokens}\\n\")\n",
    "for i, task_name in enumerate(task_names):\n",
    "    print(f\"Task: {task_name}\")\n",
    "    print(f\"Style: {class_labels_dict[i][preds[i][0]]}\")\n",
    "    print(f\"Class Scores: {class_labels_dict[i][1]} : {scores[i][1]*100:.2f}%, {class_labels_dict[i][0]} : {scores[i][0]*100:.2f}%\\n\")\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_xlabel(\"Token Position\")\n",
    "plt.imshow([viz_attns], cmap='Reds');\n",
    "plt.savefig(f'Attention_humor_and_politeness_heatmap_{\"_\".join(sent.split())}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = viz_attns\n",
    "x = np.arange(len(tokens))\n",
    "labels = tokens\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, y, 'k:')\n",
    "ax.set_ylabel(\"Attention\")\n",
    "ax.set_xlabel(\"Token Position\")\n",
    "\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (x[i], y[i]), xytext=(x[i] + 0.03, y[i] + 0.03))\n",
    "plt.savefig(f'Attention_humor_and_politeness_plot_{\"_\".join(sent.split())}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "checkpoint_path = \"../models/BERT_Joint_EarlyTest\"\n",
    "if save_model:\n",
    "    model.save_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_marvin)",
   "language": "python",
   "name": "env_marvin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
