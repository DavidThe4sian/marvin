{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextGenerationPipeline, AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class JointSeqClassifier(transformers.DistilBertForSequenceClassification):\n",
    "    '''\n",
    "    A class that inherits from DistilBertForSequenceClassification, but extends the model to \n",
    "    have multiple classifiers at the end to perform joint classification over multple tasks.\n",
    "    '''\n",
    "    def __init__(self, config, num_tasks=1):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self. num_tasks = num_tasks\n",
    "\n",
    "        self.distilbert = transformers.DistilBertModel(config)\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        # List of classifiers\n",
    "        self.classifier = nn.ModuleList([nn.Linear(config.dim, config.num_labels) \\\n",
    "                           for i in range(num_tasks)])\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        task_ids, \n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \n",
    "        task_ids (list of ints):\n",
    "            Labels indexing which classification task the labels correspond to.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
    "        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n",
    "        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        \n",
    "        logits_list = []\n",
    "        loss = 0\n",
    "        for i in range(self.num_tasks):\n",
    "            logits = self.classifier[i](pooled_output)  # (bs, num_labels)\n",
    "            logits_list.append(logits)\n",
    "            if labels != None:\n",
    "                for i in task_ids:\n",
    "                    if self.num_labels == 1:\n",
    "                        loss_fct = nn.MSELoss()\n",
    "                        loss += loss_fct(logits.view(-1), labels.view(-1))\n",
    "                    else:\n",
    "                        loss_fct = nn.CrossEntropyLoss()\n",
    "                        loss += loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits_list,) + distilbert_output[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return transformers.modeling_outputs.SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits_list,\n",
    "            hidden_states=distilbert_output.hidden_states,\n",
    "            attentions=distilbert_output.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing JointSeqClassifier: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing JointSeqClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing JointSeqClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of JointSeqClassifier were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['classifier.0.weight', 'classifier.0.bias', 'classifier.1.weight', 'classifier.1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JointSeqClassifier(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): ModuleList(\n",
       "    (0): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING JOINT MODEL\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "                                          model_max_length=64)\n",
    "\n",
    "model = JointSeqClassifier.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                                            num_tasks=2)\n",
    "\n",
    "# Try only updating final layers\n",
    "params_to_update = []\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "    if 'classifier' in name:\n",
    "        params_to_update.append(param)\n",
    "        \n",
    "optim = AdamW(params_to_update, lr=5e-5)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", model_max_length=64)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# # Try only updating final layers\n",
    "# params_to_update = []\n",
    "\n",
    "# for name,param in model.named_parameters():\n",
    "#     if 'classifier' in name:\n",
    "#         params_to_update.append(param)\n",
    "        \n",
    "# optim = AdamW(params_to_update, lr=5e-5)\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single(input_tensor_batch, target_tensor_batch, \n",
    "                 model, model_optimizer, task_ids):\n",
    "    '''\n",
    "    A single forward and backward pass of the neural net on a single training batch.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        - input_tensor_batch  : list of tensors. \n",
    "                                A batch of encoded sentence inputs and is\n",
    "                                of size (batch_size, max_length).\n",
    "        - target_tensors_batch : list of tensors\n",
    "                                 Each tensor represents a batch of class labels.\n",
    "                                 Each tensor is of size (batch_size, 1).\n",
    "        - model                : PyTorch sequence classifier model.  \n",
    "                                 Assumed to be a JointSeqClassifier or \n",
    "                                 DistilBertForSequenceClassification model\n",
    "        - model_optimizer      : PyTorch Optimizer.\n",
    "                                 The optimizer used by the model for training.\n",
    "        - task_ids             : list of ints.\n",
    "                                 List of the indices for the tasks on which we're training. \n",
    "                                 Although it is a list, currently it only works if the list \n",
    "                                 is a single element (for the JointSeqClassifier model). TODO:\n",
    "                                 fix this. \n",
    "                           \n",
    "    Returns:\n",
    "    \n",
    "        - loss : float.\n",
    "                 The loss of this training run.\n",
    "        \n",
    "    '''\n",
    "    target_tensor = torch.stack(target_tensor_batch).reshape(len(input_tensor_batch))\n",
    "    input_tensor = torch.stack(input_tensor_batch)\n",
    "    input_tensor = input_tensor.reshape(len(input_tensor_batch), \n",
    "                                        input_tensor.shape[2])\n",
    "    output = model(input_ids=input_tensor.to(device),  \n",
    "                   task_ids=task_ids, \n",
    "                   labels = target_tensor.to(device),\n",
    "                   output_attentions=False)\n",
    "    loss = output[0]\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train(input_tensors, target_tensors, input_val_tensors, target_val_tensors,\n",
    "          model, model_optimizer, n_epochs, task_ids):\n",
    "    '''\n",
    "    Train the classfier for a given number of epochs on the whole training set.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        - input_tensors   : list of tensors. \n",
    "                            Each entry in the list is a single batch of encoded \n",
    "                            sentence inputs and is of size (batch_size, max_length).\n",
    "        - target_tensors  : list of tensors\n",
    "                            Each tensor represents a batch of class labels.\n",
    "                            Each tensor is of size (batch_size, 1).\n",
    "        - model           : PyTorch sequence classifier model.  \n",
    "                            Assumed to be a JointSeqClassifier or \n",
    "                            DistilBertForSequenceClassification model\n",
    "        - model_optimizer : PyTorch Optimizer.\n",
    "                            The optimizer used by the model for training.\n",
    "        - n_epochs        : int.\n",
    "                            The number of epochs to train for. \n",
    "                            Each epoch is an entire pass over the data. \n",
    "        - task_ids        : list of ints.\n",
    "                            List of the indices for the tasks on which we're training. \n",
    "                            Although it is a list, currently it only works if the list \n",
    "                            is a single element (for the JointSeqClassifier model). TODO:\n",
    "                            fix this. \n",
    "                           \n",
    "    Returns:\n",
    "    \n",
    "        - loss : float.\n",
    "                 The loss of this training run.\n",
    "    '''\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    # Iterate over given num of epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = 0\n",
    "        # Iterate over batches\n",
    "        for i in tqdm.tqdm(range(len(input_tensors)), desc=\"batches progress\"):\n",
    "            input_tensor = input_tensors[i]\n",
    "            target_tensor = target_tensors[i]\n",
    "            loss += train_single(input_tensor, target_tensor, model, \n",
    "                                 model_optimizer, task_ids)\n",
    "        print(f\"Epoch {epoch} :\") \n",
    "        print(f\"\\tLoss {loss/len(input_tensors):.4f}\")\n",
    "        print(f\"input_tensors {input_tensors}\")\n",
    "        print(f\"target_tensors {target_tensors}\")\n",
    "        train_accuracy = get_accuracy(input_tensors, target_tensors, model)\n",
    "        val_accuracy = get_accuracy(input_val_tensors, target_val_tensors, model)\n",
    "        print(f\"\\tTraining Accuracy {train_accuracy:.4f}\")\n",
    "        print(f\"\\tValidation Accuracy {val_accuracy:.4f}\")\n",
    "        losses.append(loss/len(input_tensors))\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return losses, train_accs, val_accs\n",
    "\n",
    "def get_accuracy(input_tensors, target_tensors, model, task_num=0):\n",
    "    '''\n",
    "    Get model accuracy for the corresponding task. \n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        - input_tensors  : list of tensors. \n",
    "                           Each tensor represents a batch of encoded sentence inputs and is\n",
    "                           of size (batch_size, max_length).\n",
    "        - target_tensors : list of tensors\n",
    "                           Each tensor represents a batch of class labels.\n",
    "                           Each tensor is of size (batch_size, 1).\n",
    "        - model          : PyTorch sequence classifier model.  \n",
    "                           Assumed to be a JointSeqClassifier or \n",
    "                           DistilBertForSequenceClassification model\n",
    "        - task_num       : int.\n",
    "                           represents the index of the specific task we are evaluating.\n",
    "                           \n",
    "    Returns:\n",
    "    \n",
    "        - accuracy : float.\n",
    "                     Classification accuracy of the model on this data and task.\n",
    "    '''\n",
    "    accs = []\n",
    "    # Iterate over batches\n",
    "    for i in range(len(input_tensors)):\n",
    "        input_tensor_batch = input_tensors[i]\n",
    "        target_tensor_batch = target_tensors[i]\n",
    "        # Wrangle tensors into needed shapes\n",
    "        target_tensor = torch.stack(target_tensor_batch).reshape(len(input_tensor_batch)).to(device)\n",
    "        input_tensor = torch.stack(input_tensor_batch)\n",
    "        input_tensor = input_tensor.reshape(len(input_tensor_batch), \n",
    "                                            input_tensor.shape[2]).to(device)\n",
    "        # Run the model\n",
    "        output = model(input_tensor, output_attentions=False, task_ids=[task_num])\n",
    "        # Get classification prediction for the task of interest\n",
    "        preds = output.logits[task_num].argmax(axis=1)\n",
    "        # Get accuracy of given batch\n",
    "        batch_acc = ((preds == target_tensor[task_num]).sum()/target_tensor[task_num].shape[0]).item()\n",
    "        # Add accuracy to list of accuracies\n",
    "        accs.append(batch_acc)\n",
    "    # Return the total accuracy, averaged over the batches\n",
    "    return np.mean(accs)\n",
    "\n",
    "def sent_pred(sent, model, tokenizer, device, batch_size):\n",
    "    '''\n",
    "    Runs the model on an input sentence.\n",
    "    \n",
    "    Arguments: \n",
    "    \n",
    "      sent  : str. \n",
    "              The input sentence.\n",
    "      model : the PyTorch sequence classifier model.  \n",
    "              Assumed to be a JointSeqClassifier or \n",
    "              DistilBertForSequenceClassification model\n",
    "    Returns:\n",
    "    \n",
    "      pred  : np array. \n",
    "              The prediction, wich is a normalized array with a value for \\\n",
    "              each class, representing the predicted probability for that class\n",
    "      attns : tuple of tensors\n",
    "              each entry in tuple is the attention matrix for an attention head.\n",
    "    '''\n",
    "    input_tensor = tokenizer.encode(sent, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output = model(input_tensor, output_attentions=True, task_ids=len(model.classifier))\n",
    "    \n",
    "    preds = []\n",
    "    scores = []\n",
    "    # Iterate over tasks and get class predition and scorews for each.\n",
    "    for i in range(model.num_tasks):\n",
    "        pred = output.logits[i].argmax(axis=1)\n",
    "    \n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        score = softmax(output.logits[i].detach())\n",
    "        \n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        scores.append(score)\n",
    "    \n",
    "    attns = output.attentions\n",
    "    \n",
    "    return preds, scores, attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stanford Politeness:\n",
    "train_polite_file = \"../../../cross_style_transfer_internal/data/xslue/StanfordPoliteness/train.tsv\"\n",
    "dev_polite_file = \"../../../cross_style_transfer_internal/data/xslue/StanfordPoliteness/dev.tsv\"\n",
    "train_polite_data = pd.read_csv(train_polite_file, names=['domain', 'id', 'text', 'score'], sep='\\t')\n",
    "val_polite_data = pd.read_csv(dev_polite_file, names=['domain', 'id', 'text', 'score'], sep='\\t')\n",
    "\n",
    "\n",
    "# Short Humor\n",
    "train_humor_file = \"../../../cross_style_transfer_internal/data/xslue/ShortHumor/train.tsv\"\n",
    "dev_humor_file = \"../../../cross_style_transfer_internal/data/xslue/ShortHumor/dev.tsv\"\n",
    "train_humor_data = pd.read_csv(train_humor_file, names=['domain', 'score', 'text'], sep='\\t', error_bad_lines=False)\n",
    "val_humor_data = pd.read_csv(dev_humor_file, names=['domain', 'score', 'text'], sep='\\t', \n",
    "                       quoting=3, error_bad_lines=False)\n",
    "\n",
    "# Dictionary for the classes for each task\n",
    "task_names = [\"Politeness\", \"Humor\"]\n",
    "class_labels_dict = [{0: \"impolite\", 1 : \"polite\"}, \n",
    "                     {0: \"humorous\", 1 : \"not humorous\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_humor(humor_df):\n",
    "    '''\n",
    "    Parse short humor dataframe into the format we need for classification.\n",
    "    \n",
    "    Returns a DataFrame with two columns, one for the input text and one for the class labels.\n",
    "    '''\n",
    "    input_df = pd.DataFrame()\n",
    "    input_df['text'] = humor_df['text']\n",
    "    input_df['label'] = humor_df['score']\n",
    "    return input_df\n",
    "\n",
    "def parse_stanford_politeness(polite_df):\n",
    "    '''\n",
    "    Parse stanford politeness dataframe into the format we need for classification.\n",
    "    \n",
    "    Returns a DataFrame with two columns, one for the input text and one for the class labels.\n",
    "    '''\n",
    "    input_df = pd.DataFrame()\n",
    "    input_df['text'] = polite_df['text']\n",
    "    # Map scores >= 0 (polite) to label 1 and scores < 0 (impolite) to label 0.\n",
    "    input_df['label'] = polite_df['score'].apply(lambda x : int(x >= 0))\n",
    "    return input_df\n",
    "\n",
    "def df_to_training_pairs(df, tokenizer, batch_size):\n",
    "    '''\n",
    "    Convert DataFrames with a 'text' and 'label' column into two lists of tensors, \n",
    "    one with texts encoded by the tokenizer and one with the class labels.\n",
    "    '''\n",
    "    input_tensors = df['text'].apply(lambda x : tokenizer.encode(x, \n",
    "                                                                 padding='max_length', \n",
    "                                                                 truncation=True, \n",
    "                                                                 return_tensors=\"pt\"))\n",
    "    target_tensors = df['label'].apply(lambda x : torch.LongTensor([x]))\n",
    "    return input_tensors.values.reshape(-1, batch_size).tolist(), target_tensors.values.reshape(-1, batch_size).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrames for tasks\n",
    "train_polite_df = parse_stanford_politeness(train_polite_data)\n",
    "val_polite_df = parse_stanford_politeness(val_polite_data)\n",
    "\n",
    "train_humor_df = parse_humor(train_humor_data)\n",
    "val_humor_df = parse_humor(val_humor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "input_polite_tensors, target_polite_tensors = df_to_training_pairs(train_polite_df.head((len(train_polite_df)//batch_size)*batch_size), \n",
    "                                                                   tokenizer, batch_size)\n",
    "input_polite_val_tensors, target_polite_val_tensors = df_to_training_pairs(val_polite_df.head((len(val_polite_df)//batch_size)*batch_size), \n",
    "                                                                  tokenizer, batch_size)\n",
    "\n",
    "input_humor_tensors, target_humor_tensors = df_to_training_pairs(train_humor_df.head((len(train_humor_df)//batch_size)*batch_size), \n",
    "                                                                   tokenizer, batch_size)\n",
    "input_humor_val_tensors, target_humor_val_tensors = df_to_training_pairs(val_humor_df.head((len(val_humor_df)//batch_size)*batch_size), \n",
    "                                                                  tokenizer, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(target_polite_tensors)):\n",
    "    target_polite_tensors[i] = [torch.LongTensor(target_polite_tensors[i])]\n",
    "for i in range(len(target_polite_val_tensors)):\n",
    "    target_polite_val_tensors[i] = [torch.LongTensor(target_polite_val_tensors[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(target_humor_tensors)):\n",
    "    target_humor_tensors[i] = [torch.LongTensor(target_humor_tensors[i])]\n",
    "for i in range(len(target_humor_val_tensors)):\n",
    "    target_humor_val_tensors[i] = [torch.LongTensor(target_humor_val_tensors[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_single(input_tensors[0], target_tensor_joint_test, model, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batches progress:  38%|███▊      | 454/1181 [23:09<37:04,  3.06s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-e1354800540c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train(input_humor_tensors, target_humor_tensors, \n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0minput_humor_val_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_humor_val_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       model, optim, train_epochs, task_ids=[1])\n",
      "\u001b[0;32m<ipython-input-105-3203c23b7204>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensors, target_tensors, input_val_tensors, target_val_tensors, model, model_optimizer, n_epochs, task_ids)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             loss += train_single(input_tensor, target_tensor, model, \n\u001b[0m\u001b[1;32m     35\u001b[0m                                  model_optimizer, task_ids)\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch} :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-3203c23b7204>\u001b[0m in \u001b[0;36mtrain_single\u001b[0;34m(input_tensor_batch, target_tensor_batch, model, model_optimizer, task_ids)\u001b[0m\n\u001b[1;32m     13\u001b[0m                    output_attentions=False)\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epochs = 3\n",
    "\n",
    "train(input_humor_tensors, target_humor_tensors, \n",
    "      input_humor_val_tensors, target_humor_val_tensors, \n",
    "      model, optim, train_epochs, task_ids=[1])\n",
    "\n",
    "train(input_polite_tensors, target_polite_tensors, \n",
    "      input_polite_val_tensors, target_polite_val_tensors, \n",
    "      model, optim, train_epochs, task_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Are you stupid?\"\n",
    "\n",
    "preds, scores, attns = sent_pred(sent, model, tokenizer, device, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.7889, 0.2111]]), tensor([[0.8382, 0.1618]])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 6, 6])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum over attention vectors for each head and handle dimensions and move to cpu\n",
    "viz_attns = np.array([attn.sum(axis=1).cpu().detach().squeeze().numpy() for attn in attns])\n",
    "# Sum over heads\n",
    "viz_attns = viz_attns.sum(axis=0)\n",
    "# Drop cls and sep tokens\n",
    "viz_attns = viz_attns[0, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_attns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(sent))[1:-1]\n",
    "scores = [score.cpu().detach().squeeze().numpy() for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'impolite', 1: 'polite'}, {0: 'humorous', 1: 'not humorous'}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Input: ['are', 'you', 'stupid', '?']\n",
      "\n",
      "Task: Politeness\n",
      "Style: impolite\n",
      "Class Scores: polite : 21.11%, impolite : 78.89%\n",
      "\n",
      "Task: Humor\n",
      "Style: humorous\n",
      "Class Scores: not humorous : 16.18%, humorous : 83.82%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create heatmap\n",
    "print(f\"Tokenized Input: {tokens}\\n\")\n",
    "for i, task_name in enumerate(task_names):\n",
    "    print(f\"Task: {task_name}\")\n",
    "    print(f\"Style: {class_labels_dict[i][preds[i][0]]}\")\n",
    "    print(f\"Class Scores: {class_labels_dict[i][1]} : {scores[i][1]*100:.2f}%, {class_labels_dict[i][0]} : {scores[i][0]*100:.2f}%\\n\")\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_xlabel(\"Token Position\")\n",
    "plt.imshow([viz_attns], cmap='Reds');\n",
    "plt.savefig(f'Attention_humor_heatmap_{\"_\".join(sent.split())}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = viz_attns\n",
    "x = np.arange(len(tokens))\n",
    "labels = tokens\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, y, 'k:')\n",
    "ax.set_ylabel(\"Attention\")\n",
    "ax.set_xlabel(\"Token Position\")\n",
    "\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (x[i], y[i]), xytext=(x[i] + 0.03, y[i] + 0.03))\n",
    "plt.savefig(f'Attention_humor_plot_{\"_\".join(sent.split())}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "checkpoint_path = \"../models/BERT_Joint_EarlyTest\"\n",
    "if save_model:\n",
    "    model.save_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_marvin)",
   "language": "python",
   "name": "env_marvin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
