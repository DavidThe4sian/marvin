{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Standard Python Data Science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partly taken from https://github.com/prakashpandey9/Text-Classification-Pytorch\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
    "        output_size : 2 = (pos, neg)\n",
    "        hidden_sie : Size of the hidden_state of the LSTM\n",
    "        vocab_size : Size of the vocabulary containing unique words\n",
    "        embedding_length : Embeddding dimension of GloVe word embeddings\n",
    "        weights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
    "        \n",
    "        --------\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "        self.weights = weights\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\n",
    "        self.dropout = 0.8\n",
    "        self.bilstm = nn.LSTM(embedding_length, hidden_size, dropout=self.dropout, bidirectional=True)\n",
    "        # We will use da = 350, r = 30 & penalization_coeff = 1 \n",
    "        # as per given in the self-attention original ICLR paper\n",
    "        self.W_s1 = nn.Linear(2*hidden_size, 350)\n",
    "        self.W_s2 = nn.Linear(350, 30)\n",
    "        self.fc_layer = nn.Linear(30*2*hidden_size, 2000)\n",
    "        self.label = nn.Linear(2000, output_size)\n",
    "\n",
    "    def attention_net(self, lstm_output):\n",
    "\n",
    "        \"\"\"\n",
    "        Now we will use self attention mechanism to produce a matrix \n",
    "        embedding of the input sentence in which every row represents an\n",
    "        encoding of the input sentence but giving an attention to a \n",
    "        specific part of the sentence. We will use 30 such embedding of \n",
    "        the input sentence and then finally we will concatenate all the 30 \n",
    "        sentence embedding vectors and connect it to a fully connected layer \n",
    "        of size 2000 which will be connected to the output layer of size 2 \n",
    "        returning logits for our two classes i.e., pos & neg.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        lstm_output = A tensor containing hidden states corresponding to each time step of the LSTM network.\n",
    "        ---------\n",
    "        Returns : Final Attention weight matrix for all the 30 different sentence embedding in which each of 30 embeddings give\n",
    "                  attention to different parts of the input sentence.\n",
    "        Tensor size : lstm_output.size() = (batch_size, num_seq, 2*hidden_size)\n",
    "                      attn_weight_matrix.size() = (batch_size, 30, num_seq)\n",
    "        \"\"\"\n",
    "        attn_weight_matrix = self.W_s2(F.tanh(self.W_s1(lstm_output)))\n",
    "        attn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n",
    "        attn_weight_matrix = F.softmax(attn_weight_matrix, dim=2)\n",
    "\n",
    "        return attn_weight_matrix\n",
    "\n",
    "    def forward(self, input_sentences, batch_size=None, return_attn=False):\n",
    "\n",
    "        \"\"\" \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_sentence: input_sentence of shape = (batch_size, num_sequences)\n",
    "        batch_size : default = None. \n",
    "        Used only for prediction on a single sentence after training (batch_size = 1)\n",
    "        return_attn : bool determining whether to return attention layer activation \n",
    "                      default = False\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Output of the linear layer containing logits for pos & neg class.\n",
    "        Attention layer if the return_attn is set\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        input = self.word_embeddings(input_sentences)\n",
    "        input = input.permute(1, 0, 2)\n",
    "        if batch_size is None:\n",
    "            h_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(2, self.batch_size, self.hidden_size).cuda())\n",
    "        else:\n",
    "            h_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(2, batch_size, self.hidden_size).cuda())\n",
    "\n",
    "        output, (h_n, c_n) = self.bilstm(input, (h_0, c_0))\n",
    "        output = output.permute(1, 0, 2)\n",
    "        # output.size() = (batch_size, num_seq, 2*hidden_size)\n",
    "        # h_n.size() = (1, batch_size, hidden_size)\n",
    "        # c_n.size() = (1, batch_size, hidden_size)\n",
    "        attn_weight_matrix = self.attention_net(output)\n",
    "        # attn_weight_matrix.size() = (batch_size, r, num_seq)\n",
    "        # output.size() = (batch_size, num_seq, 2*hidden_size)\n",
    "        hidden_matrix = torch.bmm(attn_weight_matrix, output)\n",
    "        # hidden_matrix.size() = (batch_size, r, 2*hidden_size)\n",
    "        # Let's now concatenate the hidden_matrix and connect it to the fully connected layer.\n",
    "        fc_out = self.fc_layer(hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2]))\n",
    "        logits = self.label(fc_out)\n",
    "        # logits.size() = (batch_size, output_size)\n",
    "        if not return_attn:\n",
    "            return logits\n",
    "        else:\n",
    "            return logits, attn_weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(filename, vocab_size=10000, compute_avg=True):\n",
    "    \"\"\"\n",
    "    Utility function, loads in the `vocab_size` most common embeddings from `filename`\n",
    "  \n",
    "    Arguments:\n",
    "      - filename:     path to file\n",
    "                      automatically infers correct embedding dimension from filename\n",
    "      - vocab_size:   maximum number of embeddings to load\n",
    "      - compute_avg:  bool to decide whether to comnpute the average word embedding,\n",
    "                      which can be used as a <unk> embedding\n",
    "\n",
    "      Returns \n",
    "      - embeddings:   torch.FloatTensor matrix of size (vocab_size x word_embedding_dim)\n",
    "      - vocab:        dictionary mapping word (str) to index (int) in embedding matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # get the embedding size from the first embedding\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        word_embedding_dim = len(file.readline().split(\" \")) - 1\n",
    "\n",
    "    vocab = {}\n",
    "    inv_vocab = {}\n",
    "    \n",
    "    if compute_avg:\n",
    "        # Add extra embedding for <unk> and <pad>\n",
    "        # last index is <unk>, first index is <pad>\n",
    "        embeddings = np.zeros((vocab_size + 2, word_embedding_dim))\n",
    "    else:\n",
    "         # Only add extra embedding for <pad>\n",
    "         # first index is <pad>\n",
    "        embeddings = np.zeros((vocab_size + 1, word_embedding_dim))\n",
    "        \n",
    "\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for idx, line in enumerate(file):\n",
    "\n",
    "            if idx >= vocab_size:\n",
    "                break\n",
    "            \n",
    "            cols = line.rstrip().split(\" \")\n",
    "            val = np.array(cols[1:])\n",
    "            word = cols[0]\n",
    "            embeddings[idx + 1] = val\n",
    "            vocab[word] = idx + 1\n",
    "            inv_vocab[idx + 1] = word\n",
    "    \n",
    "    # Set <unk> embedding to the average of all other embedding vects in vocab\n",
    "    if compute_avg:\n",
    "        embeddings[-1] = embeddings[:-1].mean(axis=0)\n",
    "    \n",
    "    return torch.FloatTensor(embeddings), vocab, inv_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_embedd(sent, model, vocab_dict, tokenizer, max_length, unk_embedd=True):\n",
    "    '''\n",
    "    Helper function to extract the embedding for an input sentence.\n",
    "    '''\n",
    "    idxs = [0 for i in range(max_length)]\n",
    "    i = 0\n",
    "    for word in tokenizer(sent):\n",
    "        if i < max_length:\n",
    "            if word in vocab_dict:\n",
    "                idxs[i] = vocab_dict[word]\n",
    "            else:\n",
    "                # If using <unk> embedding, append \n",
    "                # the final index where that embedding is stored\n",
    "                if unk_embedd:\n",
    "                    idxs[i] = len(vocab_dict)\n",
    "            i += 1\n",
    "    return torch.LongTensor([idxs]).to(device)\n",
    "            \n",
    "def sent_pred(sent, model, vocab_dict, max_length):\n",
    "    '''\n",
    "    Runs the model on an input sentence.\n",
    "    \n",
    "    Arguments: \n",
    "    \n",
    "      sent : str. The input sentence.\n",
    "      model : the pytorch model to be used.\n",
    "      vocab_dict : dict. A dictionary with words as keys and their indices as values\n",
    "     \n",
    "    Returns:\n",
    "      pred : np array. The prediction, wich is a normalized array with a value for \\\n",
    "             each class, representing the predicted probability for that class\n",
    "      attns : the attention matrix\n",
    "    '''\n",
    "    input_tensor = sent_embedd(sent, model, vocab_dict, max_length)\n",
    "    pred, attns = model(input_tensor, return_attn=True)\n",
    "    return pred.detach().cpu().numpy(), attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single(input_tensor_batch, target_tensor_batch, model, \n",
    "          model_optimizer, criterion):\n",
    "    '''\n",
    "    A single forward and backward pass of the neural net on a single training batch.\n",
    "    '''\n",
    "    target_tensor = torch.stack(target_tensor_batch).reshape(len(input_tensor_batch))\n",
    "    input_tensor = torch.stack(input_tensor_batch)\n",
    "    input_tensor = input_tensor.reshape(len(input_tensor_batch), input_tensor.shape[2])\n",
    "    output = model(input_tensor, return_attn=False)\n",
    "    loss = criterion(output, target_tensor)\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train(input_tensors, target_tensors, input_val_tensors, target_val_tensors,\n",
    "          model, model_optimizer, criterion, n_epochs):\n",
    "    '''\n",
    "    Train the attention classfier for a given number of epochs on the whole training set.\n",
    "    '''\n",
    "    losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    # Iterate over given num of epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = 0\n",
    "        # Iterate over batches\n",
    "        for i in range(len(input_tensors)):\n",
    "            input_tensor = input_tensors[i]\n",
    "            target_tensor = target_tensors[i]\n",
    "            loss += train_single(input_tensor, target_tensor, model, \n",
    "                                 model_optimizer, criterion)\n",
    "        train_accuracy = get_accuracy(input_tensors, target_tensors, model)\n",
    "        val_accuracy = get_accuracy(input_val_tensors, target_val_tensors, model)\n",
    "        print(f\"Epoch {epoch} :\") \n",
    "        print(f\"\\tLoss {loss/len(input_tensors):.4f}\")\n",
    "        print(f\"\\tTraining Accuracy {train_accuracy:.4f}\")\n",
    "        print(f\"\\tValidation Accuracy {val_accuracy:.4f}\")\n",
    "        losses.append(loss/len(input_tensors))\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return losses, train_accs, val_accs\n",
    "\n",
    "def get_accuracy(input_tensors, target_tensors, model):\n",
    "    '''\n",
    "    Get model accuracy.\n",
    "    '''\n",
    "    accs = []\n",
    "    # Iterate over batches\n",
    "    for i in range(len(input_tensors)):\n",
    "        input_tensor_batch = input_tensors[i]\n",
    "        target_tensor_batch = target_tensors[i]\n",
    "        target_tensor = torch.stack(target_tensor_batch).reshape(len(input_tensor_batch))\n",
    "        input_tensor = torch.stack(input_tensor_batch)\n",
    "        input_tensor = input_tensor.reshape(len(input_tensor_batch), input_tensor.shape[2])\n",
    "        output = model(input_tensor, return_attn=False)\n",
    "        # Get classification prediction\n",
    "        preds = output.argmax(axis=1)\n",
    "        # Get accuracy of given batch\n",
    "        batch_acc = ((preds == target_tensor).sum()/target_tensor.shape[0]).item()\n",
    "        accs.append(batch_acc)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_embedd = True # Bool for whether to create an embedding for the <unk> token\n",
    "# Get initial word vector embedings from disk\n",
    "glove_filename = './GloveEmbeddings/glove.6B.100d.txt' \n",
    "glove_embeddings, vocab_dict, inv_vocab_dict = read_embeddings(glove_filename, \n",
    "                                                               vocab_size=100000,\n",
    "                                                               compute_avg=unk_embedd)\n",
    "# Create tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmac/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelfAttention(\n",
       "  (word_embeddings): Embedding(100002, 100)\n",
       "  (bilstm): LSTM(100, 100, dropout=0.8, bidirectional=True)\n",
       "  (W_s1): Linear(in_features=200, out_features=350, bias=True)\n",
       "  (W_s2): Linear(in_features=350, out_features=30, bias=True)\n",
       "  (fc_layer): Linear(in_features=6000, out_features=2000, bias=True)\n",
       "  (label): Linear(in_features=2000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set dimensions and hyperparameters\n",
    "batch_size = 16\n",
    "output_size = 2\n",
    "hidden_size = 100\n",
    "vocab_size = glove_embeddings.shape[0]\n",
    "embedding_length = glove_embeddings.shape[1]\n",
    "learning_rate = 5e-5\n",
    "max_length = 40 # max sentence length (in tokens)\n",
    "# Initialize embedding weights\n",
    "weights = glove_embeddings\n",
    "# Create model\n",
    "model = SelfAttention(batch_size, output_size, hidden_size, vocab_size, \n",
    "                      embedding_length, weights)\n",
    "#Define model optimizer\n",
    "model_optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# Use cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred, attns = sent_pred('the world is red', model, vocab_dict)\n",
    "# print(pred)\n",
    "# print(attns.sum(axis=1).reshape(attns.shape[2]).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../cross_style_transfer_internal/data/xslue/StanfordPoliteness/train.tsv\"\n",
    "dev_file = \"../cross_style_transfer_internal/data/xslue/StanfordPoliteness/dev.tsv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file, names=['domain', 'id', 'text', 'score'], sep='\\t')\n",
    "val_data = pd.read_csv(dev_file, names=['domain', 'id', 'text', 'score'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stanford_politeness(polite_df):\n",
    "    '''\n",
    "    Parse stanford politeness dataframe into the format we need for classification.\n",
    "    '''\n",
    "    input_df = pd.DataFrame()\n",
    "    input_df['text'] = polite_df['text']\n",
    "    # Map scores >= 0 (polite) to label 1 and scores < 0 (impolite) to label 0.\n",
    "    input_df['label'] = polite_df['score'].apply(lambda x : int(x >= 0))\n",
    "    return input_df\n",
    "\n",
    "def df_to_training_pairs(df, batch_size, max_length):\n",
    "    input_tensors = df['text'].apply(lambda x : sent_embedd(x, model, vocab_dict, tokenizer, max_length))\n",
    "    target_tensors = df['label'].apply(lambda x : torch.LongTensor([x]).to(device))\n",
    "    return input_tensors.values.reshape(-1, batch_size).tolist(), target_tensors.values.reshape(-1, batch_size).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = parse_stanford_politeness(train_data)\n",
    "val_df = parse_stanford_politeness(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where did you learn English? How come you're t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks very much for your edit to the &lt;url&gt; ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sir i think u hav many friends on wiki who can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't find it.  Maybe I didn't manage to gue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't spend too much time, and I'm no specia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Where did you learn English? How come you're t...      0\n",
       "1  Thanks very much for your edit to the <url> ar...      1\n",
       "2  Sir i think u hav many friends on wiki who can...      0\n",
       "3  I can't find it.  Maybe I didn't manage to gue...      1\n",
       "4  I can't spend too much time, and I'm no specia...      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a single pass on a single input\n",
    "\n",
    "# sent = input_df['text'].iloc[0]\n",
    "# target_tensor = torch.LongTensor([input_df['label'].iloc[0]]).to(device)\n",
    "# input_tensor = sent_embedd(sent, model, vocab_dict)\n",
    "# train_single(input_tensor, target_tensor, model, \n",
    "#           model_optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensors, target_tensors = df_to_training_pairs(train_df.head((len(train_df)//batch_size)*batch_size), \n",
    "                                                                   batch_size, max_length)\n",
    "\n",
    "input_val_tensors, target_val_tensors = df_to_training_pairs(val_df.head((len(val_df)//batch_size)*batch_size), \n",
    "                                                                   batch_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmac/.local/lib/python3.8/site-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "\tLoss 0.6881\n",
      "\tTraining Accuracy 0.5755\n",
      "\tValidation Accuracy 0.5739\n",
      "Epoch 1 :\n",
      "\tLoss 0.6943\n",
      "\tTraining Accuracy 0.5509\n",
      "\tValidation Accuracy 0.5568\n",
      "Epoch 2 :\n",
      "\tLoss 0.7038\n",
      "\tTraining Accuracy 0.5496\n",
      "\tValidation Accuracy 0.5587\n",
      "Epoch 3 :\n",
      "\tLoss 0.7067\n",
      "\tTraining Accuracy 0.5580\n",
      "\tValidation Accuracy 0.5625\n",
      "Epoch 4 :\n",
      "\tLoss 0.7025\n",
      "\tTraining Accuracy 0.5680\n",
      "\tValidation Accuracy 0.5720\n",
      "Epoch 5 :\n",
      "\tLoss 0.7057\n",
      "\tTraining Accuracy 0.5231\n",
      "\tValidation Accuracy 0.5133\n",
      "Epoch 6 :\n",
      "\tLoss 0.7202\n",
      "\tTraining Accuracy 0.5632\n",
      "\tValidation Accuracy 0.5492\n",
      "Epoch 7 :\n",
      "\tLoss 0.6900\n",
      "\tTraining Accuracy 0.5841\n",
      "\tValidation Accuracy 0.5436\n",
      "Epoch 8 :\n",
      "\tLoss 0.6641\n",
      "\tTraining Accuracy 0.5872\n",
      "\tValidation Accuracy 0.5644\n",
      "Epoch 9 :\n",
      "\tLoss 0.6656\n",
      "\tTraining Accuracy 0.6279\n",
      "\tValidation Accuracy 0.5928\n",
      "Epoch 10 :\n",
      "\tLoss 0.6803\n",
      "\tTraining Accuracy 0.6133\n",
      "\tValidation Accuracy 0.5947\n",
      "Epoch 11 :\n",
      "\tLoss 0.6654\n",
      "\tTraining Accuracy 0.6439\n",
      "\tValidation Accuracy 0.6023\n",
      "Epoch 12 :\n",
      "\tLoss 0.6298\n",
      "\tTraining Accuracy 0.6420\n",
      "\tValidation Accuracy 0.6174\n",
      "Epoch 13 :\n",
      "\tLoss 0.6556\n",
      "\tTraining Accuracy 0.5881\n",
      "\tValidation Accuracy 0.5492\n",
      "Epoch 14 :\n",
      "\tLoss 0.6117\n",
      "\tTraining Accuracy 0.6815\n",
      "\tValidation Accuracy 0.6212\n",
      "Epoch 15 :\n",
      "\tLoss 0.6397\n",
      "\tTraining Accuracy 0.6519\n",
      "\tValidation Accuracy 0.6080\n",
      "Epoch 16 :\n",
      "\tLoss 0.6765\n",
      "\tTraining Accuracy 0.6291\n",
      "\tValidation Accuracy 0.5871\n",
      "Epoch 17 :\n",
      "\tLoss 0.6620\n",
      "\tTraining Accuracy 0.6751\n",
      "\tValidation Accuracy 0.5795\n",
      "Epoch 18 :\n",
      "\tLoss 0.6014\n",
      "\tTraining Accuracy 0.6432\n",
      "\tValidation Accuracy 0.5682\n",
      "Epoch 19 :\n",
      "\tLoss 0.5936\n",
      "\tTraining Accuracy 0.6921\n",
      "\tValidation Accuracy 0.6136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6881055099430022,\n",
       "  0.6943177017685654,\n",
       "  0.7038455501005247,\n",
       "  0.7066699025015553,\n",
       "  0.7025346806297055,\n",
       "  0.7057447461048504,\n",
       "  0.7202064522675106,\n",
       "  0.6899715457837303,\n",
       "  0.6641012302466801,\n",
       "  0.6655831758368325,\n",
       "  0.6803252941795758,\n",
       "  0.6654025166259183,\n",
       "  0.629844592279428,\n",
       "  0.6555914195714059,\n",
       "  0.6116804084801054,\n",
       "  0.6397476038085176,\n",
       "  0.6764576588454959,\n",
       "  0.6620258017406835,\n",
       "  0.6014392430615889,\n",
       "  0.5935664949091998],\n",
       " [0.575487012987013,\n",
       "  0.5509334415584416,\n",
       "  0.549614448051948,\n",
       "  0.5580357142857143,\n",
       "  0.5679788961038961,\n",
       "  0.5231331168831169,\n",
       "  0.5632102272727273,\n",
       "  0.5841112012987013,\n",
       "  0.5871550324675324,\n",
       "  0.6279423701298701,\n",
       "  0.6133319805194806,\n",
       "  0.6438717532467533,\n",
       "  0.6420454545454546,\n",
       "  0.5880681818181818,\n",
       "  0.6815137987012987,\n",
       "  0.6518871753246753,\n",
       "  0.6290584415584416,\n",
       "  0.6751217532467533,\n",
       "  0.643161525974026,\n",
       "  0.6920657467532467],\n",
       " [0.5738636363636364,\n",
       "  0.5568181818181818,\n",
       "  0.5587121212121212,\n",
       "  0.5625,\n",
       "  0.571969696969697,\n",
       "  0.5132575757575758,\n",
       "  0.5492424242424242,\n",
       "  0.5435606060606061,\n",
       "  0.5643939393939394,\n",
       "  0.5928030303030303,\n",
       "  0.5946969696969697,\n",
       "  0.6022727272727273,\n",
       "  0.6174242424242424,\n",
       "  0.5492424242424242,\n",
       "  0.6212121212121212,\n",
       "  0.6079545454545454,\n",
       "  0.5871212121212122,\n",
       "  0.5795454545454546,\n",
       "  0.5681818181818182,\n",
       "  0.6136363636363636])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(input_tensors, target_tensors, input_val_tensors, target_val_tensors, \n",
    "      model, model_optimizer, criterion, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- [X] handle unk words better\n",
    "    - currently initalizing to the average of all word embeddings like suggested [here](https://stackoverflow.com/questions/49239941/what-is-unk-in-the-pretrained-glove-vector-files-e-g-glove-6b-50d-txt)\n",
    "- [X] make work with batches\n",
    "- [ ] use different, better embeddings\n",
    "- [X] use better tokenizer, like spacy or some huggingface transformer model\n",
    "- [ ] train and save a good model\n",
    "- [ ] visualize attentions\n",
    "- [ ] make work with other datasets\n",
    "- [ ] convert to .py script that runs with input file that determines which data and parameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_batch = input_tensors[0]\n",
    "target_tensor_batch = target_tensors[0]\n",
    "target_tensor = torch.stack(target_tensor_batch).reshape(len(input_tensor_batch))\n",
    "input_tensor = torch.stack(input_tensor_batch)\n",
    "input_tensor = input_tensor.reshape(len(input_tensor_batch), input_tensor.shape[2])\n",
    "output, attention = model(input_tensor, return_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Where did you learn English? How come you're taking on a third language?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 112,  120,   82, 2369,  712,  189,  198,  327,   82,   58, 1766,  583,\n",
       "           14,    8,  246, 1033,  189,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0874, 0.1752, 0.4235, 0.0182, 0.0019, 0.0175, 0.4379, 0.0640, 0.4176,\n",
       "        0.8864, 1.1952, 0.1029, 1.2384, 0.0171, 1.1456, 0.3960, 0.0279, 1.0153,\n",
       "        1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151,\n",
       "        1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151, 1.0151,\n",
       "        1.0151, 1.0151, 1.0151, 1.0151], device='cuda:0',\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_df['text'].iloc[0])[attention[0].sum(axis=0).argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe820d1bee0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow([attention[0].sum(axis=0).cpu().detach().numpy()], cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30, 40])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_df['text'].iloc[0])[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
