{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generate Some Transfered Sentences and get Style Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys, os\n",
    "import numpy as np\n",
    "import torch\n",
    "sys.path.append('../paraphrase/')\n",
    "sys.path.append('../jointclassifier/')\n",
    "from paraphraser_args import ModelArguments as pma, DataTrainingArguments as pda, TrainingArguments as pta\n",
    "from paraphraser_dataloader import load_dataset as pld, load_dataset_style as lds\n",
    "from paraphraser_dataloader import load_dataset_pseudo as ldp, load_dataset_pseudo_binary_single as ldpb\n",
    "from paraphraser_dataloader import load_dataset_pseudo_joint as ldpj\n",
    "from paraphraser_trainer import ParaphraserTrainer\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelWithLMHead, HfArgumentParser\n",
    "from joint_args import ModelArguments as jma, DataTrainingArguments as jda, TrainingArguments as jta\n",
    "from joint_dataloader import load_dataset as jld\n",
    "from joint_trainer import JointTrainer\n",
    "from joint_model_v1 import JointSeqClassifier\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch import cuda, no_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in desired dataset and paraphraser model\n",
    "In the cell below, define the dataset you want to work with and the paraphraser model (here a `\"t5-small\"` [from Hugging Face](https://huggingface.co/t5-small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_data_dir = '../data/pseudo/'\n",
    "#\"../data/processed_filtered/\"\n",
    "binary = True\n",
    "joint = False\n",
    "#joint_transfer_tasks = ['formality', 'emo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tokenizer_binary(task, model_nick):\n",
    "    data_dir = \"../data/pseudo\"\n",
    "    model_name = \"t5-small\"\n",
    "    meta_task_type = \"binary_single\"\n",
    "    meta_task = 'transfer'\n",
    "\n",
    "\n",
    "    output_dir = \"../models/\"\n",
    "    epochs = \"5\"\n",
    "    train_batch_size = \"16\"\n",
    "    eval_batch_size = \"16\"\n",
    "    save_log_steps = \"800\"\n",
    "\n",
    "    parser = HfArgumentParser((pma, pda, pta))\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses([\n",
    "        \"--model_name_or_path\",\n",
    "        model_name,\n",
    "        \"--model_nick\",\n",
    "        model_nick,\n",
    "        \"--data_dir\",\n",
    "        data_dir,\n",
    "        \"--output_dir\",\n",
    "        os.path.join(output_dir, model_nick),\n",
    "        \"--cache_dir\",\n",
    "        os.path.join(output_dir,\"cache\"),\n",
    "        \"--overwrite_cache\",\n",
    "        \"--per_device_train_batch_size\",\n",
    "        train_batch_size,\n",
    "        \"--per_device_eval_batch_size\",\n",
    "        eval_batch_size,\n",
    "        \"--max_seq_len\",\n",
    "        \"64\",\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        \"1\",\n",
    "        \"--num_train_epochs\",\n",
    "        epochs,\n",
    "        \"--logging_steps\",\n",
    "        save_log_steps,\n",
    "        \"--save_steps\",\n",
    "        save_log_steps,\n",
    "        \"--data_parallel\",\n",
    "        \"True\",\n",
    "        \"--meta_task\",\n",
    "        meta_task,\n",
    "        \"--meta_task_type\",\n",
    "        meta_task_type\n",
    "    ])\n",
    "\n",
    "    # Eval\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path)\n",
    "    model = AutoModelWithLMHead.from_pretrained(os.path.join(output_dir, model_nick))   \n",
    "    return tokenizer, model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "mode = 'dev'\n",
    "paraphrase_model_name = \"t5_transfer_wiki_binary\"\n",
    "paraphrase_task = 'wiki'\n",
    "prompt_task = paraphrase_task #+ \"_prompt\"\n",
    "\n",
    "\n",
    "paraphrase_model_nick = \"t5_transfer_formality_joint\"\n",
    "paraphrase_model_type = 't5-small'\n",
    "output_dir = \"../models/\"\n",
    "epochs = \"3\"\n",
    "train_batch_size = \"16\"\n",
    "eval_batch_size = \"16\"\n",
    "save_log_steps = \"400\"\n",
    "\n",
    "parser = HfArgumentParser((pma, pda, pta))\n",
    "model_args_para, data_args_para, training_args_para = parser.parse_args_into_dataclasses([\n",
    "    \"--model_name_or_path\",\n",
    "    paraphrase_model_name,\n",
    "    \"--model_nick\",\n",
    "    paraphrase_model_nick,\n",
    "    \"--data_dir\",\n",
    "    pseudo_data_dir,\n",
    "    \"--output_dir\",\n",
    "    os.path.join(output_dir, paraphrase_model_nick),\n",
    "    \"--cache_dir\",\n",
    "    os.path.join(output_dir,\"cache\"),\n",
    "    \"--overwrite_cache\",\n",
    "    \"--per_device_train_batch_size\",\n",
    "    train_batch_size,\n",
    "    \"--per_device_eval_batch_size\",\n",
    "    eval_batch_size,\n",
    "    \"--max_seq_len\",\n",
    "    \"64\",\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    \"1\",\n",
    "    \"--num_train_epochs\",\n",
    "    epochs,\n",
    "    \"--logging_steps\",\n",
    "    save_log_steps,\n",
    "    \"--save_steps\",\n",
    "    save_log_steps,\n",
    "    \"--data_parallel\",\n",
    "    \"True\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "joint_task = \"abstract+shakespeare\"\n",
    "\n",
    "class_data_dir = \"../data/processed_filtered/\"\n",
    "joint_model_name = \"distilbert-base-uncased\"\n",
    "joint_model_nick = \"distilbert_uncased_2\"\n",
    "output_dir = \"../models/\"\n",
    "freeze_encoder = \"False\"\n",
    "skip_preclassifier = \"False\"\n",
    "train_jointly = \"True\"\n",
    "epochs = \"5\"\n",
    "train_batch_size = \"256\"\n",
    "eval_batch_size = \"512\"\n",
    "log_save_steps = \"200\"\n",
    "\n",
    "parser = HfArgumentParser((jma, jda, jta))\n",
    "model_args_joint, data_args_joint, training_args_joint = parser.parse_args_into_dataclasses([\n",
    "    \"--model_name_or_path\",\n",
    "    joint_model_name,\n",
    "    \"--model_nick\",\n",
    "    joint_model_nick,\n",
    "    \"--task\",\n",
    "    joint_task,\n",
    "    \"--data_dir\",\n",
    "    class_data_dir,\n",
    "    \"--output_dir\",\n",
    "    os.path.join(output_dir, joint_model_nick, joint_task, 'joint'),\n",
    "    \"--cache_dir\",\n",
    "    os.path.join(output_dir,\"cache\"),\n",
    "    \"--freeze_encoder\",\n",
    "    freeze_encoder,\n",
    "    \"--skip_preclassifier\",\n",
    "    skip_preclassifier,\n",
    "    \"--train_jointly\",\n",
    "    train_jointly,\n",
    "    \"--overwrite_cache\",\n",
    "    \"--per_device_train_batch_size\",\n",
    "    train_batch_size,\n",
    "    \"--per_device_eval_batch_size\",\n",
    "    eval_batch_size,\n",
    "    \"--max_seq_len\",\n",
    "    \"64\",\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    \"1\",\n",
    "    \"--num_train_epochs\",\n",
    "    epochs,\n",
    "    \"--logging_steps\",\n",
    "    log_save_steps,\n",
    "    \"--save_steps\",\n",
    "    log_save_steps\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /home/dmac/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /home/dmac/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
      "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /home/dmac/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "/home/dmac/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:966: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "loading configuration file ../models/t5_transfer_wiki_binary/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file ../models/t5_transfer_wiki_binary/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at ../models/t5_transfer_wiki_binary.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#If using a binary model, run this:\n",
    "if binary:\n",
    "    para_tokenizer, model = get_model_tokenizer_binary(paraphrase_task,\n",
    "                                                       paraphrase_model_name)\n",
    "    dataset = ldpb(pseudo_data_dir, para_tokenizer, mode=mode, tasks=[prompt_task], n_proc=6000)\n",
    "elif not joint:\n",
    "    # Create the paraphraser tokenizer and dataset objects\n",
    "    para_tokenizer = AutoTokenizer.from_pretrained(paraphrase_model_type, cache_dir=model_args_para.cache_dir,\n",
    "                                             model_max_length = data_args_para.max_seq_len)\n",
    "    dataset = ldp(pseudo_data_dir, para_tokenizer, mode=mode, tasks=[prompt_task], n_proc=6000)\n",
    "    # Use the paraphrase configuration defined above to create the model\n",
    "    model = AutoModelWithLMHead.from_pretrained(os.path.join(output_dir, paraphrase_model_name))\n",
    "    \n",
    "# Handle joint case:\n",
    "else:\n",
    "    para_tokenizer = AutoTokenizer.from_pretrained(paraphrase_model_type, cache_dir=model_args_para.cache_dir,\n",
    "                                             model_max_length = data_args_para.max_seq_len)\n",
    "    dataset = ldpj(pseudo_data_dir, para_tokenizer, mode=mode, tasks=[prompt_task], n_proc=6000) \n",
    "    model = AutoModelWithLMHead.from_pretrained(os.path.join(output_dir, paraphrase_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Paraphraser to Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467df118573846ecbf388e3841cbc578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=625.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = SequentialSampler(dataset)\n",
    "dataloader = DataLoader(dataset, sampler=sampler, batch_size=8)\n",
    "\n",
    "num_return_sequences = 3\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "predicted1 = []\n",
    "predicted2 = []\n",
    "predicted3 = []\n",
    "\n",
    "\n",
    "\n",
    "epoch_iterator = tqdm(dataloader, desc=\"Iteration\")\n",
    "with no_grad():\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.to(device) for t in batch)  # GPU or CPU\n",
    "        generated_outputs = model.generate(input_ids= batch[0], \n",
    "                                           attention_mask = batch[1], \n",
    "                                           max_length=50, \n",
    "                                           num_beams=9,\n",
    "                                           early_stopping=True,\n",
    "                                           encoder_no_repeat_ngram_size=5,\n",
    "                                           no_repeat_ngram_size=4,\n",
    "                                           num_beam_groups=3,\n",
    "                                           diversity_penalty=0.5,\n",
    "                                           num_return_sequences=num_return_sequences)\n",
    "        paras = para_tokenizer.batch_decode(generated_outputs.detach().cpu().numpy(), \n",
    "                                                 skip_special_tokens=True)\n",
    "        predicted1 += paras[0::3]\n",
    "        predicted2 += paras[1::3]\n",
    "        predicted3 += paras[2::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outputs to disk using in_filename as the original texts \n",
    "# and writing outputs to out_filename\n",
    "\n",
    "# If you want to do other parts of the dataset other than train, \n",
    "# set the mode in 'dataset' above to the desired mode and then rerun the paraphrase\n",
    "# and change these filenames to point to the slice of the data you want to use (dev, test, etc.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_para = pd.DataFrame(data={'transfered1' : predicted1, \n",
    "                             'transfered2' : predicted2, \n",
    "                             'transfered3' : predicted3}) \n",
    "\n",
    "if not binary and not joint:\n",
    "    in_filename = f'{mode}.csv'\n",
    "    out_filename = f'{mode}_transfered.csv'\n",
    "    df = pd.read_csv(os.path.join(pseudo_data_dir, paraphrase_task, in_filename), names =['paraphrase', \n",
    "                                                                               'para_bucket',\n",
    "                                                                               'orig_text', \n",
    "                                                                               'oring_bucket'])\n",
    "elif not joint:\n",
    "    in_filename = f'{mode}_binary.csv'\n",
    "    out_filename = f'{mode}_binary_transfered.csv'\n",
    "    df = pd.read_csv(os.path.join(pseudo_data_dir, paraphrase_task, in_filename), names =['paraphrase',\n",
    "                                                                                           'orig_text'])   \n",
    "else:\n",
    "    in_filename = f'{mode}.csv'\n",
    "    out_filename = f'{mode}_transfered.csv'\n",
    "    df = pd.read_csv(os.path.join(pseudo_data_dir, paraphrase_task, in_filename), \n",
    "                     names =['paraphrase',\n",
    "                             f\"{joint_transfer_tasks[0]}_para_bucket\",\n",
    "                             f\"{joint_transfer_tasks[1]}_para_bucket\",\n",
    "                             'orig_text', \n",
    "                             f\"{joint_transfer_tasks[0]}_orig_bucket\",\n",
    "                             f\"{joint_transfer_tasks[1]}_orig_bucket\"])     \n",
    "\n",
    "    \n",
    "df['transfered1'] = df_para['transfered1']\n",
    "df['transfered2'] = df_para['transfered2']\n",
    "df['transfered3'] = df_para['transfered3']\n",
    "df.to_csv(os.path.join(pseudo_data_dir, prompt_task, out_filename), \n",
    "               header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>orig_text</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there's more than two possible outcomes in K.</td>\n",
       "      <td>there are K possible outcomes rather than just...</td>\n",
       "      <td>In K, there are more than 2 possible outcomes.</td>\n",
       "      <td>In K, there are more than two possible results.</td>\n",
       "      <td>In K, there are more than 2 possible outcomes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the small number of multiplications in matrix-...</td>\n",
       "      <td>The nonlinear map from the parameter to this c...</td>\n",
       "      <td>The nonlinear parameter map to vector collecti...</td>\n",
       "      <td>The nonlinear parameter map to the vector coll...</td>\n",
       "      <td>The nonlinear parameter map to the vector coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the template must not be linked to the image, ...</td>\n",
       "      <td>The template need not to be anyhow related to ...</td>\n",
       "      <td>The template cannot be linked to an image, and...</td>\n",
       "      <td>The template cannot be linked to an image, and...</td>\n",
       "      <td>It is not necessary to link the template to an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the initialization of the deep learning classi...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a visual representation of the indoor environm...</td>\n",
       "      <td>The aim of this work is to use Variational Aut...</td>\n",
       "      <td>For this work, visual representations of indoo...</td>\n",
       "      <td>For this work, visual representations of indoo...</td>\n",
       "      <td>For this work, visual representations of indoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paraphrase  \\\n",
       "0      there's more than two possible outcomes in K.   \n",
       "1  the small number of multiplications in matrix-...   \n",
       "2  the template must not be linked to the image, ...   \n",
       "3  the initialization of the deep learning classi...   \n",
       "4  a visual representation of the indoor environm...   \n",
       "\n",
       "                                           orig_text  \\\n",
       "0  there are K possible outcomes rather than just...   \n",
       "1  The nonlinear map from the parameter to this c...   \n",
       "2  The template need not to be anyhow related to ...   \n",
       "3  Latent representations from original SNP seque...   \n",
       "4  The aim of this work is to use Variational Aut...   \n",
       "\n",
       "                                         transfered1  \\\n",
       "0     In K, there are more than 2 possible outcomes.   \n",
       "1  The nonlinear parameter map to vector collecti...   \n",
       "2  The template cannot be linked to an image, and...   \n",
       "3  Latent representations from original SNP seque...   \n",
       "4  For this work, visual representations of indoo...   \n",
       "\n",
       "                                         transfered2  \\\n",
       "0    In K, there are more than two possible results.   \n",
       "1  The nonlinear parameter map to the vector coll...   \n",
       "2  The template cannot be linked to an image, and...   \n",
       "3  Latent representations from original SNP seque...   \n",
       "4  For this work, visual representations of indoo...   \n",
       "\n",
       "                                         transfered3  \n",
       "0      In K, there are more than 2 possible outcomes  \n",
       "1  The nonlinear parameter map to the vector coll...  \n",
       "2  It is not necessary to link the template to an...  \n",
       "3  Latent representations from original SNP seque...  \n",
       "4  For this work, visual representations of indoo...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use classifier for Scoring\n",
    "This may cause GPU memory issues, so it's possible you may have to shutdown the kernel and restart without running the paraphraser first to run this next portion. If doing so, reload the df that was written to disk in several cells above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in desired dataset and classifier model\n",
    "In the cell below, define the dataset you want to work with and the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at ../models/cache/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at ../models/cache/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at ../models/cache/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at ../models/cache/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(model_args_joint.model_name_or_path, \n",
    "                                          cache_dir=model_args_joint.cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args_joint.model_name_or_path, \n",
    "                                          cache_dir=model_args_joint.cache_dir,\n",
    "                                          model_max_length = data_args_joint.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81523, 64]) torch.Size([81523, 64]) torch.Size([81523, 2]) torch.Size([81523])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.70it/s]\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([113262, 64]) torch.Size([113262, 64]) torch.Size([113262, 2]) torch.Size([113262])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.75it/s]\n",
      " 50%|█████     | 1/2 [00:00<00:00,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20306, 64]) torch.Size([20306, 64]) torch.Size([20306, 2]) torch.Size([20306])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28322, 64]) torch.Size([28322, 64]) torch.Size([28322, 2]) torch.Size([28322])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data as expected by joint classifier\n",
    "tasks = data_args_joint.task.split('+')\n",
    "train_dataset, idx_to_classes = jld(data_args_joint.data_dir, \n",
    "                                             tokenizer, \n",
    "                                             model_name=model_args_joint.model_name_or_path, \n",
    "                           tasks=tasks, mode=\"train\", n_proc=6000)\n",
    "dev_dataset, _ = jld(data_args_joint.data_dir, \n",
    "                              tokenizer, \n",
    "                              model_name=model_args_joint.model_name_or_path, \n",
    "                              tasks=tasks, mode=\"dev\", n_proc=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dims = {task : 1 if len(list(idx_to_classes[task].keys())) == 2 else len(list(idx_to_classes[task].keys())) for task in idx_to_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/distilbert_uncased_2/abstract+shakespeare/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"JointSeqClassifier\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../models/distilbert_uncased_2/abstract+shakespeare/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing JointSeqClassifier.\n",
      "\n",
      "All the weights of JointSeqClassifier were initialized from the model checkpoint at ../models/distilbert_uncased_2/abstract+shakespeare.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use JointSeqClassifier for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "joint_model = JointSeqClassifier.from_pretrained(os.path.join(output_dir,\n",
    "                                                              model_args_joint.model_nick, joint_task),\n",
    "                                           tasks=tasks,\n",
    "                                           model_args=model_args_joint,\n",
    "                                           task_if_single=None, \n",
    "                                           joint = training_args_joint.train_jointly,\n",
    "                                           label_dims=label_dims)\n",
    "\n",
    "trainer = JointTrainer([training_args_joint,model_args_joint, data_args_joint], \n",
    "                       joint_model, train_dataset, dev_dataset, idx_to_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run classifier on paraphrased and original text\n",
    "\n",
    "This is currently done with pd DataFrames but could probably be made better by using a batch data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract', 'shakespeare']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_paraphrases(row, tasks, cols):\n",
    "    '''\n",
    "    Make style predictions on a given df row for a given set of text columns\n",
    "    and classification tasks. \n",
    "    '''\n",
    "    preds = {}\n",
    "    for col in cols:\n",
    "        sentence = row[col]\n",
    "        out = trainer.predict_for_sentence(sentence, tokenizer)\n",
    "        for task in tasks:\n",
    "            pred = float(out[task]['prob'])\n",
    "            preds[task + '_' + col] = pred\n",
    "    return preds\n",
    "\n",
    "def get_best_pred(row, cols, target_val=0.5):\n",
    "    '''\n",
    "    Helper funtion for determiningg which paraphrase is 'best' \n",
    "    for a given set of paraphrase column style scores and a target value\n",
    "    that you want the scores to be close to. Currently just outputs the best score\n",
    "    but could be modified to get best sentence as well.\n",
    "    '''\n",
    "    best_diff = 1\n",
    "    best_val = None\n",
    "    for col in cols:\n",
    "        diff = abs(row[col] - target_val)\n",
    "        if diff < best_diff:\n",
    "            best_val = row[col]\n",
    "            best_diff = diff\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:58<00:00, 16.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define columns on which to run the classification\n",
    "cols_to_use = ['orig_text', 'paraphrase','transfered1', 'transfered2', 'transfered3']\n",
    "# Define the names of the columns where the output scores will be stored\n",
    "cols_preds = [f'pred_{tasks[0]}_orig', f'pred_{tasks[1]}_orig',\n",
    "              f'pred_{tasks[0]}_para', f'pred_{tasks[1]}_para',\n",
    "              f'pred_{tasks[0]}_transfered1', f'pred_{tasks[1]}_transfered1',\n",
    "              f'pred_{tasks[0]}_transfered2', f'pred_{tasks[1]}_transfered2',\n",
    "              f'pred_{tasks[0]}_transfered3', f'pred_{tasks[1]}_transfered3']\n",
    "# Store results into df\n",
    "df[cols_preds] = df.progress_apply(lambda x : pred_paraphrases(x, tasks, cols_to_use), \n",
    "                                   axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the results of the transfer for style changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>orig_text</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "      <th>pred_formality_orig</th>\n",
       "      <th>pred_emo_orig</th>\n",
       "      <th>pred_formality_para</th>\n",
       "      <th>pred_emo_para</th>\n",
       "      <th>pred_formality_transfered1</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_abstract_orig</th>\n",
       "      <th>pred_shakespeare_orig</th>\n",
       "      <th>pred_abstract_para</th>\n",
       "      <th>pred_shakespeare_para</th>\n",
       "      <th>pred_abstract_transfered1</th>\n",
       "      <th>pred_shakespeare_transfered1</th>\n",
       "      <th>pred_abstract_transfered2</th>\n",
       "      <th>pred_shakespeare_transfered2</th>\n",
       "      <th>pred_abstract_transfered3</th>\n",
       "      <th>pred_shakespeare_transfered3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there's more than two possible outcomes in K.</td>\n",
       "      <td>there are K possible outcomes rather than just...</td>\n",
       "      <td>In K, there are more than 2 possible outcomes.</td>\n",
       "      <td>In K, there are more than two possible results.</td>\n",
       "      <td>In K, there are more than 2 possible outcomes</td>\n",
       "      <td>0.873103</td>\n",
       "      <td>0.824869</td>\n",
       "      <td>0.880773</td>\n",
       "      <td>0.885823</td>\n",
       "      <td>0.823150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.113090</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.304722</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.310722</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.351737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the small number of multiplications in matrix-...</td>\n",
       "      <td>The nonlinear map from the parameter to this c...</td>\n",
       "      <td>The nonlinear parameter map to vector collecti...</td>\n",
       "      <td>The nonlinear parameter map to the vector coll...</td>\n",
       "      <td>The nonlinear parameter map to the vector coll...</td>\n",
       "      <td>0.969080</td>\n",
       "      <td>0.882344</td>\n",
       "      <td>0.956581</td>\n",
       "      <td>0.693250</td>\n",
       "      <td>0.962489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999576</td>\n",
       "      <td>0.378452</td>\n",
       "      <td>0.999519</td>\n",
       "      <td>0.408578</td>\n",
       "      <td>0.999549</td>\n",
       "      <td>0.411191</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.387537</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.382447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the template must not be linked to the image, ...</td>\n",
       "      <td>The template need not to be anyhow related to ...</td>\n",
       "      <td>The template cannot be linked to an image, and...</td>\n",
       "      <td>The template cannot be linked to an image, and...</td>\n",
       "      <td>It is not necessary to link the template to an...</td>\n",
       "      <td>0.916163</td>\n",
       "      <td>0.418875</td>\n",
       "      <td>0.995045</td>\n",
       "      <td>0.535523</td>\n",
       "      <td>0.994128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.231495</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.237502</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.254806</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.209619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the initialization of the deep learning classi...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "      <td>Latent representations from original SNP seque...</td>\n",
       "      <td>0.990662</td>\n",
       "      <td>0.947853</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>0.900966</td>\n",
       "      <td>0.991874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.345480</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.284943</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.298768</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.334723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a visual representation of the indoor environm...</td>\n",
       "      <td>The aim of this work is to use Variational Aut...</td>\n",
       "      <td>For this work, visual representations of indoo...</td>\n",
       "      <td>For this work, visual representations of indoo...</td>\n",
       "      <td>For this work, visual representations of indoo...</td>\n",
       "      <td>0.969464</td>\n",
       "      <td>0.986648</td>\n",
       "      <td>0.995278</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.994145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.326097</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.203785</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.225494</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.234881</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.334261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>in order to provide more information, the resp...</td>\n",
       "      <td>The lower layer responses are transferred to t...</td>\n",
       "      <td>The responses of the lower layers are transfer...</td>\n",
       "      <td>The responses of the lower layers are transfer...</td>\n",
       "      <td>The responses of the lower layers are transfer...</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>0.892616</td>\n",
       "      <td>0.994789</td>\n",
       "      <td>0.830346</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.350174</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.230139</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.256072</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>0.999576</td>\n",
       "      <td>0.316912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>however, both departments have failed to excel...</td>\n",
       "      <td>However, existing frameworks fail to excel in ...</td>\n",
       "      <td>However, existing frameworks have failed in bo...</td>\n",
       "      <td>However, existing frameworks have failed in bo...</td>\n",
       "      <td>However, existing frameworks have failed in bo...</td>\n",
       "      <td>0.986414</td>\n",
       "      <td>0.486884</td>\n",
       "      <td>0.994676</td>\n",
       "      <td>0.624792</td>\n",
       "      <td>0.979495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>0.330449</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.193641</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>0.302278</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>0.325910</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.319097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>structural changes that can encourage physical...</td>\n",
       "      <td>Understanding the association between specific...</td>\n",
       "      <td>The understanding of association between speci...</td>\n",
       "      <td>The understanding of association between speci...</td>\n",
       "      <td>The understanding of association between speci...</td>\n",
       "      <td>0.990401</td>\n",
       "      <td>0.755807</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>0.806404</td>\n",
       "      <td>0.994012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.346098</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.201334</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.230093</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>0.337382</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.237188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>the results demonstrate that such a declarativ...</td>\n",
       "      <td>Experiments performed on a large computing clu...</td>\n",
       "      <td>The results demonstrate that such declarative ...</td>\n",
       "      <td>The results show that such a afirmative approa...</td>\n",
       "      <td>The results demonstrate that such declarative ...</td>\n",
       "      <td>0.991427</td>\n",
       "      <td>0.985020</td>\n",
       "      <td>0.992018</td>\n",
       "      <td>0.983310</td>\n",
       "      <td>0.991762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.338455</td>\n",
       "      <td>0.999520</td>\n",
       "      <td>0.256230</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.319539</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.325544</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.226534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>in terms of computational resources, leakage a...</td>\n",
       "      <td>We study their benefits, limitations and trade...</td>\n",
       "      <td>We investigate their advantages, limitations, ...</td>\n",
       "      <td>We investigate their advantages, limitations, ...</td>\n",
       "      <td>We investigate their advantages, limitations, ...</td>\n",
       "      <td>0.988453</td>\n",
       "      <td>0.985645</td>\n",
       "      <td>0.992172</td>\n",
       "      <td>0.971073</td>\n",
       "      <td>0.990353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>0.351645</td>\n",
       "      <td>0.999550</td>\n",
       "      <td>0.325962</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.282457</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.275661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paraphrase  \\\n",
       "0       there's more than two possible outcomes in K.   \n",
       "1   the small number of multiplications in matrix-...   \n",
       "2   the template must not be linked to the image, ...   \n",
       "3   the initialization of the deep learning classi...   \n",
       "4   a visual representation of the indoor environm...   \n",
       "..                                                ...   \n",
       "95  in order to provide more information, the resp...   \n",
       "96  however, both departments have failed to excel...   \n",
       "97  structural changes that can encourage physical...   \n",
       "98  the results demonstrate that such a declarativ...   \n",
       "99  in terms of computational resources, leakage a...   \n",
       "\n",
       "                                            orig_text  \\\n",
       "0   there are K possible outcomes rather than just...   \n",
       "1   The nonlinear map from the parameter to this c...   \n",
       "2   The template need not to be anyhow related to ...   \n",
       "3   Latent representations from original SNP seque...   \n",
       "4   The aim of this work is to use Variational Aut...   \n",
       "..                                                ...   \n",
       "95  The lower layer responses are transferred to t...   \n",
       "96  However, existing frameworks fail to excel in ...   \n",
       "97  Understanding the association between specific...   \n",
       "98  Experiments performed on a large computing clu...   \n",
       "99  We study their benefits, limitations and trade...   \n",
       "\n",
       "                                          transfered1  \\\n",
       "0      In K, there are more than 2 possible outcomes.   \n",
       "1   The nonlinear parameter map to vector collecti...   \n",
       "2   The template cannot be linked to an image, and...   \n",
       "3   Latent representations from original SNP seque...   \n",
       "4   For this work, visual representations of indoo...   \n",
       "..                                                ...   \n",
       "95  The responses of the lower layers are transfer...   \n",
       "96  However, existing frameworks have failed in bo...   \n",
       "97  The understanding of association between speci...   \n",
       "98  The results demonstrate that such declarative ...   \n",
       "99  We investigate their advantages, limitations, ...   \n",
       "\n",
       "                                          transfered2  \\\n",
       "0     In K, there are more than two possible results.   \n",
       "1   The nonlinear parameter map to the vector coll...   \n",
       "2   The template cannot be linked to an image, and...   \n",
       "3   Latent representations from original SNP seque...   \n",
       "4   For this work, visual representations of indoo...   \n",
       "..                                                ...   \n",
       "95  The responses of the lower layers are transfer...   \n",
       "96  However, existing frameworks have failed in bo...   \n",
       "97  The understanding of association between speci...   \n",
       "98  The results show that such a afirmative approa...   \n",
       "99  We investigate their advantages, limitations, ...   \n",
       "\n",
       "                                          transfered3  pred_formality_orig  \\\n",
       "0       In K, there are more than 2 possible outcomes             0.873103   \n",
       "1   The nonlinear parameter map to the vector coll...             0.969080   \n",
       "2   It is not necessary to link the template to an...             0.916163   \n",
       "3   Latent representations from original SNP seque...             0.990662   \n",
       "4   For this work, visual representations of indoo...             0.969464   \n",
       "..                                                ...                  ...   \n",
       "95  The responses of the lower layers are transfer...             0.981573   \n",
       "96  However, existing frameworks have failed in bo...             0.986414   \n",
       "97  The understanding of association between speci...             0.990401   \n",
       "98  The results demonstrate that such declarative ...             0.991427   \n",
       "99  We investigate their advantages, limitations, ...             0.988453   \n",
       "\n",
       "    pred_emo_orig  pred_formality_para  pred_emo_para  \\\n",
       "0        0.824869             0.880773       0.885823   \n",
       "1        0.882344             0.956581       0.693250   \n",
       "2        0.418875             0.995045       0.535523   \n",
       "3        0.947853             0.993578       0.900966   \n",
       "4        0.986648             0.995278       0.947575   \n",
       "..            ...                  ...            ...   \n",
       "95       0.892616             0.994789       0.830346   \n",
       "96       0.486884             0.994676       0.624792   \n",
       "97       0.755807             0.993889       0.806404   \n",
       "98       0.985020             0.992018       0.983310   \n",
       "99       0.985645             0.992172       0.971073   \n",
       "\n",
       "    pred_formality_transfered1  ...  pred_abstract_orig  \\\n",
       "0                     0.823150  ...            0.000399   \n",
       "1                     0.962489  ...            0.999576   \n",
       "2                     0.994128  ...            0.000582   \n",
       "3                     0.991874  ...            0.999584   \n",
       "4                     0.994145  ...            0.999578   \n",
       "..                         ...  ...                 ...   \n",
       "95                    0.994796  ...            0.999584   \n",
       "96                    0.979495  ...            0.999564   \n",
       "97                    0.994012  ...            0.999566   \n",
       "98                    0.991762  ...            0.999569   \n",
       "99                    0.990353  ...            0.999575   \n",
       "\n",
       "    pred_shakespeare_orig  pred_abstract_para  pred_shakespeare_para  \\\n",
       "0                0.276801            0.000686               0.113090   \n",
       "1                0.378452            0.999519               0.408578   \n",
       "2                0.231495            0.000421               0.143112   \n",
       "3                0.345480            0.000349               0.284943   \n",
       "4                0.326097            0.000370               0.203785   \n",
       "..                    ...                 ...                    ...   \n",
       "95               0.350174            0.000355               0.230139   \n",
       "96               0.330449            0.000383               0.193641   \n",
       "97               0.346098            0.000416               0.201334   \n",
       "98               0.338455            0.999520               0.256230   \n",
       "99               0.351645            0.999550               0.325962   \n",
       "\n",
       "    pred_abstract_transfered1  pred_shakespeare_transfered1  \\\n",
       "0                    0.000349                      0.304722   \n",
       "1                    0.999549                      0.411191   \n",
       "2                    0.000348                      0.237502   \n",
       "3                    0.000341                      0.298768   \n",
       "4                    0.000356                      0.225494   \n",
       "..                        ...                           ...   \n",
       "95                   0.000347                      0.256072   \n",
       "96                   0.999538                      0.302278   \n",
       "97                   0.000363                      0.230093   \n",
       "98                   0.999579                      0.319539   \n",
       "99                   0.999479                      0.282457   \n",
       "\n",
       "    pred_abstract_transfered2  pred_shakespeare_transfered2  \\\n",
       "0                    0.000363                      0.310722   \n",
       "1                    0.999552                      0.387537   \n",
       "2                    0.000342                      0.254806   \n",
       "3                    0.000343                      0.296286   \n",
       "4                    0.000350                      0.234881   \n",
       "..                        ...                           ...   \n",
       "95                   0.000348                      0.248210   \n",
       "96                   0.999572                      0.325910   \n",
       "97                   0.999572                      0.337382   \n",
       "98                   0.999584                      0.325544   \n",
       "99                   0.999469                      0.274653   \n",
       "\n",
       "    pred_abstract_transfered3  pred_shakespeare_transfered3  \n",
       "0                    0.999428                      0.351737  \n",
       "1                    0.999526                      0.382447  \n",
       "2                    0.000362                      0.209619  \n",
       "3                    0.999579                      0.334723  \n",
       "4                    0.999552                      0.334261  \n",
       "..                        ...                           ...  \n",
       "95                   0.999576                      0.316912  \n",
       "96                   0.999566                      0.319097  \n",
       "97                   0.000362                      0.237188  \n",
       "98                   0.000354                      0.226534  \n",
       "99                   0.999465                      0.275661  \n",
       "\n",
       "[100 rows x 25 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pred_wiki_orig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pred_wiki_orig'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b8f64dc64127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#for prompt_task in ['formality', 'emo']:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{prompt_task}_diff1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'pred_{prompt_task}_orig'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'pred_{prompt_task}_transfered1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{prompt_task}_diff2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'pred_{prompt_task}_orig'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'pred_{prompt_task}_transfered2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{prompt_task}_diff3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'pred_{prompt_task}_orig'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'pred_{prompt_task}_transfered3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pred_wiki_orig'"
     ]
    }
   ],
   "source": [
    "#for prompt_task in ['formality', 'emo']:\n",
    "df[f'{prompt_task}_diff1'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered1'])\n",
    "df[f'{prompt_task}_diff2'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered2'])\n",
    "df[f'{prompt_task}_diff3'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prompt_task in ['formality', 'emo']:\n",
    "df[f'{prompt_task}_diff_max'] = df.apply(lambda x : np.max([x[f'{prompt_task}_diff1'], \n",
    "                                                       x[f'{prompt_task}_diff2'], \n",
    "                                                       x[f'{prompt_task}_diff3']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store results of style classification:\n",
    "if binary:\n",
    "    out_filename = paraphrase_task + f'_{mode}_binary_cross_predict_transfers.csv'\n",
    "else:\n",
    "    out_filename = paraphrase_task + f'_{mode}_cross_predict_transfers.csv'\n",
    "\n",
    "df.to_csv(os.path.join(pseudo_data_dir, prompt_task, out_filename), header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at best sytle difference summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's disaggregate by class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['para_bucket']=='low'][f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['para_bucket']=='mid'][f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Temp for running analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '../data/pseudo/'\n",
    "model_name = 'abstract'\n",
    "dataset = 'abstract'\n",
    "mode = 'dev'\n",
    "binary = True\n",
    "\n",
    "prompt_task = dataset \n",
    "\n",
    "in_filename = f'{model_name}_{mode}_cross_predict_transfers.csv'\n",
    "full_path = os.path.join(data_dir, model_name, in_filename)\n",
    "parallel_df = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[f'{dataset}_diff1'] =  abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_transfered1'])\n",
    "parallel_df[f'{dataset}_diff2'] =  abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_transfered2'])\n",
    "parallel_df[f'{dataset}_diff3'] =  abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_transfered3'])\n",
    "\n",
    "parallel_df[f'{dataset}_para_diff1'] =  abs(parallel_df[f'pred_{dataset}_para'] - parallel_df[f'pred_{dataset}_transfered1'])\n",
    "parallel_df[f'{dataset}_para_diff2'] =  abs(parallel_df[f'pred_{dataset}_para'] - parallel_df[f'pred_{dataset}_transfered2'])\n",
    "parallel_df[f'{dataset}_para_diff3'] =  abs(parallel_df[f'pred_{dataset}_para'] - parallel_df[f'pred_{dataset}_transfered3'])\n",
    "\n",
    "parallel_df[f'{dataset}_para_orig_diff'] = abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_para'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[f'{dataset}_orig_diff_max'] = parallel_df.apply(lambda x : np.max([x[f'{dataset}_diff1'], \n",
    "                                                       x[f'{dataset}_diff2'], \n",
    "                                                       x[f'{dataset}_diff3']]), axis=1)\n",
    "\n",
    "parallel_df[f'{dataset}_para_diff_max'] = parallel_df.apply(lambda x : np.max([x[f'{dataset}_para_diff1'], \n",
    "                                                       x[f'{dataset}_para_diff2'], \n",
    "                                                       x[f'{dataset}_para_diff3']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_diff_mean = parallel_df[f'{dataset}_orig_diff_max'].mean()\n",
    "orig_diff_std = parallel_df[f'{dataset}_orig_diff_max'].std()\n",
    "print(f'orig_diff {orig_diff_mean :.4f} ({orig_diff_std :.4f}) ')\n",
    "para_diff_mean = parallel_df[f'{dataset}_para_diff_max'].mean()\n",
    "para_diff_std = parallel_df[f'{dataset}_para_diff_max'].std()\n",
    "print(f'para_diff {para_diff_mean :.4f} ({para_diff_std :.4f}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df['transfer_best_style'] = parallel_df.apply(lambda x : \\\n",
    "                                                       np.min([x[f'pred_{dataset}_transfered1'], \n",
    "                                                       x[f'pred_{dataset}_transfered2'], \n",
    "                                                       x[f'pred_{dataset}_transfered3']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[f'pred_{dataset}_transfered3'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[f'pred_{dataset}_orig'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_marvin)",
   "language": "python",
   "name": "env_marvin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "70745de62fac122a8ca1204278c5668179019927655d931b4063a8c34fb0e461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
