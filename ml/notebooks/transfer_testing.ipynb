{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generate Some Transfered Sentences and get Style Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys, os\n",
    "import numpy as np\n",
    "sys.path.append('../paraphrase/')\n",
    "sys.path.append('../jointclassifier/')\n",
    "from paraphraser_args import ModelArguments as pma, DataTrainingArguments as pda, TrainingArguments as pta\n",
    "from paraphraser_dataloader import load_dataset as pld, load_dataset_style as lds\n",
    "from paraphraser_dataloader import load_dataset_pseudo as ldp\n",
    "from paraphraser_trainer import ParaphraserTrainer\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelWithLMHead, HfArgumentParser\n",
    "from joint_args import ModelArguments as jma, DataTrainingArguments as jda, TrainingArguments as jta\n",
    "from joint_dataloader import load_dataset as jld\n",
    "from joint_trainer import JointTrainer\n",
    "from joint_model_v1 import JointSeqClassifier\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch import cuda, no_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in desired dataset and paraphraser model\n",
    "In the cell below, define the dataset you want to work with and the paraphraser model (here a `\"t5-small\"` [from Hugging Face](https://huggingface.co/t5-small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/pseudo/'\n",
    "#\"../data/processed_filtered/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "mode = 'dev'\n",
    "paraphrase_model_name = \"t5_transfer_shakespeare\"\n",
    "paraphrase_task = 'shakespeare'\n",
    "prompt_task = paraphrase_task #+ \"_prompt\"\n",
    "\n",
    "\n",
    "paraphrase_model_nick = \"t5_transfer_shakespeare\"\n",
    "paraphrase_model_type = 't5-small'\n",
    "output_dir = \"../models/\"\n",
    "epochs = \"3\"\n",
    "train_batch_size = \"16\"\n",
    "eval_batch_size = \"16\"\n",
    "save_log_steps = \"400\"\n",
    "\n",
    "parser = HfArgumentParser((pma, pda, pta))\n",
    "model_args_para, data_args_para, training_args_para = parser.parse_args_into_dataclasses([\n",
    "    \"--model_name_or_path\",\n",
    "    paraphrase_model_name,\n",
    "    \"--model_nick\",\n",
    "    paraphrase_model_nick,\n",
    "    \"--data_dir\",\n",
    "    data_dir,\n",
    "    \"--output_dir\",\n",
    "    os.path.join(output_dir, paraphrase_model_nick),\n",
    "    \"--cache_dir\",\n",
    "    os.path.join(output_dir,\"cache\"),\n",
    "    \"--overwrite_cache\",\n",
    "    \"--per_device_train_batch_size\",\n",
    "    train_batch_size,\n",
    "    \"--per_device_eval_batch_size\",\n",
    "    eval_batch_size,\n",
    "    \"--max_seq_len\",\n",
    "    \"64\",\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    \"1\",\n",
    "    \"--num_train_epochs\",\n",
    "    epochs,\n",
    "    \"--logging_steps\",\n",
    "    save_log_steps,\n",
    "    \"--save_steps\",\n",
    "    save_log_steps,\n",
    "    \"--data_parallel\",\n",
    "    \"True\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "joint_task = \"abstract+shakespeare\" #\"formality+emo\"\n",
    "data_dir = \"../data/processed_filtered/\"\n",
    "joint_model_name = \"distilbert-base-uncased\"\n",
    "joint_model_nick = \"distilbert_uncased_2\"\n",
    "output_dir = \"../models/\"\n",
    "freeze_encoder = \"False\"\n",
    "skip_preclassifier = \"False\"\n",
    "train_jointly = \"True\"\n",
    "epochs = \"5\"\n",
    "train_batch_size = \"256\"\n",
    "eval_batch_size = \"512\"\n",
    "log_save_steps = \"200\"\n",
    "\n",
    "parser = HfArgumentParser((jma, jda, jta))\n",
    "model_args_joint, data_args_joint, training_args_joint = parser.parse_args_into_dataclasses([\n",
    "    \"--model_name_or_path\",\n",
    "    joint_model_name,\n",
    "    \"--model_nick\",\n",
    "    joint_model_nick,\n",
    "    \"--task\",\n",
    "    joint_task,\n",
    "    \"--data_dir\",\n",
    "    data_dir,\n",
    "    \"--output_dir\",\n",
    "    os.path.join(output_dir, joint_model_nick, joint_task, 'joint'),\n",
    "    \"--cache_dir\",\n",
    "    os.path.join(output_dir,\"cache\"),\n",
    "    \"--freeze_encoder\",\n",
    "    freeze_encoder,\n",
    "    \"--skip_preclassifier\",\n",
    "    skip_preclassifier,\n",
    "    \"--train_jointly\",\n",
    "    train_jointly,\n",
    "    \"--overwrite_cache\",\n",
    "    \"--per_device_train_batch_size\",\n",
    "    train_batch_size,\n",
    "    \"--per_device_eval_batch_size\",\n",
    "    eval_batch_size,\n",
    "    \"--max_seq_len\",\n",
    "    \"64\",\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    \"1\",\n",
    "    \"--num_train_epochs\",\n",
    "    epochs,\n",
    "    \"--logging_steps\",\n",
    "    log_save_steps,\n",
    "    \"--save_steps\",\n",
    "    log_save_steps\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at ../models/cache/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at ../models/cache/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
      "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at ../models/cache/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0    1  \\\n",
      "0                      I'm sure you won't marry her.  low   \n",
      "1                      stand in front of the hearse!  low   \n",
      "2  I'm not going to walk out of the door, but som...  low   \n",
      "3                      how do you mean removing him?  mid   \n",
      "4                                 I'm yours forever.  low   \n",
      "\n",
      "                                                   2     3  \n",
      "0         But thus, I trust, you will not marry her.   mid  \n",
      "1                             Stand from the hearse.   mid  \n",
      "2  I have no will to wander forth of doors, Yet s...  high  \n",
      "3                  How do you mean, removing of him?  high  \n",
      "4                            I am your own for ever.  high  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the paraphraser tokenizer and dataset objects\n",
    "para_tokenizer = AutoTokenizer.from_pretrained(paraphrase_model_type, cache_dir=model_args_para.cache_dir,\n",
    "                                         model_max_length = data_args_para.max_seq_len)\n",
    "dataset = ldp(data_dir, para_tokenizer, mode=mode, tasks=[prompt_task], n_proc=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmac/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:966: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "loading configuration file ../models/t5_transfer_shakespeare/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file ../models/t5_transfer_shakespeare/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at ../models/t5_transfer_shakespeare.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Use the paraphrase configuration defined above to create the model\n",
    "model = AutoModelWithLMHead.from_pretrained(os.path.join(output_dir, paraphrase_model_name))\n",
    "#training_args_para.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Paraphraser to Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5939634daea94625aee9de93051c5db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=486.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = SequentialSampler(dataset)\n",
    "dataloader = DataLoader(dataset, sampler=sampler, batch_size=16)\n",
    "\n",
    "num_return_sequences = 3\n",
    "\n",
    "device = (\"cuda\" if cuda.is_available() else \"cpu\") #and not self.args.no_cuda\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "predicted1 = []\n",
    "predicted2 = []\n",
    "predicted3 = []\n",
    "\n",
    "epoch_iterator = tqdm(dataloader, desc=\"Iteration\")\n",
    "with no_grad():\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.to(device) for t in batch)  # GPU or CPU\n",
    "        generated_outputs = model.generate(input_ids= batch[0], \n",
    "                                           attention_mask = batch[1], \n",
    "                                           num_return_sequences = num_return_sequences, \n",
    "                                           num_beams = 12)\n",
    "        paras = para_tokenizer.batch_decode(generated_outputs.detach().cpu().numpy(), \n",
    "                                                 skip_special_tokens=True)\n",
    "        predicted1 += paras[0::3]\n",
    "        predicted2 += paras[1::3]\n",
    "        predicted3 += paras[2::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outputs to disk using in_filename as the original texts \n",
    "# and writing outputs to out_filename\n",
    "\n",
    "# If you want to do other parts of the dataset other than train, \n",
    "# set the mode in 'dataset' above to the desired mode and then rerun the paraphrase\n",
    "# and change these filenames to point to the slice of the data you want to use (dev, test, etc.)\n",
    "\n",
    "in_filename = f'{mode}.csv'\n",
    "out_filename = f'{mode}_transfered.csv'\n",
    "\n",
    "\n",
    "df_para = pd.DataFrame(data={'transfered1' : predicted1, \n",
    "                             'transfered2' : predicted2, \n",
    "                             'transfered3' : predicted3}) \n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, paraphrase_task, in_filename), names =['paraphrase', \n",
    "                                                                               'para_bucket',\n",
    "                                                                               'orig_text', \n",
    "                                                                               'oring_bucket'])\n",
    "df['transfered1'] = df_para['transfered1']\n",
    "df['transfered2'] = df_para['transfered2']\n",
    "df['transfered3'] = df_para['transfered3']\n",
    "df.to_csv(os.path.join(data_dir, prompt_task, out_filename), \n",
    "               header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>para_bucket</th>\n",
       "      <th>orig_text</th>\n",
       "      <th>oring_bucket</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure you won't marry her.</td>\n",
       "      <td>low</td>\n",
       "      <td>But thus, I trust, you will not marry her.</td>\n",
       "      <td>mid</td>\n",
       "      <td>I am sure you will not marry her.</td>\n",
       "      <td>I know you will not marry her.</td>\n",
       "      <td>I am sure you’ll not marry her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stand in front of the hearse!</td>\n",
       "      <td>low</td>\n",
       "      <td>Stand from the hearse.</td>\n",
       "      <td>mid</td>\n",
       "      <td>Stand in front of the hearse!</td>\n",
       "      <td>Stand in front of hearse!</td>\n",
       "      <td>Stand before the hearse!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not going to walk out of the door, but som...</td>\n",
       "      <td>low</td>\n",
       "      <td>I have no will to wander forth of doors, Yet s...</td>\n",
       "      <td>high</td>\n",
       "      <td>I’ll not walk out of the door, But something l...</td>\n",
       "      <td>I’ll not walk out of the door, but something l...</td>\n",
       "      <td>I will not walk out of the door, But something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do you mean removing him?</td>\n",
       "      <td>mid</td>\n",
       "      <td>How do you mean, removing of him?</td>\n",
       "      <td>high</td>\n",
       "      <td>How mean you to remove him?</td>\n",
       "      <td>How dost thou mean removing him?</td>\n",
       "      <td>How mean you removing him?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm yours forever.</td>\n",
       "      <td>low</td>\n",
       "      <td>I am your own for ever.</td>\n",
       "      <td>high</td>\n",
       "      <td>I am yours forever.</td>\n",
       "      <td>I am thyself forever.</td>\n",
       "      <td>I am thy lord forever.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>the capon burns, the pig falls out of the spit...</td>\n",
       "      <td>mid</td>\n",
       "      <td>The capon burns; the pig falls from the spit; ...</td>\n",
       "      <td>high</td>\n",
       "      <td>The capon burns, the pig falls out of the spit...</td>\n",
       "      <td>The capon burns, the pig falls out of the spit...</td>\n",
       "      <td>The capon burns, the pig falls out of spit, Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I'm going to hie, and I'll give you the papers...</td>\n",
       "      <td>low</td>\n",
       "      <td>Well, I will hie, And so bestow these papers a...</td>\n",
       "      <td>high</td>\n",
       "      <td>I will hie, and give thee papers as much as th...</td>\n",
       "      <td>I’ll hie, and give thee papers as much as thou w</td>\n",
       "      <td>I will hie, and give thee papers As much as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I'm my lord, are you?</td>\n",
       "      <td>low</td>\n",
       "      <td>Do you know me, my lord?</td>\n",
       "      <td>mid</td>\n",
       "      <td>I am my lord?</td>\n",
       "      <td>I am my lord.</td>\n",
       "      <td>Am I my lord?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>he's a courtier.</td>\n",
       "      <td>low</td>\n",
       "      <td>He hath been a courtier, he swears.</td>\n",
       "      <td>high</td>\n",
       "      <td>He is a courtier.</td>\n",
       "      <td>He’s a courtier.</td>\n",
       "      <td>He is courtier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I'm sure you'll come tomorrow.</td>\n",
       "      <td>low</td>\n",
       "      <td>And I beseech you come again tomorrow.</td>\n",
       "      <td>high</td>\n",
       "      <td>I am sure thou come’st tomorrow.</td>\n",
       "      <td>I am sure thou willst come tomorrow.</td>\n",
       "      <td>I know thou shalt come tomorrow.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paraphrase para_bucket  \\\n",
       "0                       I'm sure you won't marry her.         low   \n",
       "1                       stand in front of the hearse!         low   \n",
       "2   I'm not going to walk out of the door, but som...         low   \n",
       "3                       how do you mean removing him?         mid   \n",
       "4                                  I'm yours forever.         low   \n",
       "..                                                ...         ...   \n",
       "95  the capon burns, the pig falls out of the spit...         mid   \n",
       "96  I'm going to hie, and I'll give you the papers...         low   \n",
       "97                              I'm my lord, are you?         low   \n",
       "98                                   he's a courtier.         low   \n",
       "99                     I'm sure you'll come tomorrow.         low   \n",
       "\n",
       "                                            orig_text oring_bucket  \\\n",
       "0          But thus, I trust, you will not marry her.          mid   \n",
       "1                              Stand from the hearse.          mid   \n",
       "2   I have no will to wander forth of doors, Yet s...         high   \n",
       "3                   How do you mean, removing of him?         high   \n",
       "4                             I am your own for ever.         high   \n",
       "..                                                ...          ...   \n",
       "95  The capon burns; the pig falls from the spit; ...         high   \n",
       "96  Well, I will hie, And so bestow these papers a...         high   \n",
       "97                           Do you know me, my lord?          mid   \n",
       "98                He hath been a courtier, he swears.         high   \n",
       "99             And I beseech you come again tomorrow.         high   \n",
       "\n",
       "                                          transfered1  \\\n",
       "0                   I am sure you will not marry her.   \n",
       "1                       Stand in front of the hearse!   \n",
       "2   I’ll not walk out of the door, But something l...   \n",
       "3                         How mean you to remove him?   \n",
       "4                                 I am yours forever.   \n",
       "..                                                ...   \n",
       "95  The capon burns, the pig falls out of the spit...   \n",
       "96  I will hie, and give thee papers as much as th...   \n",
       "97                                      I am my lord?   \n",
       "98                                  He is a courtier.   \n",
       "99                   I am sure thou come’st tomorrow.   \n",
       "\n",
       "                                          transfered2  \\\n",
       "0                      I know you will not marry her.   \n",
       "1                           Stand in front of hearse!   \n",
       "2   I’ll not walk out of the door, but something l...   \n",
       "3                    How dost thou mean removing him?   \n",
       "4                               I am thyself forever.   \n",
       "..                                                ...   \n",
       "95  The capon burns, the pig falls out of the spit...   \n",
       "96   I’ll hie, and give thee papers as much as thou w   \n",
       "97                                      I am my lord.   \n",
       "98                                   He’s a courtier.   \n",
       "99               I am sure thou willst come tomorrow.   \n",
       "\n",
       "                                          transfered3  \n",
       "0                     I am sure you’ll not marry her.  \n",
       "1                            Stand before the hearse!  \n",
       "2   I will not walk out of the door, But something...  \n",
       "3                          How mean you removing him?  \n",
       "4                              I am thy lord forever.  \n",
       "..                                                ...  \n",
       "95  The capon burns, the pig falls out of spit, Th...  \n",
       "96  I will hie, and give thee papers As much as th...  \n",
       "97                                      Am I my lord?  \n",
       "98                                    He is courtier.  \n",
       "99                   I know thou shalt come tomorrow.  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some results\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>para_bucket</th>\n",
       "      <th>orig_text</th>\n",
       "      <th>oring_bucket</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>I've got a couple of messengers, madam.</td>\n",
       "      <td>low</td>\n",
       "      <td>Ay, madam, twenty several messengers.</td>\n",
       "      <td>high</td>\n",
       "      <td>I have, madam, a couple of messengers.</td>\n",
       "      <td>I have several messengers, madam.</td>\n",
       "      <td>I have some messengers, madam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>I've never heard of it.</td>\n",
       "      <td>low</td>\n",
       "      <td>He never did harm that I heard of.</td>\n",
       "      <td>mid</td>\n",
       "      <td>I never heard of it.</td>\n",
       "      <td>I have never heard of it.</td>\n",
       "      <td>I never heard it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760</th>\n",
       "      <td>he's not going to be admirable.</td>\n",
       "      <td>low</td>\n",
       "      <td>Oh, ’twill be admirable!</td>\n",
       "      <td>high</td>\n",
       "      <td>He will not be admirable.</td>\n",
       "      <td>He shall not be admirable.</td>\n",
       "      <td>He is not admirable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>he hasn't claimed or deserved it.</td>\n",
       "      <td>low</td>\n",
       "      <td>This prince hath neither claimed it nor deserv...</td>\n",
       "      <td>high</td>\n",
       "      <td>He hath not claimed or deserved it.</td>\n",
       "      <td>He hath not claimed or deserved.</td>\n",
       "      <td>He hath not claimed nor deserved it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>he's going to talk to you, are you?</td>\n",
       "      <td>low</td>\n",
       "      <td>He’ll speak with you, will you or no.</td>\n",
       "      <td>mid</td>\n",
       "      <td>Will he speak with you?</td>\n",
       "      <td>Is he going to speak with you?</td>\n",
       "      <td>Shall he speak with you?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paraphrase para_bucket  \\\n",
       "7758  I've got a couple of messengers, madam.         low   \n",
       "7759                  I've never heard of it.         low   \n",
       "7760          he's not going to be admirable.         low   \n",
       "7761        he hasn't claimed or deserved it.         low   \n",
       "7762      he's going to talk to you, are you?         low   \n",
       "\n",
       "                                              orig_text oring_bucket  \\\n",
       "7758              Ay, madam, twenty several messengers.         high   \n",
       "7759                 He never did harm that I heard of.          mid   \n",
       "7760                           Oh, ’twill be admirable!         high   \n",
       "7761  This prince hath neither claimed it nor deserv...         high   \n",
       "7762              He’ll speak with you, will you or no.          mid   \n",
       "\n",
       "                                 transfered1  \\\n",
       "7758  I have, madam, a couple of messengers.   \n",
       "7759                    I never heard of it.   \n",
       "7760               He will not be admirable.   \n",
       "7761     He hath not claimed or deserved it.   \n",
       "7762                 Will he speak with you?   \n",
       "\n",
       "                            transfered2                           transfered3  \n",
       "7758  I have several messengers, madam.        I have some messengers, madam.  \n",
       "7759          I have never heard of it.                     I never heard it.  \n",
       "7760         He shall not be admirable.                  He is not admirable.  \n",
       "7761   He hath not claimed or deserved.  He hath not claimed nor deserved it.  \n",
       "7762     Is he going to speak with you?              Shall he speak with you?  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use classifier for Scoring\n",
    "This may cause GPU memory issues, so it's possible you may have to shutdown the kernel and restart without running the paraphraser first to run this next portion. If doing so, reload the df that was written to disk in several cells above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in desired dataset and classifier model\n",
    "In the cell below, define the dataset you want to work with and the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at ../models/cache/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at ../models/cache/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at ../models/cache/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at ../models/cache/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(model_args_joint.model_name_or_path, \n",
    "                                          cache_dir=model_args_joint.cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args_joint.model_name_or_path, \n",
    "                                          cache_dir=model_args_joint.cache_dir,\n",
    "                                          model_max_length = data_args_joint.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.43it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81523, 64]) torch.Size([81523, 64]) torch.Size([81523, 2]) torch.Size([81523])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.44it/s]\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([113262, 64]) torch.Size([113262, 64]) torch.Size([113262, 2]) torch.Size([113262])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.95it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20306, 64]) torch.Size([20306, 64]) torch.Size([20306, 2]) torch.Size([20306])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28322, 64]) torch.Size([28322, 64]) torch.Size([28322, 2]) torch.Size([28322])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data as expected by joint classifier\n",
    "tasks = data_args_joint.task.split('+')\n",
    "train_dataset, idx_to_classes = jld(data_args_joint.data_dir, \n",
    "                                             tokenizer, \n",
    "                                             model_name=model_args_joint.model_name_or_path, \n",
    "                           tasks=tasks, mode=\"train\", n_proc=6000)\n",
    "dev_dataset, _ = jld(data_args_joint.data_dir, \n",
    "                              tokenizer, \n",
    "                              model_name=model_args_joint.model_name_or_path, \n",
    "                              tasks=tasks, mode=\"dev\", n_proc=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 1, 'shakespeare': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dims = {task : 1 if len(list(idx_to_classes[task].keys())) == 2 else len(list(idx_to_classes[task].keys())) for task in idx_to_classes}\n",
    "label_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/distilbert_uncased_2/abstract+shakespeare/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"JointSeqClassifier\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../models/distilbert_uncased_2/abstract+shakespeare/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing JointSeqClassifier.\n",
      "\n",
      "All the weights of JointSeqClassifier were initialized from the model checkpoint at ../models/distilbert_uncased_2/abstract+shakespeare.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use JointSeqClassifier for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "joint_model = JointSeqClassifier.from_pretrained(os.path.join(output_dir,\n",
    "                                                              model_args_joint.model_nick, joint_task),\n",
    "                                           tasks=tasks,\n",
    "                                           model_args=model_args_joint,\n",
    "                                           task_if_single=None, \n",
    "                                           joint = training_args_joint.train_jointly,\n",
    "                                           label_dims=label_dims)\n",
    "\n",
    "trainer = JointTrainer([training_args_joint,model_args_joint, data_args_joint], \n",
    "                       joint_model, train_dataset, dev_dataset, idx_to_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run classifier on paraphrased and original text\n",
    "\n",
    "This is currently done with pd DataFrames but could probably be made better by using a batch data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract', 'shakespeare']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_paraphrases(row, tasks, cols):\n",
    "    '''\n",
    "    Make style predictions on a given df row for a given set of text columns\n",
    "    and classification tasks. \n",
    "    '''\n",
    "    preds = {}\n",
    "    for col in cols:\n",
    "        sentence = row[col]\n",
    "        out = trainer.predict_for_sentence(sentence, tokenizer)\n",
    "        for task in tasks:\n",
    "            pred = float(out[task]['prob'])\n",
    "            preds[task + '_' + col] = pred\n",
    "    return preds\n",
    "\n",
    "def get_best_pred(row, cols, target_val=0.5):\n",
    "    '''\n",
    "    Helper funtion for determiningg which paraphrase is 'best' \n",
    "    for a given set of paraphrase column style scores and a target value\n",
    "    that you want the scores to be close to. Currently just outputs the best score\n",
    "    but could be modified to get best sentence as well.\n",
    "    '''\n",
    "    best_diff = 1\n",
    "    best_val = None\n",
    "    for col in cols:\n",
    "        diff = abs(row[col] - target_val)\n",
    "        if diff < best_diff:\n",
    "            best_val = row[col]\n",
    "            best_diff = diff\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7763/7763 [04:05<00:00, 31.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define columns on which to run the classification\n",
    "cols_to_use = ['paraphrase','transfered1', 'transfered2', 'transfered3']\n",
    "# Define the names of the columns where the output scores will be stored\n",
    "cols_preds = [f'pred_{tasks[0]}_orig', f'pred_{tasks[1]}_orig',\n",
    "              f'pred_{tasks[0]}_transfered1', f'pred_{tasks[1]}_transfered1',\n",
    "              f'pred_{tasks[0]}_transfered2', f'pred_{tasks[1]}_transfered2',\n",
    "              f'pred_{tasks[0]}_transfered3', f'pred_{tasks[1]}_transfered3']\n",
    "# Store results into df\n",
    "df[cols_preds] = df.progress_apply(lambda x : pred_paraphrases(x, tasks, cols_to_use), \n",
    "                                   axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results of style classification:\n",
    "out_filename = paraphrase_task + f'_{mode}_cross_predict_transfers.csv'\n",
    "\n",
    "df.to_csv(os.path.join(data_dir, prompt_task, out_filename), header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the results of the transfer for style changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>para_bucket</th>\n",
       "      <th>orig_text</th>\n",
       "      <th>oring_bucket</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "      <th>pred_abstract_orig</th>\n",
       "      <th>pred_shakespeare_orig</th>\n",
       "      <th>pred_abstract_transfered1</th>\n",
       "      <th>pred_shakespeare_transfered1</th>\n",
       "      <th>pred_abstract_transfered2</th>\n",
       "      <th>pred_shakespeare_transfered2</th>\n",
       "      <th>pred_abstract_transfered3</th>\n",
       "      <th>pred_shakespeare_transfered3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure you won't marry her.</td>\n",
       "      <td>low</td>\n",
       "      <td>But thus, I trust, you will not marry her.</td>\n",
       "      <td>mid</td>\n",
       "      <td>I am sure you will not marry her.</td>\n",
       "      <td>I know you will not marry her.</td>\n",
       "      <td>I am sure you’ll not marry her.</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.050229</td>\n",
       "      <td>0.122297</td>\n",
       "      <td>0.998928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stand in front of the hearse!</td>\n",
       "      <td>low</td>\n",
       "      <td>Stand from the hearse.</td>\n",
       "      <td>mid</td>\n",
       "      <td>Stand in front of the hearse!</td>\n",
       "      <td>Stand in front of hearse!</td>\n",
       "      <td>Stand before the hearse!</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>0.062622</td>\n",
       "      <td>0.998390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not going to walk out of the door, but som...</td>\n",
       "      <td>low</td>\n",
       "      <td>I have no will to wander forth of doors, Yet s...</td>\n",
       "      <td>high</td>\n",
       "      <td>I’ll not walk out of the door, But something l...</td>\n",
       "      <td>I’ll not walk out of the door, but something l...</td>\n",
       "      <td>I will not walk out of the door, But something...</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.164337</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>0.164337</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.026706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do you mean removing him?</td>\n",
       "      <td>mid</td>\n",
       "      <td>How do you mean, removing of him?</td>\n",
       "      <td>high</td>\n",
       "      <td>How mean you to remove him?</td>\n",
       "      <td>How dost thou mean removing him?</td>\n",
       "      <td>How mean you removing him?</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.981065</td>\n",
       "      <td>0.204749</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.006354</td>\n",
       "      <td>0.977889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm yours forever.</td>\n",
       "      <td>low</td>\n",
       "      <td>I am your own for ever.</td>\n",
       "      <td>high</td>\n",
       "      <td>I am yours forever.</td>\n",
       "      <td>I am thyself forever.</td>\n",
       "      <td>I am thy lord forever.</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.058799</td>\n",
       "      <td>0.997922</td>\n",
       "      <td>0.229949</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.320483</td>\n",
       "      <td>0.999098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>the capon burns, the pig falls out of the spit...</td>\n",
       "      <td>mid</td>\n",
       "      <td>The capon burns; the pig falls from the spit; ...</td>\n",
       "      <td>high</td>\n",
       "      <td>The capon burns, the pig falls out of the spit...</td>\n",
       "      <td>The capon burns, the pig falls out of the spit...</td>\n",
       "      <td>The capon burns, the pig falls out of spit, Th...</td>\n",
       "      <td>0.138432</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.961486</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.961486</td>\n",
       "      <td>0.029663</td>\n",
       "      <td>0.993786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I'm going to hie, and I'll give you the papers...</td>\n",
       "      <td>low</td>\n",
       "      <td>Well, I will hie, And so bestow these papers a...</td>\n",
       "      <td>high</td>\n",
       "      <td>I will hie, and give thee papers as much as th...</td>\n",
       "      <td>I’ll hie, and give thee papers as much as thou w</td>\n",
       "      <td>I will hie, and give thee papers As much as th...</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.276824</td>\n",
       "      <td>0.999133</td>\n",
       "      <td>0.307574</td>\n",
       "      <td>0.999119</td>\n",
       "      <td>0.276824</td>\n",
       "      <td>0.999133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I'm my lord, are you?</td>\n",
       "      <td>low</td>\n",
       "      <td>Do you know me, my lord?</td>\n",
       "      <td>mid</td>\n",
       "      <td>I am my lord?</td>\n",
       "      <td>I am my lord.</td>\n",
       "      <td>Am I my lord?</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.874076</td>\n",
       "      <td>0.278475</td>\n",
       "      <td>0.999096</td>\n",
       "      <td>0.251299</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.276162</td>\n",
       "      <td>0.999099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>he's a courtier.</td>\n",
       "      <td>low</td>\n",
       "      <td>He hath been a courtier, he swears.</td>\n",
       "      <td>high</td>\n",
       "      <td>He is a courtier.</td>\n",
       "      <td>He’s a courtier.</td>\n",
       "      <td>He is courtier.</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.165066</td>\n",
       "      <td>0.998896</td>\n",
       "      <td>0.334452</td>\n",
       "      <td>0.999019</td>\n",
       "      <td>0.202655</td>\n",
       "      <td>0.998996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I'm sure you'll come tomorrow.</td>\n",
       "      <td>low</td>\n",
       "      <td>And I beseech you come again tomorrow.</td>\n",
       "      <td>high</td>\n",
       "      <td>I am sure thou come’st tomorrow.</td>\n",
       "      <td>I am sure thou willst come tomorrow.</td>\n",
       "      <td>I know thou shalt come tomorrow.</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.315657</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.282092</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.313481</td>\n",
       "      <td>0.999102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paraphrase para_bucket  \\\n",
       "0                       I'm sure you won't marry her.         low   \n",
       "1                       stand in front of the hearse!         low   \n",
       "2   I'm not going to walk out of the door, but som...         low   \n",
       "3                       how do you mean removing him?         mid   \n",
       "4                                  I'm yours forever.         low   \n",
       "..                                                ...         ...   \n",
       "95  the capon burns, the pig falls out of the spit...         mid   \n",
       "96  I'm going to hie, and I'll give you the papers...         low   \n",
       "97                              I'm my lord, are you?         low   \n",
       "98                                   he's a courtier.         low   \n",
       "99                     I'm sure you'll come tomorrow.         low   \n",
       "\n",
       "                                            orig_text oring_bucket  \\\n",
       "0          But thus, I trust, you will not marry her.          mid   \n",
       "1                              Stand from the hearse.          mid   \n",
       "2   I have no will to wander forth of doors, Yet s...         high   \n",
       "3                   How do you mean, removing of him?         high   \n",
       "4                             I am your own for ever.         high   \n",
       "..                                                ...          ...   \n",
       "95  The capon burns; the pig falls from the spit; ...         high   \n",
       "96  Well, I will hie, And so bestow these papers a...         high   \n",
       "97                           Do you know me, my lord?          mid   \n",
       "98                He hath been a courtier, he swears.         high   \n",
       "99             And I beseech you come again tomorrow.         high   \n",
       "\n",
       "                                          transfered1  \\\n",
       "0                   I am sure you will not marry her.   \n",
       "1                       Stand in front of the hearse!   \n",
       "2   I’ll not walk out of the door, But something l...   \n",
       "3                         How mean you to remove him?   \n",
       "4                                 I am yours forever.   \n",
       "..                                                ...   \n",
       "95  The capon burns, the pig falls out of the spit...   \n",
       "96  I will hie, and give thee papers as much as th...   \n",
       "97                                      I am my lord?   \n",
       "98                                  He is a courtier.   \n",
       "99                   I am sure thou come’st tomorrow.   \n",
       "\n",
       "                                          transfered2  \\\n",
       "0                      I know you will not marry her.   \n",
       "1                           Stand in front of hearse!   \n",
       "2   I’ll not walk out of the door, but something l...   \n",
       "3                    How dost thou mean removing him?   \n",
       "4                               I am thyself forever.   \n",
       "..                                                ...   \n",
       "95  The capon burns, the pig falls out of the spit...   \n",
       "96   I’ll hie, and give thee papers as much as thou w   \n",
       "97                                      I am my lord.   \n",
       "98                                   He’s a courtier.   \n",
       "99               I am sure thou willst come tomorrow.   \n",
       "\n",
       "                                          transfered3  pred_abstract_orig  \\\n",
       "0                     I am sure you’ll not marry her.            0.000403   \n",
       "1                            Stand before the hearse!            0.000320   \n",
       "2   I will not walk out of the door, But something...            0.000409   \n",
       "3                          How mean you removing him?            0.000276   \n",
       "4                              I am thy lord forever.            0.000332   \n",
       "..                                                ...                 ...   \n",
       "95  The capon burns, the pig falls out of spit, Th...            0.138432   \n",
       "96  I will hie, and give thee papers As much as th...            0.000431   \n",
       "97                                      Am I my lord?            0.002302   \n",
       "98                                    He is courtier.            0.000288   \n",
       "99                   I know thou shalt come tomorrow.            0.000351   \n",
       "\n",
       "    pred_shakespeare_orig  pred_abstract_transfered1  \\\n",
       "0                0.000557                   0.000232   \n",
       "1                0.012139                   0.000320   \n",
       "2                0.000621                   0.164337   \n",
       "3                0.000980                   0.006401   \n",
       "4                0.000957                   0.058799   \n",
       "..                    ...                        ...   \n",
       "95               0.998865                   0.007343   \n",
       "96               0.000553                   0.276824   \n",
       "97               0.874076                   0.278475   \n",
       "98               0.003029                   0.165066   \n",
       "99               0.000657                   0.315657   \n",
       "\n",
       "    pred_shakespeare_transfered1  pred_abstract_transfered2  \\\n",
       "0                       0.002530                   0.000307   \n",
       "1                       0.012139                   0.000438   \n",
       "2                       0.998977                   0.164337   \n",
       "3                       0.981065                   0.204749   \n",
       "4                       0.997922                   0.229949   \n",
       "..                           ...                        ...   \n",
       "95                      0.961486                   0.007343   \n",
       "96                      0.999133                   0.307574   \n",
       "97                      0.999096                   0.251299   \n",
       "98                      0.998896                   0.334452   \n",
       "99                      0.999105                   0.282092   \n",
       "\n",
       "    pred_shakespeare_transfered2  pred_abstract_transfered3  \\\n",
       "0                       0.050229                   0.122297   \n",
       "1                       0.040431                   0.062622   \n",
       "2                       0.998977                   0.000302   \n",
       "3                       0.998964                   0.006354   \n",
       "4                       0.999094                   0.320483   \n",
       "..                           ...                        ...   \n",
       "95                      0.961486                   0.029663   \n",
       "96                      0.999119                   0.276824   \n",
       "97                      0.999111                   0.276162   \n",
       "98                      0.999019                   0.202655   \n",
       "99                      0.999115                   0.313481   \n",
       "\n",
       "    pred_shakespeare_transfered3  \n",
       "0                       0.998928  \n",
       "1                       0.998390  \n",
       "2                       0.026706  \n",
       "3                       0.977889  \n",
       "4                       0.999098  \n",
       "..                           ...  \n",
       "95                      0.993786  \n",
       "96                      0.999133  \n",
       "97                      0.999099  \n",
       "98                      0.998996  \n",
       "99                      0.999102  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'{prompt_task}_diff1'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered1'])\n",
    "df[f'{prompt_task}_diff2'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered2'])\n",
    "df[f'{prompt_task}_diff3'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'{prompt_task}_diff_max'] = df.apply(lambda x : np.max([x[f'{prompt_task}_diff1'], \n",
    "                                                       x[f'{prompt_task}_diff2'], \n",
    "                                                       x[f'{prompt_task}_diff3']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at best sytle difference summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7763.000000\n",
       "mean        0.759769\n",
       "std         0.391638\n",
       "min         0.000000\n",
       "25%         0.630386\n",
       "50%         0.996468\n",
       "75%         0.998343\n",
       "max         0.998648\n",
       "Name: shakespeare_diff_max, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's disaggregate by class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paraphrase', 'para_bucket', 'orig_text', 'oring_bucket', 'transfered1',\n",
       "       'transfered2', 'transfered3', 'pred_abstract_orig',\n",
       "       'pred_shakespeare_orig', 'pred_abstract_transfered1',\n",
       "       'pred_shakespeare_transfered1', 'pred_abstract_transfered2',\n",
       "       'pred_shakespeare_transfered2', 'pred_abstract_transfered3',\n",
       "       'pred_shakespeare_transfered3', 'shakespeare_diff1',\n",
       "       'shakespeare_diff2', 'shakespeare_diff3', 'shakespeare_diff_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6324.000000\n",
       "mean        0.835582\n",
       "std         0.333153\n",
       "min         0.000000\n",
       "25%         0.957236\n",
       "50%         0.997673\n",
       "75%         0.998396\n",
       "max         0.998648\n",
       "Name: shakespeare_diff_max, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['para_bucket']=='low'][f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1439.000000\n",
       "mean        0.426594\n",
       "std         0.451128\n",
       "min         0.000000\n",
       "25%         0.001393\n",
       "50%         0.132307\n",
       "75%         0.986538\n",
       "max         0.998554\n",
       "Name: shakespeare_diff_max, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['para_bucket']=='mid'][f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paraphrase                              I'm sure you'll come tomorrow.\n",
       "para_bucket                                                        low\n",
       "orig_text                       And I beseech you come again tomorrow.\n",
       "oring_bucket                                                      high\n",
       "transfered1                           I am sure thou come’st tomorrow.\n",
       "transfered2                       I am sure thou willst come tomorrow.\n",
       "transfered3                           I know thou shalt come tomorrow.\n",
       "pred_abstract_orig                                            0.000351\n",
       "pred_shakespeare_orig                                         0.000657\n",
       "pred_abstract_transfered1                                     0.315657\n",
       "pred_shakespeare_transfered1                                  0.999105\n",
       "pred_abstract_transfered2                                     0.282092\n",
       "pred_shakespeare_transfered2                                  0.999115\n",
       "pred_abstract_transfered3                                     0.313481\n",
       "pred_shakespeare_transfered3                                  0.999102\n",
       "shakespeare_diff1                                             0.998448\n",
       "shakespeare_diff2                                             0.998458\n",
       "shakespeare_diff3                                             0.998445\n",
       "shakespeare_diff_max                                          0.998458\n",
       "Name: 99, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_marvin)",
   "language": "python",
   "name": "env_marvin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "70745de62fac122a8ca1204278c5668179019927655d931b4063a8c34fb0e461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
