{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generate Some Transfered Sentences and get Style Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_dataset_pseudo' from 'paraphraser_dataloader' (../paraphrase/paraphraser_dataloader.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0f9e4478bb7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparaphraser_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelArguments\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTrainingArguments\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparaphraser_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset_style\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mparaphraser_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset_pseudo\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mldp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparaphraser_trainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParaphraserTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHfArgumentParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_dataset_pseudo' from 'paraphraser_dataloader' (../paraphrase/paraphraser_dataloader.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys, os\n",
    "import numpy as np\n",
    "sys.path.append('../paraphrase/')\n",
    "sys.path.append('../jointclassifier/')\n",
    "from paraphraser_args import ModelArguments as pma, DataTrainingArguments as pda, TrainingArguments as pta\n",
    "from paraphraser_dataloader import load_dataset as pld, load_dataset_style as lds\n",
    "from paraphraser_dataloader import load_dataset_pseudo as ldp\n",
    "from paraphraser_trainer import ParaphraserTrainer\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelWithLMHead, HfArgumentParser\n",
    "from joint_args import ModelArguments as jma, DataTrainingArguments as jda, TrainingArguments as jta\n",
    "from joint_dataloader import load_dataset as jld\n",
    "from joint_trainer import JointTrainer\n",
    "from joint_model_v1 import JointSeqClassifier\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch import cuda, no_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in desired dataset and paraphraser model\n",
    "In the cell below, define the dataset you want to work with and the paraphraser model (here a `\"t5-small\"` [from Hugging Face](https://huggingface.co/t5-small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/shakespeare/'\n",
    "#\"../data/processed_filtered/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "paraphrase_model_name = \"t5_transfer_shakespeare\"\n",
    "paraphrase_task = 'shakespeare'\n",
    "prompt_task = paraphrase_task + \"_prompt\"\n",
    "\n",
    "\n",
    "paraphrase_model_nick = \"t5_transfer_shakespeare\"\n",
    "paraphrase_model_type = 't5-small'\n",
    "output_dir = \"../models/\"\n",
    "epochs = \"3\"\n",
    "train_batch_size = \"16\"\n",
    "eval_batch_size = \"16\"\n",
    "save_log_steps = \"400\"\n",
    "\n",
    "parser = HfArgumentParser((pma, pda, pta))\n",
    "model_args_para, data_args_para, training_args_para = parser.parse_args_into_dataclasses([\n",
    "    \"--model_name_or_path\",\n",
    "    paraphrase_model_name,\n",
    "    \"--model_nick\",\n",
    "    paraphrase_model_nick,\n",
    "    \"--data_dir\",\n",
    "    data_dir,\n",
    "    \"--output_dir\",\n",
    "    os.path.join(output_dir, paraphrase_model_nick),\n",
    "    \"--cache_dir\",\n",
    "    os.path.join(output_dir,\"cache\"),\n",
    "    \"--overwrite_cache\",\n",
    "    \"--per_device_train_batch_size\",\n",
    "    train_batch_size,\n",
    "    \"--per_device_eval_batch_size\",\n",
    "    eval_batch_size,\n",
    "    \"--max_seq_len\",\n",
    "    \"64\",\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    \"1\",\n",
    "    \"--num_train_epochs\",\n",
    "    epochs,\n",
    "    \"--logging_steps\",\n",
    "    save_log_steps,\n",
    "    \"--save_steps\",\n",
    "    save_log_steps,\n",
    "    \"--data_parallel\",\n",
    "    \"True\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "joint_task = \"abstract+shakespeare\" #\"formality+emo\"\n",
    "data_dir = \"../data/processed_filtered/\"\n",
    "joint_model_name = \"distilbert-base-uncased\"\n",
    "joint_model_nick = \"distilbert_uncased_2\"\n",
    "output_dir = \"../models/\"\n",
    "freeze_encoder = \"False\"\n",
    "skip_preclassifier = \"False\"\n",
    "train_jointly = \"True\"\n",
    "epochs = \"5\"\n",
    "train_batch_size = \"256\"\n",
    "eval_batch_size = \"512\"\n",
    "log_save_steps = \"200\"\n",
    "\n",
    "parser = HfArgumentParser((jma, jda, jta))\n",
    "model_args_joint, data_args_joint, training_args_joint = parser.parse_args_into_dataclasses([\n",
    "    \"--model_name_or_path\",\n",
    "    joint_model_name,\n",
    "    \"--model_nick\",\n",
    "    joint_model_nick,\n",
    "    \"--task\",\n",
    "    joint_task,\n",
    "    \"--data_dir\",\n",
    "    data_dir,\n",
    "    \"--output_dir\",\n",
    "    os.path.join(output_dir, joint_model_nick, joint_task, 'joint'),\n",
    "    \"--cache_dir\",\n",
    "    os.path.join(output_dir,\"cache\"),\n",
    "    \"--freeze_encoder\",\n",
    "    freeze_encoder,\n",
    "    \"--skip_preclassifier\",\n",
    "    skip_preclassifier,\n",
    "    \"--train_jointly\",\n",
    "    train_jointly,\n",
    "    \"--overwrite_cache\",\n",
    "    \"--per_device_train_batch_size\",\n",
    "    train_batch_size,\n",
    "    \"--per_device_eval_batch_size\",\n",
    "    eval_batch_size,\n",
    "    \"--max_seq_len\",\n",
    "    \"64\",\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    \"1\",\n",
    "    \"--num_train_epochs\",\n",
    "    epochs,\n",
    "    \"--logging_steps\",\n",
    "    log_save_steps,\n",
    "    \"--save_steps\",\n",
    "    log_save_steps\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at ../models/cache/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at ../models/cache/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
      "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at ../models/cache/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/shakespeare/shakespeare_prompt/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5d0e612db63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m para_tokenizer = AutoTokenizer.from_pretrained(paraphrase_model_type, cache_dir=model_args_para.cache_dir,\n\u001b[1;32m      3\u001b[0m                                          model_max_length = data_args_para.max_seq_len)\n\u001b[0;32m----> 4\u001b[0;31m dataset = lds(data_dir, para_tokenizer,\n\u001b[0m\u001b[1;32m      5\u001b[0m                             task=prompt_task, mode=\"train\", n_proc=6000)\n",
      "\u001b[0;32m~/Documents/MIMS Coursework/Capstone/marvin/ml/paraphrase/paraphraser_dataloader.py\u001b[0m in \u001b[0;36mload_dataset_style\u001b[0;34m(data_dir, tokenizer, mode, task, delimiter, prefix, n_proc)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mall_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/shakespeare/shakespeare_prompt/config.json'"
     ]
    }
   ],
   "source": [
    "# Create the paraphraser tokenizer and dataset objects\n",
    "para_tokenizer = AutoTokenizer.from_pretrained(paraphrase_model_type, cache_dir=model_args_para.cache_dir,\n",
    "                                         model_max_length = data_args_para.max_seq_len)\n",
    "dataset = ldp(data_dir, para_tokenizer,\n",
    "                            task=prompt_task, mode=\"train\", n_proc=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmac/Documents/MIMS Coursework/Capstone/env_marvin/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:966: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "loading configuration file ../models/t5_transfer_shakespeare/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file ../models/t5_transfer_shakespeare/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at ../models/t5_transfer_shakespeare.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Use the paraphrase configuration defined above to create the model\n",
    "model = AutoModelWithLMHead.from_pretrained(os.path.join(output_dir, paraphrase_model_name))\n",
    "#training_args_para.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Paraphraser to Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836bd16673e440c4ba5556d38dbf0764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1984.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = SequentialSampler(dataset)\n",
    "dataloader = DataLoader(dataset, sampler=sampler, batch_size=16)\n",
    "\n",
    "num_return_sequences = 3\n",
    "\n",
    "device = (\"cuda\" if cuda.is_available() else \"cpu\") #and not self.args.no_cuda\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "predicted1 = []\n",
    "predicted2 = []\n",
    "predicted3 = []\n",
    "\n",
    "epoch_iterator = tqdm(dataloader, desc=\"Iteration\")\n",
    "with no_grad():\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.to(device) for t in batch)  # GPU or CPU\n",
    "        generated_outputs = model.generate(input_ids= batch[0], \n",
    "                                           attention_mask = batch[1], \n",
    "                                           num_return_sequences = num_return_sequences, \n",
    "                                           num_beams = 12)\n",
    "        paras = para_tokenizer.batch_decode(generated_outputs.detach().cpu().numpy(), \n",
    "                                                 skip_special_tokens=True)\n",
    "        predicted1 += paras[0::3]\n",
    "        predicted2 += paras[1::3]\n",
    "        predicted3 += paras[2::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outputs to disk using in_filename as the original texts \n",
    "# and writing outputs to out_filename\n",
    "\n",
    "# If you want to do other parts of the dataset other than train, \n",
    "# set the mode in 'dataset' above to the desired mode and then rerun the paraphrase\n",
    "# and change these filenames to point to the slice of the data you want to use (dev, test, etc.)\n",
    "in_filename = 'train.csv'\n",
    "out_filename = 'train_transfered.csv'\n",
    "\n",
    "df_para = pd.DataFrame(data={'transfered1' : predicted1, \n",
    "                             'transfered2' : predicted2, \n",
    "                             'transfered3' : predicted3}) \n",
    "df = pd.read_csv(os.path.join(data_dir, paraphrase_task, in_filename), names =['text', 'label'])\n",
    "df['transfered1'] = df_para['transfered1']\n",
    "df['transfered2'] = df_para['transfered2']\n",
    "df['transfered3'] = df_para['transfered3']\n",
    "df.to_csv(os.path.join(data_dir, prompt_task, out_filename), \n",
    "               header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have not read them i have only seen the firs...</td>\n",
       "      <td>0</td>\n",
       "      <td>I have not read them i' th' first movie.</td>\n",
       "      <td>I have not read them, i' th' first movie i' th</td>\n",
       "      <td>I have not read them, i' th' first movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I know they are stupid, and hardly make any se...</td>\n",
       "      <td>0</td>\n",
       "      <td>I know they are stupid, and hardly make any se...</td>\n",
       "      <td>I know they are stupid, and make no sense at all.</td>\n",
       "      <td>I know they are stupid, and hardly make any se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>put more in what you right</td>\n",
       "      <td>0</td>\n",
       "      <td>Put more in what thou hast righted.</td>\n",
       "      <td>Put more in what thou hath righted.</td>\n",
       "      <td>Put more in what thou right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Give it a miss and get some N.W.A.</td>\n",
       "      <td>0</td>\n",
       "      <td>Give it miss and get some N.W.A.</td>\n",
       "      <td>Give it miss, and get some N.W.A.</td>\n",
       "      <td>Give it misses and get some N.W.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flash, because that is his only power.</td>\n",
       "      <td>0</td>\n",
       "      <td>Flash, for that is his only power.</td>\n",
       "      <td>Flash, for that is only his power.</td>\n",
       "      <td>Flash, for that is his power only.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Let every eye nogetiate for itself And trust n...</td>\n",
       "      <td>1</td>\n",
       "      <td>Let every eye nogetiate for itself And trust n...</td>\n",
       "      <td>Let every eye nogetiate For itself And trust n...</td>\n",
       "      <td>Let every eye nogetiate for itself And trust n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>it just means you have moved on to accept that...</td>\n",
       "      <td>0</td>\n",
       "      <td>It just means you have moved on to accept that...</td>\n",
       "      <td>This just means you have moved on to accept th...</td>\n",
       "      <td>It just means that you have moved on to accept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>there's no problem falling in love with your g...</td>\n",
       "      <td>0</td>\n",
       "      <td>There’s no problem falling in love with your g...</td>\n",
       "      <td>There’s no problem in falling in love with you...</td>\n",
       "      <td>There is no problem in falling in love with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MY CHICKEN I VERY FUNKY HE HAS RED SPOTS AND Y...</td>\n",
       "      <td>0</td>\n",
       "      <td>I VERY FUNKY HE HAS RED SPOTS AND YEL</td>\n",
       "      <td>MY CHICKEN I VERY FUNKY HE HAS RED SPO</td>\n",
       "      <td>My CHICKEN I VERY FUNKY HE HAS RED SPOTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>thats why i didnt buy the icrap.</td>\n",
       "      <td>0</td>\n",
       "      <td>That is why i did not buy the icrap.</td>\n",
       "      <td>That is the reason i did buy the icrap.</td>\n",
       "      <td>That’s why i did buy the icrap.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  \\\n",
       "0   i have not read them i have only seen the firs...      0   \n",
       "1   I know they are stupid, and hardly make any se...      0   \n",
       "2                          put more in what you right      0   \n",
       "3                  Give it a miss and get some N.W.A.      0   \n",
       "4              Flash, because that is his only power.      0   \n",
       "..                                                ...    ...   \n",
       "95  Let every eye nogetiate for itself And trust n...      1   \n",
       "96  it just means you have moved on to accept that...      0   \n",
       "97  there's no problem falling in love with your g...      0   \n",
       "98  MY CHICKEN I VERY FUNKY HE HAS RED SPOTS AND Y...      0   \n",
       "99                   thats why i didnt buy the icrap.      0   \n",
       "\n",
       "                                          transfered1  \\\n",
       "0            I have not read them i' th' first movie.   \n",
       "1   I know they are stupid, and hardly make any se...   \n",
       "2                 Put more in what thou hast righted.   \n",
       "3                    Give it miss and get some N.W.A.   \n",
       "4                  Flash, for that is his only power.   \n",
       "..                                                ...   \n",
       "95  Let every eye nogetiate for itself And trust n...   \n",
       "96  It just means you have moved on to accept that...   \n",
       "97  There’s no problem falling in love with your g...   \n",
       "98              I VERY FUNKY HE HAS RED SPOTS AND YEL   \n",
       "99               That is why i did not buy the icrap.   \n",
       "\n",
       "                                          transfered2  \\\n",
       "0      I have not read them, i' th' first movie i' th   \n",
       "1   I know they are stupid, and make no sense at all.   \n",
       "2                 Put more in what thou hath righted.   \n",
       "3                   Give it miss, and get some N.W.A.   \n",
       "4                  Flash, for that is only his power.   \n",
       "..                                                ...   \n",
       "95  Let every eye nogetiate For itself And trust n...   \n",
       "96  This just means you have moved on to accept th...   \n",
       "97  There’s no problem in falling in love with you...   \n",
       "98             MY CHICKEN I VERY FUNKY HE HAS RED SPO   \n",
       "99            That is the reason i did buy the icrap.   \n",
       "\n",
       "                                          transfered3  \n",
       "0           I have not read them, i' th' first movie.  \n",
       "1   I know they are stupid, and hardly make any se...  \n",
       "2                        Put more in what thou right?  \n",
       "3                  Give it misses and get some N.W.A.  \n",
       "4                  Flash, for that is his power only.  \n",
       "..                                                ...  \n",
       "95  Let every eye nogetiate for itself And trust n...  \n",
       "96  It just means that you have moved on to accept...  \n",
       "97  There is no problem in falling in love with th...  \n",
       "98           My CHICKEN I VERY FUNKY HE HAS RED SPOTS  \n",
       "99                    That’s why i did buy the icrap.  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some results\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31734</th>\n",
       "      <td>Why then, God’s soldier be he!</td>\n",
       "      <td>1</td>\n",
       "      <td>Why then, God’s soldier be he!</td>\n",
       "      <td>Why then, God be a soldier!</td>\n",
       "      <td>Why then, God’s soldier be he.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31735</th>\n",
       "      <td>If he cheated once odds are he will again.</td>\n",
       "      <td>0</td>\n",
       "      <td>If he cheated once odds are, he will again.</td>\n",
       "      <td>If he cheated once odds are he will again.</td>\n",
       "      <td>If he cheated once odds are, then he will again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31736</th>\n",
       "      <td>In me ’tis villainy, In thee ’t had been good ...</td>\n",
       "      <td>1</td>\n",
       "      <td>In me ’tis villainy, In thee ’twas good service.</td>\n",
       "      <td>Paraphrase: In me ’tis villainy, In thee ’twas</td>\n",
       "      <td>In me ’tis villainy, In thee ’t had been good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31737</th>\n",
       "      <td>It is perfectly fine. People who are gay shoul...</td>\n",
       "      <td>0</td>\n",
       "      <td>It is perfectly fine. People that are gay shou...</td>\n",
       "      <td>It is perfectly fine, and those that are gay s...</td>\n",
       "      <td>It is perfectly fine. People who are gay shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31738</th>\n",
       "      <td>Some never, some sometimes &amp; some all the time...</td>\n",
       "      <td>0</td>\n",
       "      <td>Some never, some sometimes &amp; some all the time...</td>\n",
       "      <td>Some never, Some sometimes &amp; some all the time...</td>\n",
       "      <td>Some never, some sometimes &amp; some all the time...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "31734                     Why then, God’s soldier be he!      1   \n",
       "31735         If he cheated once odds are he will again.      0   \n",
       "31736  In me ’tis villainy, In thee ’t had been good ...      1   \n",
       "31737  It is perfectly fine. People who are gay shoul...      0   \n",
       "31738  Some never, some sometimes & some all the time...      0   \n",
       "\n",
       "                                             transfered1  \\\n",
       "31734                     Why then, God’s soldier be he!   \n",
       "31735        If he cheated once odds are, he will again.   \n",
       "31736   In me ’tis villainy, In thee ’twas good service.   \n",
       "31737  It is perfectly fine. People that are gay shou...   \n",
       "31738  Some never, some sometimes & some all the time...   \n",
       "\n",
       "                                             transfered2  \\\n",
       "31734                        Why then, God be a soldier!   \n",
       "31735         If he cheated once odds are he will again.   \n",
       "31736     Paraphrase: In me ’tis villainy, In thee ’twas   \n",
       "31737  It is perfectly fine, and those that are gay s...   \n",
       "31738  Some never, Some sometimes & some all the time...   \n",
       "\n",
       "                                             transfered3  \n",
       "31734                     Why then, God’s soldier be he.  \n",
       "31735   If he cheated once odds are, then he will again.  \n",
       "31736  In me ’tis villainy, In thee ’t had been good ...  \n",
       "31737  It is perfectly fine. People who are gay shoul...  \n",
       "31738  Some never, some sometimes & some all the time...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use classifier for Scoring\n",
    "This may cause GPU memory issues, so it's possible you may have to shutdown the kernel and restart without running the paraphraser first to run this next portion. If doing so, reload the df that was written to disk in several cells above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in desired dataset and classifier model\n",
    "In the cell below, define the dataset you want to work with and the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at ../models/cache/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at ../models/cache/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at ../models/cache/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at ../models/cache/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(model_args_joint.model_name_or_path, \n",
    "                                          cache_dir=model_args_joint.cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args_joint.model_name_or_path, \n",
    "                                          cache_dir=model_args_joint.cache_dir,\n",
    "                                          model_max_length = data_args_joint.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed_filtered/abstract/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-21cc15e52b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data as expected by joint classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_args_joint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_dataset, idx_to_classes = jld(data_args_joint.data_dir, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                              \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                              \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_args_joint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MIMS Coursework/Capstone/marvin/ml/jointclassifier/joint_dataloader.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(data_dir, tokenizer, model_name, tasks, mode, n_proc)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0midx_to_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed_filtered/abstract/config.json'"
     ]
    }
   ],
   "source": [
    "# Load data as expected by joint classifier\n",
    "tasks = data_args_joint.task.split('+')\n",
    "train_dataset, idx_to_classes = jld(data_args_joint.data_dir, \n",
    "                                             tokenizer, \n",
    "                                             model_name=model_args_joint.model_name_or_path, \n",
    "                           tasks=tasks, mode=\"train\", n_proc=6000)\n",
    "dev_dataset, _ = jld(data_args_joint.data_dir, \n",
    "                              tokenizer, \n",
    "                              model_name=model_args_joint.model_name_or_path, \n",
    "                              tasks=tasks, mode=\"dev\", n_proc=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dims = {task : 1 if len(list(idx_to_classes[task].keys())) == 2 else len(list(idx_to_classes[task].keys())) for task in idx_to_classes}\n",
    "label_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_model = JointSeqClassifier.from_pretrained(os.path.join(output_dir,\n",
    "                                                              model_args_joint.model_nick, joint_task),\n",
    "                                           tasks=tasks,\n",
    "                                           model_args=model_args_joint,\n",
    "                                           task_if_single=None, \n",
    "                                           joint = training_args_joint.train_jointly,\n",
    "                                           label_dims=label_dims)\n",
    "\n",
    "trainer = JointTrainer([training_args_joint,model_args_joint, data_args_joint], \n",
    "                       joint_model, train_dataset, dev_dataset, idx_to_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run classifier on paraphrased and original text\n",
    "\n",
    "This is currently done with pd DataFrames but could probably be made better by using a batch data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_paraphrases(row, tasks, cols):\n",
    "    '''\n",
    "    Make style predictions on a given df row for a given set of text columns\n",
    "    and classification tasks. \n",
    "    '''\n",
    "    preds = {}\n",
    "    for col in cols:\n",
    "        sentence = row[col]\n",
    "        out = trainer.predict_for_sentence(sentence, tokenizer)\n",
    "        for task in tasks:\n",
    "            pred = float(out[task]['prob'])\n",
    "            preds[task + '_' + col] = pred\n",
    "    return preds\n",
    "\n",
    "def get_best_pred(row, cols, target_val=0.5):\n",
    "    '''\n",
    "    Helper funtion for determiningg which paraphrase is 'best' \n",
    "    for a given set of paraphrase column style scores and a target value\n",
    "    that you want the scores to be close to. Currently just outputs the best score\n",
    "    but could be modified to get best sentence as well.\n",
    "    '''\n",
    "    best_diff = 1\n",
    "    best_val = None\n",
    "    for col in cols:\n",
    "        diff = abs(row[col] - target_val)\n",
    "        if diff < best_diff:\n",
    "            best_val = row[col]\n",
    "            best_diff = diff\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns on which to run the classification\n",
    "cols_to_use = ['text','transfered1', 'transfered2', 'transfered3']\n",
    "# Define the names of the columns where the output scores will be stored\n",
    "cols_preds = [f'pred_{tasks[0]}_orig', f'pred_{tasks[1]}_orig',\n",
    "              f'pred_{tasks[0]}_transfered1', f'pred_{tasks[1]}_transfered1',\n",
    "              f'pred_{tasks[0]}_transfered2', f'pred_{tasks[1]}_transfered2',\n",
    "              f'pred_{tasks[0]}_transfered3', f'pred_{tasks[1]}_transfered3']\n",
    "# Store results into df\n",
    "df[cols_preds] = df.progress_apply(lambda x : pred_paraphrases(x, tasks, cols_to_use), \n",
    "                                   axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results of style classification:\n",
    "out_filename = paraphrase_task + '_train_cross_predict_transfers.csv'\n",
    "\n",
    "df.to_csv(os.path.join(data_dir, prompt_task, out_filename), header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the results of the transfer for style changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'{prompt_task}_diff1'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered1'])\n",
    "df[f'{prompt_task}_diff2'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered2'])\n",
    "df[f'{prompt_task}_diff3'] =  abs(df[f'pred_{prompt_task}_orig'] - df[f'pred_{prompt_task}_transfered3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['formality_diff_max'] = df.apply(lambda x : np.max([x[f'{prompt_task}_diff1'], \n",
    "                                                       x[f'{prompt_task}_diff2'], \n",
    "                                                       x[f'{prompt_task}_diff3']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at best sytle difference summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's disaggregate by class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']==0][f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']==1][f'{prompt_task}_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_marvin)",
   "language": "python",
   "name": "env_marvin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "70745de62fac122a8ca1204278c5668179019927655d931b4063a8c34fb0e461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
