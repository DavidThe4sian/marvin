{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sufficient-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reported-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driven-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "crude-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_into_input(ipath, opath):\n",
    "    with open(ipath, 'rb') as fob:\n",
    "        file = pickle.load(fob)\n",
    "    ofile = []\n",
    "    for line in file:\n",
    "        new_line = line[3]+tokenizer.bos_token+line[4]+tokenizer.bos_token+'\\n'\n",
    "        ofile.append(new_line)\n",
    "    with open(opath, 'w') as fob:\n",
    "        fob.writelines(ofile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "imperial-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_files_into_input('../data/paranmt_filtered/train.pickle','../data/paranmt_filtered/train_processed.txt')\n",
    "process_files_into_input('../data/paranmt_filtered/dev.pickle','../data/paranmt_filtered/dev_processed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "settled-panic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Whetstone is goingto speak to you after I finish.<|endoftext|>after I'm done, Mr. Whetstone will be speaking.<|endoftext|>\n",
      "I guess it's up to me to save this family, then.<|endoftext|>so saving my family is on me.<|endoftext|>\n",
      "It'll speed distribution when we get the lines set up.<|endoftext|>we would expedite such distributions when we form ranks.<|endoftext|>\n",
      "I'm less than 15 minutes away from Matobo's house.<|endoftext|>I'll be with Matoby in fifteen minutes.<|endoftext|>\n",
      "If it'd exist, I'd free it.<|endoftext|>if he really existed, I would have freed him.<|endoftext|>\n",
      "---------------------------------\n",
      "1, 2, 3, 4, and get the hell out of there!<|endoftext|>one, two, three, four and fall!<|endoftext|>\n",
      "A person's character is reflected in his wathan.<|endoftext|>in the wathan, it reflects the character of a man.<|endoftext|>\n",
      "In moments, black clouds seethed across the sky.<|endoftext|>within seconds, the sky drew black clouds.<|endoftext|>\n",
      "I shall therefore conduct my analysis on the basis of that premiss.<|endoftext|>that is why I will be based on this assumption in my analysis.<|endoftext|>\n",
      "It was kind of a warm, satisfied feeling.<|endoftext|>I had such a warm feeling of satisfaction.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../data/paranmt_filtered/train_processed.txt\n",
    "!echo \"---------------------------------\"\n",
    "!head -5 ../data/paranmt_filtered/dev_processed.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "quarterly-pursuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/10/2021 12:42:59 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/10/2021 12:42:59 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=./output, overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=EvaluationStrategy.STEPS, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Mar10_12-42-59_peace, logging_first_step=False, logging_steps=500, save_steps=2000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=./output, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=1)\n",
      "03/10/2021 12:42:59 - WARNING - datasets.builder -   Using custom data configuration default-1cbd18d00e1c152c\n",
      "03/10/2021 12:42:59 - WARNING - datasets.builder -   Reusing dataset text (/home/nuwandavek/.cache/huggingface/datasets/text/default-1cbd18d00e1c152c/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57)\n",
      "[INFO|configuration_utils.py:449] 2021-03-10 12:43:00,690 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /home/nuwandavek/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "[INFO|configuration_utils.py:485] 2021-03-10 12:43:00,691 >> Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:449] 2021-03-10 12:43:01,175 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /home/nuwandavek/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "[INFO|configuration_utils.py:485] 2021-03-10 12:43:01,177 >> Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-03-10 12:43:02,200 >> loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /home/nuwandavek/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-03-10 12:43:02,200 >> loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /home/nuwandavek/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1786] 2021-03-10 12:43:02,200 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /home/nuwandavek/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|modeling_utils.py:1027] 2021-03-10 12:43:02,574 >> loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /home/nuwandavek/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
      "[INFO|modeling_utils.py:1143] 2021-03-10 12:43:05,266 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "[INFO|modeling_utils.py:1151] 2021-03-10 12:43:05,266 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "03/10/2021 12:43:05 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/nuwandavek/.cache/huggingface/datasets/text/default-1cbd18d00e1c152c/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-42f6da54d02de8a0.arrow\n",
      "03/10/2021 12:43:05 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/nuwandavek/.cache/huggingface/datasets/text/default-1cbd18d00e1c152c/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-44abe8f59fa430b6.arrow\n",
      "03/10/2021 12:43:05 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/nuwandavek/.cache/huggingface/datasets/text/default-1cbd18d00e1c152c/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-d4dfbe575a18c39d.arrow\n",
      "03/10/2021 12:43:05 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /home/nuwandavek/.cache/huggingface/datasets/text/default-1cbd18d00e1c152c/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-9f71f9bb9d7db45a.arrow\n",
      "[INFO|trainer.py:431] 2021-03-10 12:43:07,460 >> The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
      "[INFO|trainer.py:431] 2021-03-10 12:43:07,460 >> The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
      "[INFO|trainer.py:837] 2021-03-10 12:43:07,462 >> ***** Running training *****\n",
      "[INFO|trainer.py:838] 2021-03-10 12:43:07,462 >>   Num examples = 8310\n",
      "[INFO|trainer.py:839] 2021-03-10 12:43:07,462 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:840] 2021-03-10 12:43:07,462 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:841] 2021-03-10 12:43:07,462 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:842] 2021-03-10 12:43:07,462 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:843] 2021-03-10 12:43:07,462 >>   Total optimization steps = 6234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6057, 'learning_rate': 4.59897337183189e-05, 'epoch': 0.24}          \n",
      "  8%|███▏                                    | 500/6234 [01:41<19:36,  4.87it/s][INFO|trainer.py:1600] 2021-03-10 12:44:48,991 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:44:48,991 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:44:48,991 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 26.69it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 22.86it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 20.82it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 19.58it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 18.78it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 18.26it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 17.94it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:00<00:01, 17.75it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 17.54it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 17.45it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 17.44it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 17.39it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:00, 17.28it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 17.34it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 17.20it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:01<00:00, 17.17it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:01<00:00, 17.24it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 17.23it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 17.17it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 17.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.36619234085083, 'eval_runtime': 2.4837, 'eval_samples_per_second': 68.849, 'epoch': 0.24}\n",
      "  8%|███▏                                    | 500/6234 [01:44<19:36,  4.87it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 17.20it/s]\u001b[A\n",
      "{'loss': 3.4419, 'learning_rate': 4.197946743663779e-05, 'epoch': 0.48}         \u001b[A\n",
      " 16%|██████▎                                | 1000/6234 [03:27<19:03,  4.58it/s][INFO|trainer.py:1600] 2021-03-10 12:46:35,205 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:46:35,206 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:46:35,206 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 24.50it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 21.02it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 19.11it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 17.88it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 17.15it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.71it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.37it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:01<00:01, 16.10it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 16.00it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 15.87it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 15.80it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 15.80it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:01, 15.76it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 15.72it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 15.70it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:02<00:00, 15.67it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 15.65it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 15.64it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 15.69it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 15.67it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.2994627952575684, 'eval_runtime': 2.7265, 'eval_samples_per_second': 62.719, 'epoch': 0.48}\n",
      " 16%|██████▎                                | 1000/6234 [03:30<19:03,  4.58it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 15.64it/s]\u001b[A\n",
      "{'loss': 3.3788, 'learning_rate': 3.7969201154956694e-05, 'epoch': 0.72}        \u001b[A\n",
      " 24%|█████████▍                             | 1500/6234 [05:19<16:55,  4.66it/s][INFO|trainer.py:1600] 2021-03-10 12:48:26,998 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:48:26,998 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:48:26,998 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 24.56it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 21.36it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 19.28it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 18.20it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 17.23it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.91it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.53it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:00<00:01, 16.52it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 16.22it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 16.16it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 15.97it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 16.02it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:01, 15.96it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 16.06it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 15.86it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:02<00:00, 16.02it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 15.92it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 16.05it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 15.92it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 15.99it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.2535979747772217, 'eval_runtime': 2.6809, 'eval_samples_per_second': 63.785, 'epoch': 0.72}\n",
      " 24%|█████████▍                             | 1500/6234 [05:22<16:55,  4.66it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 15.87it/s]\u001b[A\n",
      "{'loss': 3.3403, 'learning_rate': 3.395893487327559e-05, 'epoch': 0.96}         \u001b[A\n",
      " 32%|████████████▌                          | 2000/6234 [07:10<15:13,  4.63it/s][INFO|trainer.py:1600] 2021-03-10 12:50:18,441 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:50:18,441 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:50:18,441 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 23.72it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 20.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 18.83it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 17.95it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 17.10it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 17.01it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.96it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:00<00:01, 16.91it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 16.87it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 16.85it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 16.87it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 16.89it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:00, 16.81it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 16.85it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 16.85it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:01<00:00, 16.39it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 16.09it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 16.32it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 16.27it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 16.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.2280497550964355, 'eval_runtime': 2.6069, 'eval_samples_per_second': 65.594, 'epoch': 0.96}\n",
      " 32%|████████████▌                          | 2000/6234 [07:13<15:13,  4.63it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 16.60it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1408] 2021-03-10 12:50:21,048 >> Saving model checkpoint to ./output/checkpoint-2000\n",
      "[INFO|configuration_utils.py:304] 2021-03-10 12:50:21,050 >> Configuration saved in ./output/checkpoint-2000/config.json\n",
      "[INFO|modeling_utils.py:817] 2021-03-10 12:50:21,673 >> Model weights saved in ./output/checkpoint-2000/pytorch_model.bin\n",
      "{'loss': 3.23, 'learning_rate': 2.994866859159448e-05, 'epoch': 1.2}            \n",
      " 40%|███████████████▋                       | 2500/6234 [09:05<14:29,  4.29it/s][INFO|trainer.py:1600] 2021-03-10 12:52:13,093 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:52:13,093 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:52:13,093 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 23.97it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 20.54it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 18.70it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 17.56it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 16.89it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.38it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.06it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:01<00:01, 15.89it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 15.75it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 15.65it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 15.54it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 15.73it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:01, 15.56it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 15.57it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 15.51it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:02<00:00, 15.55it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 15.41it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 15.53it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 15.47it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 15.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.2082419395446777, 'eval_runtime': 2.7641, 'eval_samples_per_second': 61.865, 'epoch': 1.2}\n",
      " 40%|███████████████▋                       | 2500/6234 [09:08<14:29,  4.29it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 15.50it/s]\u001b[A\n",
      "{'loss': 3.2085, 'learning_rate': 2.5938402309913378e-05, 'epoch': 1.44}        \u001b[A\n",
      " 48%|██████████████████▊                    | 3000/6234 [10:55<11:11,  4.82it/s][INFO|trainer.py:1600] 2021-03-10 12:54:02,542 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:54:02,542 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:54:02,543 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 27.04it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 23.09it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 20.91it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 19.61it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 18.85it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 18.32it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 17.97it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:00<00:01, 17.70it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 17.55it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 17.45it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 17.36it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 17.29it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:00, 17.28it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 17.28it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 17.24it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:01<00:00, 17.24it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:01<00:00, 17.23it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 17.23it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 17.20it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 17.19it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.2010133266448975, 'eval_runtime': 2.4837, 'eval_samples_per_second': 68.848, 'epoch': 1.44}\n",
      " 48%|██████████████████▊                    | 3000/6234 [10:57<11:11,  4.82it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 17.03it/s]\u001b[A\n",
      "{'loss': 3.1929, 'learning_rate': 2.1928136028232275e-05, 'epoch': 1.68}        \u001b[A\n",
      " 56%|█████████████████████▉                 | 3500/6234 [12:42<09:28,  4.81it/s][INFO|trainer.py:1600] 2021-03-10 12:55:50,325 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:55:50,325 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:55:50,325 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 26.81it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 22.94it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 20.78it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 19.57it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|███████████                                | 11/43 [00:00<00:01, 18.79it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 18.14it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 17.73it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:00<00:01, 17.44it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 17.27it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 17.30it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 17.26it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 17.21it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:00, 17.18it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 17.14it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 17.16it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:01<00:00, 17.15it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:01<00:00, 17.11it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 17.21it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 17.08it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 17.13it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.18471097946167, 'eval_runtime': 2.501, 'eval_samples_per_second': 68.371, 'epoch': 1.68}\n",
      " 56%|█████████████████████▉                 | 3500/6234 [12:45<09:28,  4.81it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 17.10it/s]\u001b[A\n",
      "{'loss': 3.1847, 'learning_rate': 1.7917869746551172e-05, 'epoch': 1.92}        \u001b[A\n",
      " 64%|█████████████████████████              | 4000/6234 [14:34<08:03,  4.62it/s][INFO|trainer.py:1600] 2021-03-10 12:57:41,573 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:57:41,574 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:57:41,574 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 24.72it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 21.46it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 19.15it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 18.10it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 17.30it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.87it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.32it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:01<00:01, 16.38it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 16.11it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 16.04it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 15.81it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 15.95it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:01, 15.79it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 15.89it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 15.72it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:02<00:00, 15.89it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 15.76it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 15.97it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 15.79it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 15.92it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.1730635166168213, 'eval_runtime': 2.7022, 'eval_samples_per_second': 63.282, 'epoch': 1.92}\n",
      " 64%|█████████████████████████              | 4000/6234 [14:36<08:03,  4.62it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 15.79it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1408] 2021-03-10 12:57:44,276 >> Saving model checkpoint to ./output/checkpoint-4000\n",
      "[INFO|configuration_utils.py:304] 2021-03-10 12:57:44,277 >> Configuration saved in ./output/checkpoint-4000/config.json\n",
      "[INFO|modeling_utils.py:817] 2021-03-10 12:57:44,855 >> Model weights saved in ./output/checkpoint-4000/pytorch_model.bin\n",
      "{'loss': 3.1435, 'learning_rate': 1.3907603464870067e-05, 'epoch': 2.17}        \n",
      " 72%|████████████████████████████▏          | 4500/6234 [16:27<06:18,  4.58it/s][INFO|trainer.py:1600] 2021-03-10 12:59:35,428 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 12:59:35,428 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 12:59:35,428 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 24.70it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 21.43it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 19.24it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 17.94it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 17.16it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.63it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.21it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:01<00:01, 16.05it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 15.76it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 15.67it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 15.72it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 15.59it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:01, 15.78it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 15.72it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 15.74it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:02<00:00, 15.66it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 15.85it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 15.81it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 15.97it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 15.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.1711254119873047, 'eval_runtime': 2.7271, 'eval_samples_per_second': 62.705, 'epoch': 2.17}\n",
      " 72%|████████████████████████████▏          | 4500/6234 [16:30<06:18,  4.58it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 15.61it/s]\u001b[A\n",
      "{'loss': 3.1087, 'learning_rate': 9.897337183188963e-06, 'epoch': 2.41}         \u001b[A\n",
      " 80%|███████████████████████████████▎       | 5000/6234 [18:19<04:28,  4.60it/s][INFO|trainer.py:1600] 2021-03-10 13:01:27,455 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 13:01:27,455 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 13:01:27,455 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 23.79it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 20.62it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 19.02it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 17.82it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 17.15it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.51it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:01<00:01, 16.23it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 16.30it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 16.37it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 16.52it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 16.52it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:00, 16.64it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 16.59it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 16.73it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:01<00:00, 16.79it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 16.89it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 16.93it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 16.90it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 16.81it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.1663105487823486, 'eval_runtime': 2.6073, 'eval_samples_per_second': 65.586, 'epoch': 2.41}\n",
      " 80%|███████████████████████████████▎       | 5000/6234 [18:22<04:28,  4.60it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 16.83it/s]\u001b[A\n",
      "{'loss': 3.1157, 'learning_rate': 5.88707090150786e-06, 'epoch': 2.65}          \u001b[A\n",
      " 88%|██████████████████████████████████▍    | 5500/6234 [20:09<02:38,  4.64it/s][INFO|trainer.py:1600] 2021-03-10 13:03:17,165 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 13:03:17,165 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 13:03:17,165 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 24.70it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 21.26it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 19.07it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 18.20it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 17.30it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.94it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.43it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:01<00:01, 16.37it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 16.02it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 16.03it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 15.93it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 15.97it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:01, 15.83it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 15.97it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 15.77it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:02<00:00, 15.94it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 15.81it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 15.95it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 15.79it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 15.89it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.1605145931243896, 'eval_runtime': 2.6966, 'eval_samples_per_second': 63.413, 'epoch': 2.65}\n",
      " 88%|██████████████████████████████████▍    | 5500/6234 [20:12<02:38,  4.64it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 15.73it/s]\u001b[A\n",
      "{'loss': 3.1007, 'learning_rate': 1.8768046198267566e-06, 'epoch': 2.89}        \u001b[A\n",
      " 96%|█████████████████████████████████████▌ | 6000/6234 [22:03<00:50,  4.59it/s][INFO|trainer.py:1600] 2021-03-10 13:05:11,235 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:1601] 2021-03-10 13:05:11,235 >>   Num examples = 171\n",
      "[INFO|trainer.py:1602] 2021-03-10 13:05:11,235 >>   Batch size = 4\n",
      "\n",
      "  0%|                                                    | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███                                         | 3/43 [00:00<00:01, 23.61it/s]\u001b[A\n",
      " 12%|█████                                       | 5/43 [00:00<00:01, 20.35it/s]\u001b[A\n",
      " 16%|███████▏                                    | 7/43 [00:00<00:01, 18.61it/s]\u001b[A\n",
      " 21%|█████████▏                                  | 9/43 [00:00<00:01, 17.69it/s]\u001b[A\n",
      " 26%|███████████                                | 11/43 [00:00<00:01, 16.97it/s]\u001b[A\n",
      " 30%|█████████████                              | 13/43 [00:00<00:01, 16.72it/s]\u001b[A\n",
      " 35%|███████████████                            | 15/43 [00:00<00:01, 16.21it/s]\u001b[A\n",
      " 40%|█████████████████                          | 17/43 [00:01<00:01, 16.23it/s]\u001b[A\n",
      " 44%|███████████████████                        | 19/43 [00:01<00:01, 15.96it/s]\u001b[A\n",
      " 49%|█████████████████████                      | 21/43 [00:01<00:01, 15.75it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 23/43 [00:01<00:01, 15.65it/s]\u001b[A\n",
      " 58%|█████████████████████████                  | 25/43 [00:01<00:01, 15.54it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 27/43 [00:01<00:01, 15.50it/s]\u001b[A\n",
      " 67%|█████████████████████████████              | 29/43 [00:01<00:00, 15.45it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 31/43 [00:01<00:00, 15.40it/s]\u001b[A\n",
      " 77%|█████████████████████████████████          | 33/43 [00:02<00:00, 15.43it/s]\u001b[A\n",
      " 81%|███████████████████████████████████        | 35/43 [00:02<00:00, 15.36it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 37/43 [00:02<00:00, 15.36it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 39/43 [00:02<00:00, 15.36it/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████  | 41/43 [00:02<00:00, 15.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.1595754623413086, 'eval_runtime': 2.7643, 'eval_samples_per_second': 61.86, 'epoch': 2.89}\n",
      " 96%|█████████████████████████████████████▌ | 6000/6234 [22:06<00:50,  4.59it/s]\n",
      "100%|███████████████████████████████████████████| 43/43 [00:02<00:00, 15.36it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1408] 2021-03-10 13:05:14,000 >> Saving model checkpoint to ./output/checkpoint-6000\n",
      "[INFO|configuration_utils.py:304] 2021-03-10 13:05:14,036 >> Configuration saved in ./output/checkpoint-6000/config.json\n",
      "[INFO|modeling_utils.py:817] 2021-03-10 13:05:14,643 >> Model weights saved in ./output/checkpoint-6000/pytorch_model.bin\n",
      "100%|███████████████████████████████████████| 6234/6234 [23:00<00:00,  4.99it/s][INFO|trainer.py:1007] 2021-03-10 13:06:07,852 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1380.3894, 'train_samples_per_second': 4.516, 'epoch': 3.0}   \n",
      "100%|███████████████████████████████████████| 6234/6234 [23:00<00:00,  4.52it/s]\n",
      "[INFO|trainer.py:1408] 2021-03-10 13:06:07,879 >> Saving model checkpoint to ./output\n",
      "[INFO|configuration_utils.py:304] 2021-03-10 13:06:07,879 >> Configuration saved in ./output/config.json\n",
      "[INFO|modeling_utils.py:817] 2021-03-10 13:06:08,454 >> Model weights saved in ./output/pytorch_model.bin\n",
      "Traceback (most recent call last):\n",
      "  File \"../paraphrase/run_clm.py\", line 440, in <module>\n",
      "    main()\n",
      "  File \"../paraphrase/run_clm.py\", line 415, in main\n",
      "    trainer.log_metrics(\"train\", metrics)\n",
      "AttributeError: 'Trainer' object has no attribute 'log_metrics'\n"
     ]
    }
   ],
   "source": [
    "!python ../paraphrase/run_clm.py --model_name_or_path ./output\\\n",
    "    --train_file ../data/paranmt_filtered/train_processed.txt\\\n",
    "    --validation_file ../data/paranmt_filtered/dev_processed.txt \\\n",
    "    --do_train --do_eval --output_dir ./output --num_train_epochs 10 \\\n",
    "    --per_device_train_batch_size 4 --per_device_eval_batch_size 4 \\\n",
    "    --save_steps 2000 --eval_steps 500 --logging_steps 500 --evaluation_strategy steps \\\n",
    "    --overwrite_output_dir --block_size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "configured-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_generator = pipeline('text-generation', model='./output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-registrar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "nutritional-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Could you please open the door?<|endoftext|>do you have an open invitation?'},\n",
       " {'generated_text': 'Could you please open the door?<|endoftext|>we have a security check in front of you.'},\n",
       " {'generated_text': 'Could you please open the door?<|endoftext|>when you open the door please open the door?'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'Could you please open the door?'+tokenizer.bos_token\n",
    "ft_generator(txt, max_length=256, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-stuart",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
