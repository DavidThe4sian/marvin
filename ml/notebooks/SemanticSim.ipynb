{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# Sentence bert model for getting similarity\n",
    "model_name = \"sentence-transformers/stsb-distilbert-base\"\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    '''\n",
    "    Mean pool embeddings to get a sentence-level representation.\n",
    "    '''\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def get_sent_embedding(sent, model, tokenizer): \n",
    "    '''\n",
    "    Get sentence embedding for a given sentence using a given transformer model.\n",
    "    '''\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sent, padding=True, truncation=True, \n",
    "                              max_length=128, return_tensors='pt')\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        \n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return sentence_embedding\n",
    "    \n",
    "def len_pen(sent_orig, sent_generated):\n",
    "    '''\n",
    "    Length penalty for simialrity score. \n",
    "    If sentences are signifcantly different in length in either direction, \n",
    "    there are penalized.\n",
    "    '''\n",
    "    encoded_input_orig = tokenizer(sent_orig, padding=True, truncation=True, \n",
    "                              max_length=128, return_tensors='pt') \n",
    "    len_orig = encoded_input_orig['attention_mask'].shape[1]\n",
    "    \n",
    "    encoded_input_generated = tokenizer(sent_generated, padding=True, truncation=True, \n",
    "                              max_length=128, return_tensors='pt') \n",
    "    len_generated = encoded_input_generated['attention_mask'].shape[1]\n",
    "    return np.exp(1 - (np.max([len_orig, len_generated])/\\\n",
    "                       np.min([len_orig, len_generated])))\n",
    "    \n",
    "    \n",
    "def get_similarity(sent_orig, sent_generated, model, \n",
    "                   tokenizer, length_penalty=True, alpha=0.4):\n",
    "    '''\n",
    "    Get sentence similarity score between two sentences.\n",
    "    '''\n",
    "    embedding_orig =  get_sent_embedding(sent_orig, model, tokenizer)\n",
    "    embedding_generated =  get_sent_embedding(sent_generated, model, tokenizer)\n",
    "    sim = torch.nn.functional.cosine_similarity(embedding_orig, \n",
    "                                                embedding_generated, dim=1)\n",
    "    if length_penalty:\n",
    "        penalty = len_pen(sent_orig, sent_generated)\n",
    "        sim *= penalty**alpha\n",
    "    return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "# get_similarity('the world is a vampire', 'hello world', model, tokenizer)\n",
    "\n",
    "# get_similarity('me and my friends really really like u', \n",
    "#                'My friends and I quite like you.', model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and dataset we're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/pseudo/' \n",
    "model_name = 'shakespeare_binary' \n",
    "dataset = 'shakespeare'\n",
    "mode = 'dev'\n",
    "binary = True\n",
    "joint = False\n",
    "joint_transfer_tasks = ['formality', 'emo']\n",
    "num_return_sequences = 3\n",
    "\n",
    "if not binary:\n",
    "    in_filename = f'{dataset}_{mode}_cross_predict_transfers.csv'\n",
    "else:\n",
    "    in_filename = f'{dataset}_{mode}_binary_cross_predict_transfers.csv'\n",
    "full_path = os.path.join(data_dir, dataset, in_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data:\n",
    "Be careful not to overwrite the dataframe before results have been saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>orig_text</th>\n",
       "      <th>transfered1</th>\n",
       "      <th>transfered2</th>\n",
       "      <th>transfered3</th>\n",
       "      <th>pred_abstract_orig</th>\n",
       "      <th>pred_shakespeare_orig</th>\n",
       "      <th>pred_abstract_para</th>\n",
       "      <th>pred_shakespeare_para</th>\n",
       "      <th>pred_abstract_transfered1</th>\n",
       "      <th>pred_shakespeare_transfered1</th>\n",
       "      <th>pred_abstract_transfered2</th>\n",
       "      <th>pred_shakespeare_transfered2</th>\n",
       "      <th>pred_abstract_transfered3</th>\n",
       "      <th>pred_shakespeare_transfered3</th>\n",
       "      <th>shakespeare_diff1</th>\n",
       "      <th>shakespeare_diff2</th>\n",
       "      <th>shakespeare_diff3</th>\n",
       "      <th>shakespeare_diff_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sure you won't marry her.</td>\n",
       "      <td>But thus, I trust, you will not marry her.</td>\n",
       "      <td>I am sure you will not marry her.</td>\n",
       "      <td>I know you will not marry her.</td>\n",
       "      <td>I am sure thou willst not marry her.</td>\n",
       "      <td>0.040968</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.050229</td>\n",
       "      <td>0.167474</td>\n",
       "      <td>0.999019</td>\n",
       "      <td>0.994722</td>\n",
       "      <td>0.947023</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.994722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stand in front of the hearse!</td>\n",
       "      <td>Stand from the hearse.</td>\n",
       "      <td>Stand in front of hearse.</td>\n",
       "      <td>Stand in the hearse.</td>\n",
       "      <td>Stand in the hearse’s front!</td>\n",
       "      <td>0.115325</td>\n",
       "      <td>0.998852</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.590538</td>\n",
       "      <td>0.056994</td>\n",
       "      <td>0.998052</td>\n",
       "      <td>0.196209</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.408314</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.408314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not going to walk out of the door, but som...</td>\n",
       "      <td>I have no will to wander forth of doors, Yet s...</td>\n",
       "      <td>I’ll not walk out of my door, But something le...</td>\n",
       "      <td>I’ll not walk out of my door, But something le...</td>\n",
       "      <td>I’ll not walk out of my door, But something le...</td>\n",
       "      <td>0.138364</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.223029</td>\n",
       "      <td>0.999028</td>\n",
       "      <td>0.156101</td>\n",
       "      <td>0.998955</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do you mean removing him?</td>\n",
       "      <td>How do you mean, removing of him?</td>\n",
       "      <td>How mean you to remove him?</td>\n",
       "      <td>How dost thou mean to remove him?</td>\n",
       "      <td>How dost thou mean removing thee?</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.918759</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.981065</td>\n",
       "      <td>0.263301</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.238432</td>\n",
       "      <td>0.999120</td>\n",
       "      <td>0.062306</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.080361</td>\n",
       "      <td>0.080361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O Thou, I'm a captain, and I'm a gracious eye ...</td>\n",
       "      <td>O Thou, whose captain I account myself, Look o...</td>\n",
       "      <td>O Thou, i' th' captain, and my gracious eye up...</td>\n",
       "      <td>O Thou, i' th' captain, and gracious eye upon ...</td>\n",
       "      <td>O Thou, captain, and gracious eye upon my forces.</td>\n",
       "      <td>0.337572</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>0.110731</td>\n",
       "      <td>0.998729</td>\n",
       "      <td>0.352569</td>\n",
       "      <td>0.999073</td>\n",
       "      <td>0.353515</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.331410</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paraphrase  \\\n",
       "0                      I'm sure you won't marry her.   \n",
       "1                      stand in front of the hearse!   \n",
       "2  I'm not going to walk out of the door, but som...   \n",
       "3                      how do you mean removing him?   \n",
       "4  O Thou, I'm a captain, and I'm a gracious eye ...   \n",
       "\n",
       "                                           orig_text  \\\n",
       "0         But thus, I trust, you will not marry her.   \n",
       "1                             Stand from the hearse.   \n",
       "2  I have no will to wander forth of doors, Yet s...   \n",
       "3                  How do you mean, removing of him?   \n",
       "4  O Thou, whose captain I account myself, Look o...   \n",
       "\n",
       "                                         transfered1  \\\n",
       "0                  I am sure you will not marry her.   \n",
       "1                          Stand in front of hearse.   \n",
       "2  I’ll not walk out of my door, But something le...   \n",
       "3                        How mean you to remove him?   \n",
       "4  O Thou, i' th' captain, and my gracious eye up...   \n",
       "\n",
       "                                         transfered2  \\\n",
       "0                     I know you will not marry her.   \n",
       "1                               Stand in the hearse.   \n",
       "2  I’ll not walk out of my door, But something le...   \n",
       "3                  How dost thou mean to remove him?   \n",
       "4  O Thou, i' th' captain, and gracious eye upon ...   \n",
       "\n",
       "                                         transfered3  pred_abstract_orig  \\\n",
       "0               I am sure thou willst not marry her.            0.040968   \n",
       "1                       Stand in the hearse’s front!            0.115325   \n",
       "2  I’ll not walk out of my door, But something le...            0.138364   \n",
       "3                  How dost thou mean removing thee?            0.002919   \n",
       "4  O Thou, captain, and gracious eye upon my forces.            0.337572   \n",
       "\n",
       "   pred_shakespeare_orig  pred_abstract_para  pred_shakespeare_para  \\\n",
       "0               0.997252            0.000403               0.000557   \n",
       "1               0.998852            0.000320               0.012139   \n",
       "2               0.998991            0.000409               0.000621   \n",
       "3               0.918759            0.000276               0.000980   \n",
       "4               0.999085            0.110731               0.998729   \n",
       "\n",
       "   pred_abstract_transfered1  pred_shakespeare_transfered1  \\\n",
       "0                   0.000232                      0.002530   \n",
       "1                   0.001270                      0.590538   \n",
       "2                   0.223029                      0.999028   \n",
       "3                   0.006401                      0.981065   \n",
       "4                   0.352569                      0.999073   \n",
       "\n",
       "   pred_abstract_transfered2  pred_shakespeare_transfered2  \\\n",
       "0                   0.000307                      0.050229   \n",
       "1                   0.056994                      0.998052   \n",
       "2                   0.156101                      0.998955   \n",
       "3                   0.263301                      0.999117   \n",
       "4                   0.353515                      0.999066   \n",
       "\n",
       "   pred_abstract_transfered3  pred_shakespeare_transfered3  shakespeare_diff1  \\\n",
       "0                   0.167474                      0.999019           0.994722   \n",
       "1                   0.196209                      0.999079           0.408314   \n",
       "2                   0.183395                      0.998951           0.000037   \n",
       "3                   0.238432                      0.999120           0.062306   \n",
       "4                   0.331410                      0.999099           0.000011   \n",
       "\n",
       "   shakespeare_diff2  shakespeare_diff3  shakespeare_diff_max  \n",
       "0           0.947023           0.001767              0.994722  \n",
       "1           0.000800           0.000227              0.408314  \n",
       "2           0.000036           0.000040              0.000040  \n",
       "3           0.080357           0.080361              0.080361  \n",
       "4           0.000018           0.000014              0.000018  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_df = pd.read_csv(full_path)\n",
    "parallel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_scores(row, orig_col, generated_cols, model, tokenizer):\n",
    "    '''\n",
    "    Get semantic similarity between an original \n",
    "    text and a set of generated texts. \n",
    "    \n",
    "    This function is meant for applying to a row of a pd DataFrame \n",
    "    where 'col' is the name of the column that \n",
    "    contains the original text, 'generated_cols' are the names of\n",
    "    the columns of generated text, and 'row' is the row of the DataFrame. \n",
    "    '''\n",
    "    scores = {}\n",
    "    sent_orig = row[orig_col]\n",
    "    for col in generated_cols:\n",
    "        sent_generated = row[col]\n",
    "        score = get_similarity(sent_orig, sent_generated, model, tokenizer)\n",
    "        scores[f\"sim_score_{col}\"] = score.item()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the similarity model comparing transfers, originals, and paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9453/9453 [23:38<00:00,  6.66it/s]\n",
      "100%|██████████| 9453/9453 [31:33<00:00,  4.99it/s]\n"
     ]
    }
   ],
   "source": [
    "orig_col = 'orig_text'\n",
    "para_col = 'paraphrase'\n",
    "generated_cols = ['transfered1', 'transfered2', 'transfered3']\n",
    "orig_score_cols = [f\"sim_score_orig_{col}\" for col in generated_cols]\n",
    "para_score_cols = [f\"sim_score_para_{col}\" for col in generated_cols]\n",
    "temp = parallel_df.progress_apply(lambda x: get_sim_scores(x, orig_col, \n",
    "                                                           generated_cols, \n",
    "                                                           model, tokenizer), axis=1, result_type=\"expand\")\n",
    "parallel_df[orig_score_cols] = temp\n",
    "temp = parallel_df.progress_apply(lambda x: get_sim_scores(x, para_col, \n",
    "                                                           generated_cols, \n",
    "                                                           model, tokenizer), axis=1, result_type=\"expand\")\n",
    "parallel_df[para_score_cols] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9453/9453 [10:46<00:00, 14.63it/s]\n"
     ]
    }
   ],
   "source": [
    "parallel_df['sim_score_orig_para'] = parallel_df.progress_apply(lambda x: get_sim_scores(x, orig_col, \n",
    "                                                           [para_col], \n",
    "                                                           model, tokenizer), axis=1, result_type=\"expand\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best similarities for each of the transfers\n",
    "Also save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df['best_sim_orig'] = parallel_df.apply(lambda x : \n",
    "                                                 np.max([x['sim_score_orig_transfered1'], \n",
    "                                                         x['sim_score_orig_transfered2'], \n",
    "                                                       x['sim_score_orig_transfered3']]), axis=1)\n",
    "parallel_df['best_sim_para'] = parallel_df.apply(lambda x : np.max([x['sim_score_para_transfered1'], \n",
    "                                                       x['sim_score_para_transfered2'], \n",
    "                                                       x['sim_score_para_transfered3']]), axis=1)\n",
    "\n",
    "if not binary:\n",
    "    out_filename = f'{dataset}_{mode}_cross_predict_transfers_sim_scores.csv'\n",
    "else:\n",
    "    out_filename = f'{dataset}_{mode}_binary_cross_predict_transfers_sim_scores.csv'\n",
    "full_path = os.path.join(data_dir, dataset, out_filename)\n",
    "parallel_df.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not binary:\n",
    "    in_filename = f'{dataset}_{mode}_cross_predict_transfers_sim_scores.csv'\n",
    "else:\n",
    "    in_filename = f'{dataset}_{mode}_binary_cross_predict_transfers_sim_scores.csv'\n",
    "full_path = os.path.join(data_dir, dataset, in_filename)\n",
    "parallel_df = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute style differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paraphrase', 'orig_text', 'transfered1', 'transfered2', 'transfered3',\n",
       "       'pred_abstract_orig', 'pred_shakespeare_orig', 'pred_abstract_para',\n",
       "       'pred_shakespeare_para', 'pred_abstract_transfered1',\n",
       "       'pred_shakespeare_transfered1', 'pred_abstract_transfered2',\n",
       "       'pred_shakespeare_transfered2', 'pred_abstract_transfered3',\n",
       "       'pred_shakespeare_transfered3', 'shakespeare_diff1',\n",
       "       'shakespeare_diff2', 'shakespeare_diff3', 'shakespeare_diff_max',\n",
       "       'sim_score_orig_transfered1', 'sim_score_orig_transfered2',\n",
       "       'sim_score_orig_transfered3', 'sim_score_para_transfered1',\n",
       "       'sim_score_para_transfered2', 'sim_score_para_transfered3',\n",
       "       'sim_score_orig_para', 'best_sim_orig', 'best_sim_para'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joint:\n",
    "    parallel_df[f'{dataset}_diff1'] =  abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_transfered1'])\n",
    "    parallel_df[f'{dataset}_diff2'] =  abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_transfered2'])\n",
    "    parallel_df[f'{dataset}_diff3'] =  abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_transfered3'])\n",
    "\n",
    "    parallel_df[f'{dataset}_para_diff1'] =  abs(parallel_df[f'pred_{dataset}_para'] - parallel_df[f'pred_{dataset}_transfered1'])\n",
    "    parallel_df[f'{dataset}_para_diff2'] =  abs(parallel_df[f'pred_{dataset}_para'] - parallel_df[f'pred_{dataset}_transfered2'])\n",
    "    parallel_df[f'{dataset}_para_diff3'] =  abs(parallel_df[f'pred_{dataset}_para'] - parallel_df[f'pred_{dataset}_transfered3'])\n",
    "\n",
    "    parallel_df[f'{dataset}_para_orig_diff'] = abs(parallel_df[f'pred_{dataset}_orig'] - parallel_df[f'pred_{dataset}_para'])\n",
    "    \n",
    "    parallel_df[f'{dataset}_orig_diff_max'] = parallel_df.apply(lambda x : np.max([x[f'{dataset}_diff1'], \n",
    "                                                       x[f'{dataset}_diff2'], \n",
    "                                                       x[f'{dataset}_diff3']]), axis=1)\n",
    "\n",
    "    parallel_df[f'{dataset}_para_diff_max'] = parallel_df.apply(lambda x : np.max([x[f'{dataset}_para_diff1'], \n",
    "                                                      x[f'{dataset}_para_diff2'], \n",
    "                                                      x[f'{dataset}_para_diff3']]), axis=1)\n",
    "else:\n",
    "    for joint_transfer_task in joint_transfer_tasks:\n",
    "        parallel_df[f'{joint_transfer_task}_diff1'] =  abs(parallel_df[f'pred_{joint_transfer_task}_orig'] - parallel_df[f'pred_{joint_transfer_task}_transfered1'])\n",
    "        parallel_df[f'{joint_transfer_task}_diff2'] =  abs(parallel_df[f'pred_{joint_transfer_task}_orig'] - parallel_df[f'pred_{joint_transfer_task}_transfered2'])\n",
    "        parallel_df[f'{joint_transfer_task}_diff3'] =  abs(parallel_df[f'pred_{joint_transfer_task}_orig'] - parallel_df[f'pred_{joint_transfer_task}_transfered3'])\n",
    "\n",
    "        parallel_df[f'{joint_transfer_task}_para_diff1'] =  abs(parallel_df[f'pred_{joint_transfer_task}_para'] - parallel_df[f'pred_{joint_transfer_task}_transfered1'])\n",
    "        parallel_df[f'{joint_transfer_task}_para_diff2'] =  abs(parallel_df[f'pred_{joint_transfer_task}_para'] - parallel_df[f'pred_{joint_transfer_task}_transfered2'])\n",
    "        parallel_df[f'{joint_transfer_task}_para_diff3'] =  abs(parallel_df[f'pred_{joint_transfer_task}_para'] - parallel_df[f'pred_{joint_transfer_task}_transfered3'])\n",
    "\n",
    "        parallel_df[f'{joint_transfer_task}_para_orig_diff'] = abs(parallel_df[f'pred_{joint_transfer_task}_orig'] - parallel_df[f'pred_{joint_transfer_task}_para'])\n",
    "        \n",
    "        parallel_df[f'{joint_transfer_task}_orig_diff_max'] = parallel_df.apply(lambda x : np.max([x[f'{joint_transfer_task}_diff1'], \n",
    "                                                   x[f'{joint_transfer_task}_diff2'], \n",
    "                                                   x[f'{joint_transfer_task}_diff3']]), axis=1)\n",
    "\n",
    "        parallel_df[f'{joint_transfer_task}_para_diff_max'] = parallel_df.apply(lambda x : np.max([x[f'{joint_transfer_task}_para_diff1'], \n",
    "                                                   x[f'{joint_transfer_task}_para_diff2'], \n",
    "                                                   x[f'{joint_transfer_task}_para_diff3']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the summary stats for style transfer eval metrics and for semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df['best_sim_orig'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_mean = round(parallel_df['best_sim_para'].mean(), 4)\n",
    "para_std = round(parallel_df['best_sim_para'].std(), 4)\n",
    "orig_mean = round(parallel_df['best_sim_orig'].mean(), 4)\n",
    "orig_std = round(parallel_df['best_sim_orig'].std(), 4)\n",
    "print(f'{para_mean} ({para_std})')\n",
    "print(f'{orig_mean} ({orig_std})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(parallel_df[f'{dataset}_para_diff_max'].mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[f'{dataset}_para_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the summary stats for style transfer eval metrics and for semantic similarity disaggregated by original class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[parallel_df['para_bucket']=='low']['best_sim_orig'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[parallel_df['para_bucket']=='mid']['best_sim_orig'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[parallel_df['para_bucket']=='low']['best_sim_para'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[parallel_df['para_bucket']=='mid']['best_sim_para'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[parallel_df['para_bucket']=='low'][f'{dataset}_orig_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[parallel_df['para_bucket']=='mid'][f'{dataset}_orig_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = f'{dataset}_{mode}_cross_predict_transfers_sim_scores.csv'\n",
    "full_path = os.path.join(data_dir, dataset, out_filename)\n",
    "parallel_df.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joint:\n",
    "    print(f\"## Summary Stats for {dataset} {mode}\")\n",
    "    print('| Metric     | Mean | Std Dev|')\n",
    "    print('| ----------- | ----------- |--------|')\n",
    "    print(f\"| Style difference between original and transfers | {parallel_df[f'{dataset}_orig_diff_max'].mean() : .4f} | {parallel_df[f'{dataset}_orig_diff_max'].std(): .4f} |\")\n",
    "    print(f\"| Style difference between paraphrase and transfers | {parallel_df[f'{dataset}_para_diff_max'].mean() : .4f} | {parallel_df[f'{dataset}_para_diff_max'].std(): .4f} |\")\n",
    "    print(f\"| Semantic similarity between original and transfers | {parallel_df['best_sim_orig'].mean(): .4f} | {parallel_df['best_sim_orig'].std(): .4f} |\")\n",
    "    print(f\"| Semantic similarity between paraphrase and transfers | {parallel_df['best_sim_para'].mean(): .4f} | {parallel_df['best_sim_para'].std(): .4f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if joint:\n",
    "    for joint_transfer_task in joint_transfer_tasks:\n",
    "        orig_diff_mean = parallel_df[f'{joint_transfer_task}_orig_diff_max'].mean()\n",
    "        orig_diff_std = parallel_df[f'{joint_transfer_task}_orig_diff_max'].std()\n",
    "        print(f'orig_diff {joint_transfer_task} {orig_diff_mean :.4f} ({orig_diff_std :.4f}) ')\n",
    "        para_diff_mean = parallel_df[f'{joint_transfer_task}_para_diff_max'].mean()\n",
    "        para_diff_std = parallel_df[f'{joint_transfer_task}_para_diff_max'].std()\n",
    "        print(f'para_diff {joint_transfer_task} {para_diff_mean :.4f} ({para_diff_std :.4f}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round(parallel_df.groupby(['formality_para_bucket', 'emo_para_bucket']).size() / len(parallel_df), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(data=parallel_df, x=\"pred_formality_orig\", y='pred_emo_orig')\n",
    "# plt.savefig('example_jointdist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_bounds = {'shakespeare' : {'low' : (0., 0.1), 'mid' : (0.1, 0.9), 'high' : (0.9, 1.)},\n",
    "'formality' : {'low' : (0., 0.2), 'mid' : (0.2, 0.7), 'high' : (0.7, 1.)},\n",
    " 'emo' : {'low' : (0., 0.25), 'mid' : (0.25, 0.7), 'high' : (0.7, 1.)},\n",
    "          'abstract' : {'low' : (0., 0.1), 'mid' : (0.1, 0.9), 'high' : (0.9, 1.)}}\n",
    "\n",
    "def get_bucket(bucket_bounds, pred, task):\n",
    "    bucks = bucket_bounds[task]\n",
    "    if pred < bucks['low'][1]:\n",
    "        return 'low'\n",
    "    elif pred < bucks['mid'][1]:\n",
    "        return 'mid'\n",
    "    else:\n",
    "        return 'high'\n",
    "    \n",
    "    \n",
    "if joint:\n",
    "    \n",
    "    for joint_transfer_task in joint_transfer_tasks:\n",
    "        for i in range(num_return_sequences):\n",
    "            parallel_df[f'{joint_transfer_task}_transfered{i+1}_bucket'] = \\\n",
    "            parallel_df.apply(lambda x : get_bucket(bucket_bounds, \n",
    "                                                    x[f'pred_{joint_transfer_task}_transfered{i+1}'], \n",
    "                                                    joint_transfer_task), \n",
    "                              axis=1)\n",
    "\n",
    "    for joint_transfer_task in joint_transfer_tasks:\n",
    "            print(f\"{joint_transfer_task}\")\n",
    "            bool1 = (parallel_df[f'{joint_transfer_task}_transfered1_bucket'] == \\\n",
    "                     parallel_df[f'{joint_transfer_task}_orig_bucket'])\n",
    "            bool2 = (parallel_df[f'{joint_transfer_task}_transfered2_bucket'] == \\\n",
    "                    parallel_df[f'{joint_transfer_task}_orig_bucket'])\n",
    "            bool3 = (parallel_df[f'{joint_transfer_task}_transfered3_bucket'] == \\\n",
    "                     parallel_df[f'{joint_transfer_task}_orig_bucket'])\n",
    "            print(round((bool1 | bool2 | bool3).mean(), 4))\n",
    "            \n",
    "else:\n",
    "    if not binary:\n",
    "        for i in range(num_return_sequences):\n",
    "            parallel_df[f'transfered{i+1}_bucket'] = \\\n",
    "            parallel_df.apply(lambda x : get_bucket(bucket_bounds, \n",
    "                                                    x[f'pred_{dataset}_transfered{i+1}'], \n",
    "                                                    dataset), \n",
    "                              axis=1)\n",
    "\n",
    "        print(f\"{dataset}\")\n",
    "        bool1 = (parallel_df[f'transfered1_bucket'] == \\\n",
    "                 parallel_df[f'oring_bucket'])\n",
    "        bool2 = (parallel_df[f'transfered2_bucket'] == \\\n",
    "                parallel_df[f'oring_bucket'])\n",
    "        bool3 = (parallel_df[f'transfered3_bucket'] == \\\n",
    "                 parallel_df[f'oring_bucket'])\n",
    "        print(f'accuracy of at least one {round((bool1 | bool2 | bool3).mean(), 4)}') \n",
    "        print(f'accuracy of at all {round((np.mean([bool1.mean(), bool2.mean(), bool3.mean()])), 4)}')\n",
    "        \n",
    "    else:\n",
    "        for i in range(num_return_sequences):\n",
    "            parallel_df[f'transfered{i+1}_bucket'] = \\\n",
    "            parallel_df.apply(lambda x : get_bucket(bucket_bounds, \n",
    "                                                    x[f'pred_{dataset}_transfered{i+1}'], \n",
    "                                                    dataset), \n",
    "                              axis=1)\n",
    "\n",
    "        print(f\"{dataset}\")\n",
    "        bool1 = (parallel_df[f'transfered1_bucket'] == 'high')\n",
    "        bool2 = (parallel_df[f'transfered2_bucket'] == 'high')\n",
    "        bool3 = (parallel_df[f'transfered3_bucket'] == 'high')\n",
    "        print(f'accuracy of at least one {round((bool1 | bool2 | bool3).mean(), 4)}') \n",
    "        print(f'accuracy of at all {round((np.mean([bool1.mean(), bool2.mean(), bool3.mean()])), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary:\n",
    "    binary_trans_buckets = (parallel_df[f'transfered1_bucket'].value_counts() + \\\n",
    "    parallel_df[f'transfered2_bucket'].value_counts() + \n",
    "    parallel_df[f'transfered3_bucket'].value_counts()) / (len(parallel_df) * 3)\n",
    "    print(f\"Transfer buckets rates \\n{binary_trans_buckets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some examples\n",
    "\n",
    "random_sample = parallel_df.sample().iloc[0]\n",
    "print(random_sample)\n",
    "print('\\n')\n",
    "print(f\"orig text:\\n{random_sample['orig_text']}\")\n",
    "print(f\"paraphrase:\\n{random_sample['paraphrase']}\")\n",
    "print(f\"transfers:\\n{random_sample['transfered1']}\")\n",
    "print(f\"{random_sample['transfered2']}\")\n",
    "print(f\"{random_sample['transfered3']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and creating summary markdown tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = f'../results/{dataset}/{mode}'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "axs.set_title(f\"Distribution of Style Classification Differences Between Original Text and Transfer {dataset}\")\n",
    "axs.set_xlabel(f\"Style Difference\")\n",
    "axs.set_ylabel(f\"Counts\")\n",
    "plt.hist(parallel_df[f'{dataset}_orig_diff_max'].values, density=False);\n",
    "plt.savefig(os.path.join(results_dir, f'{dataset}_orig_diffs.png'))\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "axs.set_title(f\"Distribution of Semantic Similarity Between Original Text and Transfer {dataset}\")\n",
    "axs.set_xlabel(f\"Similarity\")\n",
    "axs.set_ylabel(f\"Counts\")\n",
    "plt.hist(parallel_df['best_sim_orig'].values, density=False);\n",
    "plt.savefig(os.path.join(results_dir, f'{dataset}_orig_sims.png'))\n",
    "\n",
    "with open(os.path.join(results_dir, f'{dataset}_{mode}_orig_diffs.md'), 'w') as summaryfile:\n",
    "    summaryfile.write(f\"## Summary Stats for {dataset} {mode}\\n\")\n",
    "    summaryfile.write('| Metric     | Mean | Std Dev|\\n')\n",
    "    summaryfile.write('| ----------- | ----------- |--------|\\n')\n",
    "    summaryfile.write(f\"| Style difference between original and transfers | {parallel_df[f'{dataset}_orig_diff_max'].mean() : .4f} | {parallel_df[f'{dataset}_orig_diff_max'].std(): .4f} |\\n\")\n",
    "    summaryfile.write(f\"| Style difference between paraphrase and transfers | {parallel_df[f'{dataset}_para_diff_max'].mean() : .4f} | {parallel_df[f'{dataset}_para_diff_max'].std(): .4f} |\\n\")\n",
    "    summaryfile.write(f\"| Semantic similarity between original and transfers | {parallel_df['best_sim_orig'].mean(): .4f} | {parallel_df['best_sim_orig'].std(): .4f} |\\n\")\n",
    "    summaryfile.write(f\"| Semantic similarity between paraphrase and transfers | {parallel_df['best_sim_para'].mean(): .4f} | {parallel_df['best_sim_para'].std(): .4f} |\\n\")\n",
    "\n",
    "for target_style in parallel_df['oring_bucket'].unique().tolist():\n",
    "    fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "    axs.set_title(f\"Distribution of Style Classification Differences Between Original Text and Transfer (Target Style {dataset} {target_style})\")\n",
    "    axs.set_xlabel(f\"Style Difference\")\n",
    "    axs.set_ylabel(f\"Counts\")\n",
    "    plt.hist(parallel_df[parallel_df['oring_bucket']==target_style][f'{dataset}_orig_diff_max'].values, density=False);\n",
    "    plt.savefig(os.path.join(results_dir, f'{dataset}_{target_style}_orig_diffs.png'))\n",
    "    \n",
    "    fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "    axs.set_title(f\"Distribution of Semantic Similarity Between Original Text and Transfer (Target Style {dataset} {target_style})\")\n",
    "    axs.set_xlabel(f\"Similarity\")\n",
    "    axs.set_ylabel(f\"Counts\")\n",
    "    plt.hist(parallel_df[parallel_df['oring_bucket']==target_style]['best_sim_orig'].values, density=False);\n",
    "    plt.savefig(os.path.join(results_dir, f'{dataset}_{target_style}_orig_sims.png'))\n",
    "    \n",
    "    filtered = parallel_df[parallel_df['oring_bucket']==target_style]\n",
    "    with open(os.path.join(results_dir, f'{dataset}_{mode}_{target_style}_orig_diffs.md'), 'w') as summaryfile:\n",
    "        summaryfile.write(f\"## Summary Stats for {dataset} {mode} (Target Style {dataset} {target_style})\\n\")\n",
    "        summaryfile.write('| Metric     | Mean | Std Dev|\\n')\n",
    "        summaryfile.write('| ----------- | ----------- |--------|\\n')\n",
    "        summaryfile.write(f\"| Style difference between original and transfers | {filtered[f'{dataset}_orig_diff_max'].mean() : .4f} | {filtered[f'{dataset}_orig_diff_max'].std(): .4f} |\\n\")\n",
    "        summaryfile.write(f\"| Style difference between paraphrase and transfers | {filtered[f'{dataset}_para_diff_max'].mean() : .4f} | {filtered[f'{dataset}_para_diff_max'].std(): .4f} |\\n\")\n",
    "        summaryfile.write(f\"| Semantic similarity between original and transfers | {filtered['best_sim_orig'].mean(): .4f} | {filtered['best_sim_orig'].std(): .4f} |\\n\")\n",
    "        summaryfile.write(f\"| Semantic similarity between paraphrase and transfers | {filtered['best_sim_para'].mean(): .4f} | {filtered['best_sim_para'].std(): .4f} |\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "axs.set_title(f\"Distribution of Style Classification Differences Between Paraphrased Text and Transfer {dataset}\")\n",
    "axs.set_xlabel(f\"Style Difference\")\n",
    "axs.set_ylabel(f\"Counts\")\n",
    "plt.hist(parallel_df[f'{dataset}_para_diff_max'].values, density=False);\n",
    "plt.savefig(os.path.join(results_dir, f'{dataset}_para_diffs.png'))\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "axs.set_title(f\"Distribution of Semantic Similarity Between Paraphrased Text and Transfer {dataset}\")\n",
    "axs.set_xlabel(f\"Similarity\")\n",
    "axs.set_ylabel(f\"Counts\")\n",
    "plt.hist(parallel_df['best_sim_para'].values, density=False);\n",
    "plt.savefig(os.path.join(results_dir, f'{dataset}_para_sims.png'))\n",
    "\n",
    "with open(os.path.join(results_dir, f'{dataset}_{mode}_para_diffs.md'), 'w') as summaryfile:\n",
    "    summaryfile.write(f\"## Summary Stats for {dataset} {mode}\\n\")\n",
    "    summaryfile.write('| Metric     | Mean | Std Dev|\\n')\n",
    "    summaryfile.write('| ----------- | ----------- |--------|\\n')\n",
    "    summaryfile.write(f\"| Style difference between paraphrased and transfers | {parallel_df[f'{dataset}_para_diff_max'].mean() : .4f} | {parallel_df[f'{dataset}_para_diff_max'].std(): .4f} |\\n\")\n",
    "    summaryfile.write(f\"| Style difference between paraphrase and transfers | {parallel_df[f'{dataset}_para_diff_max'].mean() : .4f} | {parallel_df[f'{dataset}_para_diff_max'].std(): .4f} |\\n\")\n",
    "    summaryfile.write(f\"| Semantic similarity between paraphrased and transfers | {parallel_df['best_sim_para'].mean(): .4f} | {parallel_df['best_sim_para'].std(): .4f} |\\n\")\n",
    "    summaryfile.write(f\"| Semantic similarity between paraphrase and transfers | {parallel_df['best_sim_para'].mean(): .4f} | {parallel_df['best_sim_para'].std(): .4f} |\\n\")\n",
    "\n",
    "for target_style in parallel_df['oring_bucket'].unique().tolist():\n",
    "    fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "    axs.set_title(f\"Distribution of Style Classification Differences Between Paraphrased Text and Transfer (Target Style {dataset} {target_style})\")\n",
    "    axs.set_xlabel(f\"Style Difference\")\n",
    "    axs.set_ylabel(f\"Counts\")\n",
    "    plt.hist(parallel_df[parallel_df['oring_bucket']==target_style][f'{dataset}_para_diff_max'].values, density=False);\n",
    "    plt.savefig(os.path.join(results_dir, f'{dataset}_{target_style}_para_diffs.png'))\n",
    "    \n",
    "    fig, axs = plt.subplots(1,1,figsize=(15,10))\n",
    "    axs.set_title(f\"Distribution of Semantic Similarity Between Paraphrased Text and Transfer (Target Style {dataset} {target_style})\")\n",
    "    axs.set_xlabel(f\"Similarity\")\n",
    "    axs.set_ylabel(f\"Counts\")\n",
    "    plt.hist(parallel_df[parallel_df['oring_bucket']==target_style]['best_sim_para'].values, density=False);\n",
    "    plt.savefig(os.path.join(results_dir, f'{dataset}_{target_style}_para_sims.png'))\n",
    "    \n",
    "    filtered = parallel_df[parallel_df['oring_bucket']==target_style]\n",
    "    with open(os.path.join(results_dir, f'{dataset}_{mode}_{target_style}_para_diffs.md'), 'w') as summaryfile:\n",
    "        summaryfile.write(f\"## Summary Stats for {dataset} {mode} (Target Style {dataset} {target_style})\\n\")\n",
    "        summaryfile.write('| Metric     | Mean | Std Dev|\\n')\n",
    "        summaryfile.write('| ----------- | ----------- |--------|\\n')\n",
    "        summaryfile.write(f\"| Style difference between paraphrased and transfers | {filtered[f'{dataset}_para_diff_max'].mean() : .4f} | {filtered[f'{dataset}_para_diff_max'].std(): .4f} |\\n\")\n",
    "        summaryfile.write(f\"| Style difference between paraphrase and transfers | {filtered[f'{dataset}_para_diff_max'].mean() : .4f} | {filtered[f'{dataset}_para_diff_max'].std(): .4f} |\\n\")\n",
    "        summaryfile.write(f\"| Semantic similarity between paraphrased and transfers | {filtered['best_sim_para'].mean(): .4f} | {filtered['best_sim_para'].std(): .4f} |\\n\")\n",
    "        summaryfile.write(f\"| Semantic similarity between paraphrase and transfers | {filtered['best_sim_para'].mean(): .4f} | {filtered['best_sim_para'].std(): .4f} |\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_marvin)",
   "language": "python",
   "name": "env_marvin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
