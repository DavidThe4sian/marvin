{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"sentence-transformers/stsb-distilbert-base\"\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def get_sent_embedding(sent, model, tokenizer): \n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sent, padding=True, truncation=True, \n",
    "                              max_length=128, return_tensors='pt')\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        \n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return sentence_embedding\n",
    "    \n",
    "def len_pen(sent_orig, sent_generated):\n",
    "    encoded_input_orig = tokenizer(sent_orig, padding=True, truncation=True, \n",
    "                              max_length=128, return_tensors='pt') \n",
    "    len_orig = encoded_input_orig['attention_mask'].shape[1]\n",
    "    \n",
    "    encoded_input_generated = tokenizer(sent_generated, padding=True, truncation=True, \n",
    "                              max_length=128, return_tensors='pt') \n",
    "    len_generated = encoded_input_generated['attention_mask'].shape[1]\n",
    "    return np.exp(1 - (np.max([len_orig, len_generated])/\\\n",
    "                       np.min([len_orig, len_generated])))\n",
    "    \n",
    "    \n",
    "def get_similarity(sent_orig, sent_generated, model, \n",
    "                   tokenizer, length_penalty=True, alpha=0.4):\n",
    "    embedding_orig =  get_sent_embedding(sent_orig, model, tokenizer)\n",
    "    embedding_generated =  get_sent_embedding(sent_generated, model, tokenizer)\n",
    "    sim = torch.nn.functional.cosine_similarity(embedding_orig, \n",
    "                                                embedding_generated, dim=1)\n",
    "    if length_penalty:\n",
    "        penalty = len_pen(sent_orig, sent_generated)\n",
    "        sim *= penalty**alpha\n",
    "    return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity('the world is a vampire', 'hello world', model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity('me and my friends really really like u', 'My friends and I quite like you.', model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/processed_filtered'\n",
    "dataset = 'formality'\n",
    "base_filename = 'formality_train_cross_predict_transfers.csv'\n",
    "full_path = os.path.join(data_dir, dataset, base_filename)\n",
    "\n",
    "\n",
    "parallel_df = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_scores(row, orig_col, generated_cols, model, tokenizer):\n",
    "    '''\n",
    "    Get semantic similarity between an original \n",
    "    text and a set of generated texts. \n",
    "    \n",
    "    This function is meant for applying to a row of a pd DataFrame \n",
    "    where 'col' is the name of the column that \n",
    "    contains the original text, 'generated_cols' are the names of\n",
    "    the columns of generated text, and 'row' is the row of the DataFrame. \n",
    "    '''\n",
    "    scores = {}\n",
    "    sent_orig = row[orig_col]\n",
    "    for col in generated_cols:\n",
    "        sent_generated = row[col]\n",
    "        score = get_similarity(sent_orig, sent_generated, model, tokenizer)\n",
    "        scores[f\"sim_score_{col}\"] = score.item()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head = parallel_df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_col = 'text'\n",
    "#generated_cols = ['paraphrased1', 'paraphrased2', 'paraphrased3']\n",
    "generated_cols = ['transfered1', 'transfered2', 'transfered3']\n",
    "score_cols = [f\"sim_score_{col}\" for col in generated_cols]\n",
    "thing = parallel_df_head.progress_apply(lambda x: get_sim_scores(x, \n",
    "                                                                 orig_col, \n",
    "                                                                 generated_cols, \n",
    "                                                                 model, \n",
    "                                                                 tokenizer), axis=1, result_type=\"expand\")\n",
    "\n",
    "parallel_df_head[score_cols] = thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head['best_sim'] = parallel_df_head.apply(lambda x : np.max([x['sim_score_transfered1'], \n",
    "                                                       x['sim_score_transfered2'], \n",
    "                                                       x['sim_score_transfered3']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head['formality_diff1'] =  abs(parallel_df_head['pred_formality_orig'] - parallel_df_head['pred_formality_transfered1'])\n",
    "parallel_df_head['formality_diff2'] =  abs(parallel_df_head['pred_formality_orig'] - parallel_df_head['pred_formality_transfered2'])\n",
    "parallel_df_head['formality_diff3'] =  abs(parallel_df_head['pred_formality_orig'] - parallel_df_head['pred_formality_transfered3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head['formality_diff_max'] = parallel_df_head.apply(lambda x : np.max([x['formality_diff1'], \n",
    "                                                       x['formality_diff2'], \n",
    "                                                       x['formality_diff3']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the summary stats for style transfer eval metrics and for semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head['best_sim'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head['formality_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the summary stats for style transfer eval metrics and for semantic similarity disaggregated by original class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head[parallel_df_head['label']==0]['best_sim'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head[parallel_df_head['label']==1]['best_sim'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head[parallel_df_head['label']==1]['formality_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head[parallel_df_head['label']==1]['formality_diff_max'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_col = 'text'\n",
    "# #generated_cols = ['paraphrased1', 'paraphrased2', 'paraphrased3']\n",
    "# generated_cols = ['transfered1', 'transfered2', 'transfered3']\n",
    "# score_cols = [f\"sim_score_{col}\" for col in generated_cols]\n",
    "\n",
    "# thing = parallel_df.progress_apply(lambda x: get_sim_scores(x, orig_col, generated_cols,\n",
    "#                                                             model, tokenizer), \n",
    "#                                                      axis=1, result_type=\"expand\")\n",
    "# parallel_df[score_cols] = thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = 'formality_train_cross_predict_transfers_sim_scores_head_5000.csv'\n",
    "full_path = os.path.join(data_dir, dataset, out_filename)\n",
    "parallel_df_head.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_marvin)",
   "language": "python",
   "name": "env_marvin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
